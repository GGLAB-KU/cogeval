2023-04-03 22:48:31,921 - INFO - allennlp.common.params - random_seed = 13370
2023-04-03 22:48:31,923 - INFO - allennlp.common.params - numpy_seed = 1337
2023-04-03 22:48:31,923 - INFO - allennlp.common.params - pytorch_seed = 133
2023-04-03 22:48:31,942 - INFO - allennlp.common.checks - Pytorch version: 1.12.1+cu102
2023-04-03 22:48:31,943 - INFO - allennlp.common.params - type = default
2023-04-03 22:48:31,945 - INFO - allennlp.common.params - dataset_reader.type = snli
2023-04-03 22:48:31,946 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2023-04-03 22:48:31,947 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False
2023-04-03 22:48:31,948 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False
2023-04-03 22:48:31,949 - INFO - allennlp.common.params - dataset_reader.tokenizer = None
2023-04-03 22:48:31,950 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2023-04-03 22:48:31,951 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2023-04-03 22:48:31,952 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2023-04-03 22:48:31,952 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2023-04-03 22:48:31,953 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2023-04-03 22:48:31,954 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.feature_name = text
2023-04-03 22:48:31,954 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING
2023-04-03 22:48:31,955 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2023-04-03 22:48:31,956 - INFO - allennlp.common.params - dataset_reader.combine_input_fields = None
2023-04-03 22:48:31,957 - INFO - allennlp.common.params - dataset_reader.collapse_labels = False
2023-04-03 22:48:33,069 - INFO - allennlp.common.params - train_data_path = ./data/snli_1.0_train_clean.jsonl
2023-04-03 22:48:33,071 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f56b42d4550>
2023-04-03 22:48:33,072 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2023-04-03 22:48:33,073 - INFO - allennlp.common.params - validation_dataset_reader = None
2023-04-03 22:48:33,073 - INFO - allennlp.common.params - validation_data_path = ./data/snli_1.0_dev.jsonl
2023-04-03 22:48:33,074 - INFO - allennlp.common.params - validation_data_loader = None
2023-04-03 22:48:33,074 - INFO - allennlp.common.params - test_data_path = ./data/snli_1.0_test.jsonl
2023-04-03 22:48:33,075 - INFO - allennlp.common.params - evaluate_on_test = False
2023-04-03 22:48:33,076 - INFO - allennlp.common.params - batch_weight_key = 
2023-04-03 22:48:33,077 - INFO - allennlp.common.params - data_loader.type = multiprocess
2023-04-03 22:48:33,078 - INFO - allennlp.common.params - data_loader.batch_size = None
2023-04-03 22:48:33,078 - INFO - allennlp.common.params - data_loader.drop_last = False
2023-04-03 22:48:33,079 - INFO - allennlp.common.params - data_loader.shuffle = False
2023-04-03 22:48:33,080 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2023-04-03 22:48:33,080 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 64
2023-04-03 22:48:33,081 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2023-04-03 22:48:33,082 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2023-04-03 22:48:33,082 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2023-04-03 22:48:33,083 - INFO - allennlp.common.params - data_loader.batch_sampler.shuffle = True
2023-04-03 22:48:33,083 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2023-04-03 22:48:33,084 - INFO - allennlp.common.params - data_loader.num_workers = 0
2023-04-03 22:48:33,085 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2023-04-03 22:48:33,085 - INFO - allennlp.common.params - data_loader.start_method = fork
2023-04-03 22:48:33,086 - INFO - allennlp.common.params - data_loader.cuda_device = None
2023-04-03 22:48:33,086 - INFO - allennlp.common.params - data_loader.quiet = False
2023-04-03 22:48:33,087 - INFO - allennlp.common.params - data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x7f56e02a65e0>
2023-04-03 22:48:33,089 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2023-04-03 22:48:43,162 - INFO - tqdm - loading instances: 2195it [00:10, 235.42it/s]
2023-04-03 22:48:53,186 - INFO - tqdm - loading instances: 4403it [00:20, 223.80it/s]
2023-04-03 22:49:03,220 - INFO - tqdm - loading instances: 6625it [00:30, 228.55it/s]
2023-04-03 22:49:13,237 - INFO - tqdm - loading instances: 8820it [00:40, 233.29it/s]
2023-04-03 22:49:23,325 - INFO - tqdm - loading instances: 11135it [00:50, 234.02it/s]
2023-04-03 22:49:33,350 - INFO - tqdm - loading instances: 13311it [01:00, 225.09it/s]
2023-04-03 22:49:43,439 - INFO - tqdm - loading instances: 15616it [01:10, 227.61it/s]
2023-04-03 22:49:53,537 - INFO - tqdm - loading instances: 17802it [01:20, 229.82it/s]
2023-04-03 22:50:03,632 - INFO - tqdm - loading instances: 20103it [01:30, 229.34it/s]
2023-04-03 22:50:13,654 - INFO - tqdm - loading instances: 22363it [01:40, 228.23it/s]
2023-04-03 22:50:23,759 - INFO - tqdm - loading instances: 24538it [01:50, 219.50it/s]
2023-04-03 22:50:33,857 - INFO - tqdm - loading instances: 26873it [02:00, 232.30it/s]
2023-04-03 22:50:43,939 - INFO - tqdm - loading instances: 29183it [02:10, 232.31it/s]
2023-04-03 22:50:53,966 - INFO - tqdm - loading instances: 31268it [02:20, 226.18it/s]
2023-04-03 22:51:04,043 - INFO - tqdm - loading instances: 33561it [02:30, 229.78it/s]
2023-04-03 22:51:14,119 - INFO - tqdm - loading instances: 35859it [02:41, 230.55it/s]
2023-04-03 22:51:24,131 - INFO - tqdm - loading instances: 38165it [02:51, 232.89it/s]
2023-04-03 22:51:34,213 - INFO - tqdm - loading instances: 40249it [03:01, 202.77it/s]
2023-04-03 22:51:44,289 - INFO - tqdm - loading instances: 42579it [03:11, 228.65it/s]
2023-04-03 22:51:54,334 - INFO - tqdm - loading instances: 44885it [03:21, 230.04it/s]
2023-04-03 22:52:04,377 - INFO - tqdm - loading instances: 47219it [03:31, 236.80it/s]
2023-04-03 22:52:14,452 - INFO - tqdm - loading instances: 49547it [03:41, 232.22it/s]
2023-04-03 22:52:24,491 - INFO - tqdm - loading instances: 51565it [03:51, 138.67it/s]
2023-04-03 22:52:34,546 - INFO - tqdm - loading instances: 53910it [04:01, 233.79it/s]
2023-04-03 22:52:44,556 - INFO - tqdm - loading instances: 56209it [04:11, 217.57it/s]
2023-04-03 22:52:54,640 - INFO - tqdm - loading instances: 58529it [04:21, 234.20it/s]
2023-04-03 22:53:04,712 - INFO - tqdm - loading instances: 60868it [04:31, 231.17it/s]
2023-04-03 22:53:14,732 - INFO - tqdm - loading instances: 63095it [04:41, 236.33it/s]
2023-04-03 22:53:24,806 - INFO - tqdm - loading instances: 65435it [04:51, 233.17it/s]
2023-04-03 22:53:34,844 - INFO - tqdm - loading instances: 67356it [05:01, 224.55it/s]
2023-04-03 22:53:44,918 - INFO - tqdm - loading instances: 69670it [05:11, 232.89it/s]
2023-04-03 22:53:54,927 - INFO - tqdm - loading instances: 71979it [05:21, 228.68it/s]
2023-04-03 22:54:04,983 - INFO - tqdm - loading instances: 74312it [05:31, 237.21it/s]
2023-04-03 22:54:15,013 - INFO - tqdm - loading instances: 76569it [05:41, 232.59it/s]
2023-04-03 22:54:25,069 - INFO - tqdm - loading instances: 78908it [05:51, 231.97it/s]
2023-04-03 22:54:35,163 - INFO - tqdm - loading instances: 81247it [06:02, 230.96it/s]
2023-04-03 22:54:45,244 - INFO - tqdm - loading instances: 83111it [06:12, 76.59it/s]
2023-04-03 22:54:55,289 - INFO - tqdm - loading instances: 85440it [06:22, 222.53it/s]
2023-04-03 22:55:05,345 - INFO - tqdm - loading instances: 87775it [06:32, 238.10it/s]
2023-04-03 22:55:15,345 - INFO - tqdm - loading instances: 90093it [06:42, 230.31it/s]
2023-04-03 22:55:25,361 - INFO - tqdm - loading instances: 92339it [06:52, 230.60it/s]
2023-04-03 22:55:35,453 - INFO - tqdm - loading instances: 94655it [07:02, 229.08it/s]
2023-04-03 22:55:45,525 - INFO - tqdm - loading instances: 96971it [07:12, 232.91it/s]
2023-04-03 22:55:55,619 - INFO - tqdm - loading instances: 99298it [07:22, 227.54it/s]
2023-04-03 22:56:05,620 - INFO - tqdm - loading instances: 101610it [07:32, 227.95it/s]
2023-04-03 22:56:15,692 - INFO - tqdm - loading instances: 103923it [07:42, 219.35it/s]
2023-04-03 22:56:25,732 - INFO - tqdm - loading instances: 105617it [07:52, 230.27it/s]
2023-04-03 22:56:35,742 - INFO - tqdm - loading instances: 107938it [08:02, 227.74it/s]
2023-04-03 22:56:45,746 - INFO - tqdm - loading instances: 110242it [08:12, 227.12it/s]
2023-04-03 22:56:55,816 - INFO - tqdm - loading instances: 112573it [08:22, 232.13it/s]
2023-04-03 22:57:05,898 - INFO - tqdm - loading instances: 114902it [08:32, 231.61it/s]
2023-04-03 22:57:15,965 - INFO - tqdm - loading instances: 117218it [08:42, 219.52it/s]
2023-04-03 22:57:25,993 - INFO - tqdm - loading instances: 119477it [08:52, 202.69it/s]
2023-04-03 22:57:36,065 - INFO - tqdm - loading instances: 121794it [09:02, 225.64it/s]
2023-04-03 22:57:46,135 - INFO - tqdm - loading instances: 124125it [09:13, 227.58it/s]
2023-04-03 22:57:56,150 - INFO - tqdm - loading instances: 126431it [09:23, 224.83it/s]
2023-04-03 22:58:06,218 - INFO - tqdm - loading instances: 128733it [09:33, 227.68it/s]
2023-04-03 22:58:17,869 - INFO - tqdm - loading instances: 130617it [09:44, 20.68it/s]
2023-04-03 22:58:27,949 - INFO - tqdm - loading instances: 132938it [09:54, 235.73it/s]
2023-04-03 22:58:37,964 - INFO - tqdm - loading instances: 135194it [10:04, 234.19it/s]
2023-04-03 22:58:48,034 - INFO - tqdm - loading instances: 137502it [10:14, 226.53it/s]
2023-04-03 22:58:58,107 - INFO - tqdm - loading instances: 139822it [10:25, 230.94it/s]
2023-04-03 22:59:08,165 - INFO - tqdm - loading instances: 142151it [10:35, 231.27it/s]
2023-04-03 22:59:18,238 - INFO - tqdm - loading instances: 144467it [10:45, 236.26it/s]
2023-04-03 22:59:28,309 - INFO - tqdm - loading instances: 146780it [10:55, 223.89it/s]
2023-04-03 22:59:38,355 - INFO - tqdm - loading instances: 149055it [11:05, 227.97it/s]
2023-04-03 22:59:48,409 - INFO - tqdm - loading instances: 151386it [11:15, 231.63it/s]
2023-04-03 22:59:58,478 - INFO - tqdm - loading instances: 153723it [11:25, 234.05it/s]
2023-04-03 23:00:08,546 - INFO - tqdm - loading instances: 156055it [11:35, 226.29it/s]
2023-04-03 23:00:18,616 - INFO - tqdm - loading instances: 158393it [11:45, 230.93it/s]
2023-04-03 23:00:28,667 - INFO - tqdm - loading instances: 160674it [11:55, 233.09it/s]
2023-04-03 23:00:38,741 - INFO - tqdm - loading instances: 163005it [12:05, 229.20it/s]
2023-04-03 23:00:48,829 - INFO - tqdm - loading instances: 164340it [12:15, 240.27it/s]
2023-04-03 23:00:58,914 - INFO - tqdm - loading instances: 166680it [12:25, 227.55it/s]
2023-04-03 23:01:08,986 - INFO - tqdm - loading instances: 169000it [12:35, 229.91it/s]
2023-04-03 23:01:19,049 - INFO - tqdm - loading instances: 171312it [12:45, 227.64it/s]
2023-04-03 23:01:29,056 - INFO - tqdm - loading instances: 173599it [12:55, 223.64it/s]
2023-04-03 23:01:39,119 - INFO - tqdm - loading instances: 175942it [13:06, 228.29it/s]
2023-04-03 23:01:49,179 - INFO - tqdm - loading instances: 178274it [13:16, 233.31it/s]
2023-04-03 23:01:59,193 - INFO - tqdm - loading instances: 180582it [13:26, 231.27it/s]
2023-04-03 23:02:09,290 - INFO - tqdm - loading instances: 182902it [13:36, 223.10it/s]
2023-04-03 23:02:19,338 - INFO - tqdm - loading instances: 185222it [13:46, 227.10it/s]
2023-04-03 23:02:29,379 - INFO - tqdm - loading instances: 187539it [13:56, 234.66it/s]
2023-04-03 23:02:39,429 - INFO - tqdm - loading instances: 189856it [14:06, 232.57it/s]
2023-04-03 23:02:49,463 - INFO - tqdm - loading instances: 192124it [14:16, 229.26it/s]
2023-04-03 23:02:59,525 - INFO - tqdm - loading instances: 194428it [14:26, 220.14it/s]
2023-04-03 23:03:09,601 - INFO - tqdm - loading instances: 196744it [14:36, 227.12it/s]
2023-04-03 23:03:19,647 - INFO - tqdm - loading instances: 199048it [14:46, 237.22it/s]
2023-04-03 23:03:29,741 - INFO - tqdm - loading instances: 201365it [14:56, 229.75it/s]
2023-04-03 23:03:44,154 - INFO - tqdm - loading instances: 203347it [15:11, 13.09it/s]
2023-04-03 23:03:54,245 - INFO - tqdm - loading instances: 205648it [15:21, 226.46it/s]
2023-04-03 23:04:04,342 - INFO - tqdm - loading instances: 207968it [15:31, 229.56it/s]
2023-04-03 23:04:14,430 - INFO - tqdm - loading instances: 210306it [15:41, 224.69it/s]
2023-04-03 23:04:24,502 - INFO - tqdm - loading instances: 212613it [15:51, 227.17it/s]
2023-04-03 23:04:34,547 - INFO - tqdm - loading instances: 214930it [16:01, 231.56it/s]
2023-04-03 23:04:44,613 - INFO - tqdm - loading instances: 217266it [16:11, 230.34it/s]
2023-04-03 23:04:54,695 - INFO - tqdm - loading instances: 219612it [16:21, 231.07it/s]
2023-04-03 23:05:04,793 - INFO - tqdm - loading instances: 221934it [16:31, 228.06it/s]
2023-04-03 23:05:14,854 - INFO - tqdm - loading instances: 224262it [16:41, 233.23it/s]
2023-04-03 23:05:24,937 - INFO - tqdm - loading instances: 226582it [16:51, 231.72it/s]
2023-04-03 23:05:35,024 - INFO - tqdm - loading instances: 228913it [17:01, 232.27it/s]
2023-04-03 23:05:45,087 - INFO - tqdm - loading instances: 231230it [17:11, 231.46it/s]
2023-04-03 23:05:55,131 - INFO - tqdm - loading instances: 233518it [17:22, 223.90it/s]
2023-04-03 23:06:05,197 - INFO - tqdm - loading instances: 235820it [17:32, 229.92it/s]
2023-04-03 23:06:15,202 - INFO - tqdm - loading instances: 238100it [17:42, 226.06it/s]
2023-04-03 23:06:25,254 - INFO - tqdm - loading instances: 240429it [17:52, 233.05it/s]
2023-04-03 23:06:35,320 - INFO - tqdm - loading instances: 242754it [18:02, 233.44it/s]
2023-04-03 23:06:45,396 - INFO - tqdm - loading instances: 245071it [18:12, 232.14it/s]
2023-04-03 23:06:55,460 - INFO - tqdm - loading instances: 247406it [18:22, 235.07it/s]
2023-04-03 23:07:05,530 - INFO - tqdm - loading instances: 249744it [18:32, 226.57it/s]
2023-04-03 23:07:15,549 - INFO - tqdm - loading instances: 251988it [18:42, 230.88it/s]
2023-04-03 23:07:26,874 - INFO - tqdm - loading instances: 252843it [18:53, 10.08it/s]
2023-04-03 23:07:36,925 - INFO - tqdm - loading instances: 255160it [19:03, 239.10it/s]
2023-04-03 23:07:47,021 - INFO - tqdm - loading instances: 257487it [19:13, 228.70it/s]
2023-04-03 23:07:57,083 - INFO - tqdm - loading instances: 259813it [19:23, 228.73it/s]
2023-04-03 23:08:07,144 - INFO - tqdm - loading instances: 262132it [19:34, 232.88it/s]
2023-04-03 23:08:17,168 - INFO - tqdm - loading instances: 264354it [19:44, 231.70it/s]
2023-04-03 23:08:27,237 - INFO - tqdm - loading instances: 266686it [19:54, 232.30it/s]
2023-04-03 23:08:37,287 - INFO - tqdm - loading instances: 269013it [20:04, 224.31it/s]
2023-04-03 23:08:47,343 - INFO - tqdm - loading instances: 271332it [20:14, 231.75it/s]
2023-04-03 23:08:57,408 - INFO - tqdm - loading instances: 273624it [20:24, 224.07it/s]
2023-04-03 23:09:07,482 - INFO - tqdm - loading instances: 275953it [20:34, 214.90it/s]
2023-04-03 23:09:17,556 - INFO - tqdm - loading instances: 278240it [20:44, 222.94it/s]
2023-04-03 23:09:27,634 - INFO - tqdm - loading instances: 280540it [20:54, 226.77it/s]
2023-04-03 23:09:37,721 - INFO - tqdm - loading instances: 282884it [21:04, 233.08it/s]
2023-04-03 23:09:47,806 - INFO - tqdm - loading instances: 285204it [21:14, 225.27it/s]
2023-04-03 23:09:57,879 - INFO - tqdm - loading instances: 287514it [21:24, 231.01it/s]
2023-04-03 23:10:07,950 - INFO - tqdm - loading instances: 289844it [21:34, 228.91it/s]
2023-04-03 23:10:18,005 - INFO - tqdm - loading instances: 292146it [21:44, 229.18it/s]
2023-04-03 23:10:28,076 - INFO - tqdm - loading instances: 294471it [21:54, 236.55it/s]
2023-04-03 23:10:38,124 - INFO - tqdm - loading instances: 296787it [22:05, 227.78it/s]
2023-04-03 23:10:48,192 - INFO - tqdm - loading instances: 299097it [22:15, 234.33it/s]
2023-04-03 23:10:58,272 - INFO - tqdm - loading instances: 301425it [22:25, 228.77it/s]
2023-04-03 23:11:08,308 - INFO - tqdm - loading instances: 303745it [22:35, 228.71it/s]
2023-04-03 23:11:18,355 - INFO - tqdm - loading instances: 306057it [22:45, 235.77it/s]
2023-04-03 23:11:28,446 - INFO - tqdm - loading instances: 308290it [22:55, 233.32it/s]
2023-04-03 23:11:38,522 - INFO - tqdm - loading instances: 310611it [23:05, 232.41it/s]
2023-04-03 23:11:48,618 - INFO - tqdm - loading instances: 312927it [23:15, 229.17it/s]
2023-04-03 23:12:01,088 - INFO - tqdm - loading instances: 313616it [23:27,  8.12it/s]
2023-04-03 23:12:11,152 - INFO - tqdm - loading instances: 315915it [23:38, 226.62it/s]
2023-04-03 23:12:21,211 - INFO - tqdm - loading instances: 318245it [23:48, 230.40it/s]
2023-04-03 23:12:31,293 - INFO - tqdm - loading instances: 320559it [23:58, 227.28it/s]
2023-04-03 23:12:41,335 - INFO - tqdm - loading instances: 322879it [24:08, 235.32it/s]
2023-04-03 23:12:51,419 - INFO - tqdm - loading instances: 325183it [24:18, 222.93it/s]
2023-04-03 23:13:01,453 - INFO - tqdm - loading instances: 327509it [24:28, 230.33it/s]
2023-04-03 23:13:11,459 - INFO - tqdm - loading instances: 329812it [24:38, 224.69it/s]
2023-04-03 23:13:21,504 - INFO - tqdm - loading instances: 332115it [24:48, 228.35it/s]
2023-04-03 23:13:31,536 - INFO - tqdm - loading instances: 334407it [24:58, 227.99it/s]
2023-04-03 23:13:41,558 - INFO - tqdm - loading instances: 336708it [25:08, 233.45it/s]
2023-04-03 23:13:51,647 - INFO - tqdm - loading instances: 339019it [25:18, 220.11it/s]
2023-04-03 23:14:01,706 - INFO - tqdm - loading instances: 341338it [25:28, 229.26it/s]
2023-04-03 23:14:11,751 - INFO - tqdm - loading instances: 343632it [25:38, 218.10it/s]
2023-04-03 23:14:21,752 - INFO - tqdm - loading instances: 345944it [25:48, 225.12it/s]
2023-04-03 23:14:31,804 - INFO - tqdm - loading instances: 348233it [25:58, 230.10it/s]
2023-04-03 23:14:41,868 - INFO - tqdm - loading instances: 350543it [26:08, 227.72it/s]
2023-04-03 23:14:51,902 - INFO - tqdm - loading instances: 352861it [26:18, 231.59it/s]
2023-04-03 23:15:01,950 - INFO - tqdm - loading instances: 355156it [26:28, 222.24it/s]
2023-04-03 23:15:12,010 - INFO - tqdm - loading instances: 357493it [26:38, 226.76it/s]
2023-04-03 23:15:22,080 - INFO - tqdm - loading instances: 359798it [26:48, 230.46it/s]
2023-04-03 23:15:32,142 - INFO - tqdm - loading instances: 362105it [26:59, 235.62it/s]
2023-04-03 23:15:42,230 - INFO - tqdm - loading instances: 364439it [27:09, 227.24it/s]
2023-04-03 23:15:52,311 - INFO - tqdm - loading instances: 366757it [27:19, 229.30it/s]
2023-04-03 23:16:02,345 - INFO - tqdm - loading instances: 369104it [27:29, 239.18it/s]
2023-04-03 23:16:12,408 - INFO - tqdm - loading instances: 371427it [27:39, 231.65it/s]
2023-04-03 23:16:22,473 - INFO - tqdm - loading instances: 373755it [27:49, 237.68it/s]
2023-04-03 23:16:32,535 - INFO - tqdm - loading instances: 376067it [27:59, 238.12it/s]
2023-04-03 23:16:42,550 - INFO - tqdm - loading instances: 378302it [28:09, 226.09it/s]
2023-04-03 23:16:52,558 - INFO - tqdm - loading instances: 380543it [28:19, 229.28it/s]
2023-04-03 23:17:02,629 - INFO - tqdm - loading instances: 382861it [28:29, 225.87it/s]
2023-04-03 23:17:12,704 - INFO - tqdm - loading instances: 385165it [28:39, 226.76it/s]
2023-04-03 23:17:22,750 - INFO - tqdm - loading instances: 387438it [28:49, 234.84it/s]
2023-04-03 23:17:40,409 - INFO - tqdm - loading instances: 388765it [29:07,  6.34it/s]
2023-04-03 23:17:50,481 - INFO - tqdm - loading instances: 391029it [29:17, 221.71it/s]
2023-04-03 23:18:00,518 - INFO - tqdm - loading instances: 393285it [29:27, 228.44it/s]
2023-04-03 23:18:10,545 - INFO - tqdm - loading instances: 395572it [29:37, 234.52it/s]
2023-04-03 23:18:20,629 - INFO - tqdm - loading instances: 397860it [29:47, 226.37it/s]
2023-04-03 23:18:30,700 - INFO - tqdm - loading instances: 400151it [29:57, 224.58it/s]
2023-04-03 23:18:40,771 - INFO - tqdm - loading instances: 402459it [30:07, 227.45it/s]
2023-04-03 23:18:50,829 - INFO - tqdm - loading instances: 404749it [30:17, 231.43it/s]
2023-04-03 23:19:00,857 - INFO - tqdm - loading instances: 406913it [30:27, 198.28it/s]
2023-04-03 23:19:10,919 - INFO - tqdm - loading instances: 409148it [30:37, 222.90it/s]
2023-04-03 23:19:20,992 - INFO - tqdm - loading instances: 411457it [30:47, 228.93it/s]
2023-04-03 23:19:31,048 - INFO - tqdm - loading instances: 413749it [30:57, 229.66it/s]
2023-04-03 23:19:41,108 - INFO - tqdm - loading instances: 416024it [31:08, 226.58it/s]
2023-04-03 23:19:51,159 - INFO - tqdm - loading instances: 418321it [31:18, 231.83it/s]
2023-04-03 23:20:01,172 - INFO - tqdm - loading instances: 420574it [31:28, 223.02it/s]
2023-04-03 23:20:11,229 - INFO - tqdm - loading instances: 422858it [31:38, 227.57it/s]
2023-04-03 23:20:21,263 - INFO - tqdm - loading instances: 425115it [31:48, 227.17it/s]
2023-04-03 23:20:31,284 - INFO - tqdm - loading instances: 427362it [31:58, 225.55it/s]
2023-04-03 23:20:41,338 - INFO - tqdm - loading instances: 429652it [32:08, 220.95it/s]
2023-04-03 23:20:51,392 - INFO - tqdm - loading instances: 431934it [32:18, 227.47it/s]
2023-04-03 23:21:01,469 - INFO - tqdm - loading instances: 434149it [32:28, 228.55it/s]
2023-04-03 23:21:11,538 - INFO - tqdm - loading instances: 436452it [32:38, 232.85it/s]
2023-04-03 23:21:21,612 - INFO - tqdm - loading instances: 438761it [32:48, 230.77it/s]
2023-04-03 23:21:31,684 - INFO - tqdm - loading instances: 441060it [32:58, 225.67it/s]
2023-04-03 23:21:41,733 - INFO - tqdm - loading instances: 443341it [33:08, 221.86it/s]
2023-04-03 23:21:51,801 - INFO - tqdm - loading instances: 445635it [33:18, 228.10it/s]
2023-04-03 23:22:01,847 - INFO - tqdm - loading instances: 447946it [33:28, 231.50it/s]
2023-04-03 23:22:11,894 - INFO - tqdm - loading instances: 450216it [33:38, 225.34it/s]
2023-04-03 23:22:21,954 - INFO - tqdm - loading instances: 452484it [33:48, 234.55it/s]
2023-04-03 23:22:32,025 - INFO - tqdm - loading instances: 454772it [33:58, 227.82it/s]
2023-04-03 23:22:42,075 - INFO - tqdm - loading instances: 457061it [34:08, 226.00it/s]
2023-04-03 23:22:52,115 - INFO - tqdm - loading instances: 459361it [34:19, 234.96it/s]
2023-04-03 23:23:02,166 - INFO - tqdm - loading instances: 461662it [34:29, 233.99it/s]
2023-04-03 23:23:12,221 - INFO - tqdm - loading instances: 463966it [34:39, 226.59it/s]
2023-04-03 23:23:22,224 - INFO - tqdm - loading instances: 466180it [34:49, 232.66it/s]
2023-04-03 23:23:32,274 - INFO - tqdm - loading instances: 468482it [34:59, 222.81it/s]
2023-04-03 23:23:42,325 - INFO - tqdm - loading instances: 470778it [35:09, 226.55it/s]
2023-04-03 23:23:52,400 - INFO - tqdm - loading instances: 473080it [35:19, 230.11it/s]
2023-04-03 23:24:02,448 - INFO - tqdm - loading instances: 475374it [35:29, 233.49it/s]
2023-04-03 23:24:12,525 - INFO - tqdm - loading instances: 477690it [35:39, 231.36it/s]
2023-04-03 23:24:22,611 - INFO - tqdm - loading instances: 479984it [35:49, 226.76it/s]
2023-04-03 23:24:43,798 - INFO - tqdm - loading instances: 481437it [36:10,  5.15it/s]
2023-04-03 23:24:53,813 - INFO - tqdm - loading instances: 483709it [36:20, 225.90it/s]
2023-04-03 23:25:03,861 - INFO - tqdm - loading instances: 485997it [36:30, 228.21it/s]
2023-04-03 23:25:13,911 - INFO - tqdm - loading instances: 488273it [36:40, 224.65it/s]
2023-04-03 23:25:23,985 - INFO - tqdm - loading instances: 490558it [36:50, 223.88it/s]
2023-04-03 23:25:34,076 - INFO - tqdm - loading instances: 492828it [37:00, 227.39it/s]
2023-04-03 23:25:44,124 - INFO - tqdm - loading instances: 495109it [37:11, 222.01it/s]
2023-04-03 23:25:54,166 - INFO - tqdm - loading instances: 497406it [37:21, 223.26it/s]
2023-04-03 23:26:04,196 - INFO - tqdm - loading instances: 499687it [37:31, 224.84it/s]
2023-04-03 23:26:14,254 - INFO - tqdm - loading instances: 501962it [37:41, 232.95it/s]
2023-04-03 23:26:24,315 - INFO - tqdm - loading instances: 504234it [37:51, 224.78it/s]
2023-04-03 23:26:34,388 - INFO - tqdm - loading instances: 506505it [38:01, 224.87it/s]
2023-04-03 23:26:44,466 - INFO - tqdm - loading instances: 508813it [38:11, 230.01it/s]
2023-04-03 23:26:54,546 - INFO - tqdm - loading instances: 511098it [38:21, 222.06it/s]
2023-04-03 23:27:04,594 - INFO - tqdm - loading instances: 513400it [38:31, 227.65it/s]
2023-04-03 23:27:14,656 - INFO - tqdm - loading instances: 515675it [38:41, 228.78it/s]
2023-04-03 23:27:24,717 - INFO - tqdm - loading instances: 517928it [38:51, 224.58it/s]
2023-04-03 23:27:34,785 - INFO - tqdm - loading instances: 520219it [39:01, 224.24it/s]
2023-04-03 23:27:44,826 - INFO - tqdm - loading instances: 522502it [39:11, 223.05it/s]
2023-04-03 23:27:54,842 - INFO - tqdm - loading instances: 524780it [39:21, 225.95it/s]
2023-04-03 23:28:04,922 - INFO - tqdm - loading instances: 527066it [39:31, 223.60it/s]
2023-04-03 23:28:14,974 - INFO - tqdm - loading instances: 529360it [39:41, 226.36it/s]
2023-04-03 23:28:25,036 - INFO - tqdm - loading instances: 531661it [39:51, 227.34it/s]
2023-04-03 23:28:35,041 - INFO - tqdm - loading instances: 533858it [40:01, 229.56it/s]
2023-04-03 23:28:45,065 - INFO - tqdm - loading instances: 536070it [40:11, 224.38it/s]
2023-04-03 23:28:55,103 - INFO - tqdm - loading instances: 538340it [40:22, 228.82it/s]
2023-04-03 23:29:05,186 - INFO - tqdm - loading instances: 540625it [40:32, 224.03it/s]
2023-04-03 23:29:15,241 - INFO - tqdm - loading instances: 542893it [40:42, 227.97it/s]
2023-04-03 23:29:25,253 - INFO - tqdm - loading instances: 545179it [40:52, 228.85it/s]
2023-04-03 23:29:35,298 - INFO - tqdm - loading instances: 547453it [41:02, 229.26it/s]
2023-04-03 23:29:43,280 - INFO - allennlp.common.params - data_loader.type = multiprocess
2023-04-03 23:29:43,281 - INFO - allennlp.common.params - data_loader.batch_size = None
2023-04-03 23:29:43,282 - INFO - allennlp.common.params - data_loader.drop_last = False
2023-04-03 23:29:43,283 - INFO - allennlp.common.params - data_loader.shuffle = False
2023-04-03 23:29:43,284 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2023-04-03 23:29:43,284 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 64
2023-04-03 23:29:43,285 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2023-04-03 23:29:43,286 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2023-04-03 23:29:43,286 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2023-04-03 23:29:43,287 - INFO - allennlp.common.params - data_loader.batch_sampler.shuffle = True
2023-04-03 23:29:43,288 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2023-04-03 23:29:43,288 - INFO - allennlp.common.params - data_loader.num_workers = 0
2023-04-03 23:29:43,289 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2023-04-03 23:29:43,290 - INFO - allennlp.common.params - data_loader.start_method = fork
2023-04-03 23:29:43,290 - INFO - allennlp.common.params - data_loader.cuda_device = None
2023-04-03 23:29:43,291 - INFO - allennlp.common.params - data_loader.quiet = False
2023-04-03 23:29:43,292 - INFO - allennlp.common.params - data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x7f56e02a65e0>
2023-04-03 23:29:43,293 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2023-04-03 23:29:53,380 - INFO - tqdm - loading instances: 2261it [00:10, 227.32it/s]
2023-04-03 23:30:03,438 - INFO - tqdm - loading instances: 4510it [00:20, 220.22it/s]
2023-04-03 23:30:13,447 - INFO - tqdm - loading instances: 6775it [00:30, 222.60it/s]
2023-04-03 23:30:23,471 - INFO - tqdm - loading instances: 9039it [00:40, 223.18it/s]
2023-04-03 23:30:27,053 - INFO - allennlp.common.params - data_loader.type = multiprocess
2023-04-03 23:30:27,055 - INFO - allennlp.common.params - data_loader.batch_size = None
2023-04-03 23:30:27,055 - INFO - allennlp.common.params - data_loader.drop_last = False
2023-04-03 23:30:27,056 - INFO - allennlp.common.params - data_loader.shuffle = False
2023-04-03 23:30:27,057 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2023-04-03 23:30:27,057 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 64
2023-04-03 23:30:27,058 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2023-04-03 23:30:27,058 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2023-04-03 23:30:27,059 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2023-04-03 23:30:27,059 - INFO - allennlp.common.params - data_loader.batch_sampler.shuffle = True
2023-04-03 23:30:27,060 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2023-04-03 23:30:27,061 - INFO - allennlp.common.params - data_loader.num_workers = 0
2023-04-03 23:30:27,061 - INFO - allennlp.common.params - data_loader.max_instances_in_memory = None
2023-04-03 23:30:27,062 - INFO - allennlp.common.params - data_loader.start_method = fork
2023-04-03 23:30:27,062 - INFO - allennlp.common.params - data_loader.cuda_device = None
2023-04-03 23:30:27,063 - INFO - allennlp.common.params - data_loader.quiet = False
2023-04-03 23:30:27,063 - INFO - allennlp.common.params - data_loader.collate_fn = <allennlp.data.data_loaders.data_collator.DefaultDataCollator object at 0x7f56e02a65e0>
2023-04-03 23:30:27,064 - INFO - tqdm - loading instances: 0it [00:00, ?it/s]
2023-04-03 23:30:37,095 - INFO - tqdm - loading instances: 2242it [00:10, 222.50it/s]
2023-04-03 23:30:47,131 - INFO - tqdm - loading instances: 4486it [00:20, 223.84it/s]
2023-04-03 23:30:57,220 - INFO - tqdm - loading instances: 6672it [00:30, 222.36it/s]
2023-04-03 23:31:07,246 - INFO - tqdm - loading instances: 8911it [00:40, 220.81it/s]
2023-04-03 23:31:11,305 - INFO - allennlp.common.params - type = from_instances
2023-04-03 23:31:11,306 - INFO - allennlp.common.params - min_count = None
2023-04-03 23:31:11,307 - INFO - allennlp.common.params - max_vocab_size = None
2023-04-03 23:31:11,308 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2023-04-03 23:31:11,309 - INFO - allennlp.common.params - pretrained_files = None
2023-04-03 23:31:11,309 - INFO - allennlp.common.params - only_include_pretrained_words = False
2023-04-03 23:31:11,310 - INFO - allennlp.common.params - tokens_to_add = None
2023-04-03 23:31:11,311 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2023-04-03 23:31:11,311 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2023-04-03 23:31:11,312 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2023-04-03 23:31:11,313 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2023-04-03 23:31:11,313 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2023-04-03 23:31:21,327 - INFO - tqdm - building vocab: 509152it [00:10, 49140.57it/s]
2023-04-03 23:31:22,581 - INFO - allennlp.common.params - model.type = esim
2023-04-03 23:31:22,583 - INFO - allennlp.common.params - model.regularizer = None
2023-04-03 23:31:22,584 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2023-04-03 23:31:22,585 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding
2023-04-03 23:31:22,586 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 300
2023-04-03 23:31:22,586 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None
2023-04-03 23:31:22,587 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = None
2023-04-03 23:31:22,588 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.weight = None
2023-04-03 23:31:22,588 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None
2023-04-03 23:31:22,589 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = True
2023-04-03 23:31:22,590 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None
2023-04-03 23:31:22,590 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0
2023-04-03 23:31:22,591 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False
2023-04-03 23:31:22,591 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False
2023-04-03 23:31:22,592 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens
2023-04-03 23:31:22,593 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = https://allennlp.s3.amazonaws.com/datasets/glove/glove.840B.300d.txt.gz
2023-04-03 23:31:22,596 - INFO - allennlp.modules.token_embedders.embedding - Reading pretrained embeddings from file
2023-04-03 23:31:23,707 - INFO - cached_path - cache of https://allennlp.s3.amazonaws.com/datasets/glove/glove.840B.300d.txt.gz is up-to-date
2023-04-03 23:31:23,727 - INFO - tqdm - 0it [00:00, ?it/s]
2023-04-03 23:31:33,791 - INFO - tqdm - 503726it [00:10, 59576.71it/s]
2023-04-03 23:31:43,796 - INFO - tqdm - 1105761it [00:20, 60521.84it/s]
2023-04-03 23:31:53,798 - INFO - tqdm - 1709426it [00:30, 60248.60it/s]
2023-04-03 23:32:01,986 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer
2023-04-03 23:32:02,574 - INFO - allennlp.modules.token_embedders.embedding - Pretrained embeddings were found for 30769 out of 34150 tokens
2023-04-03 23:32:02,594 - INFO - allennlp.common.params - model.encoder.type = lstm
2023-04-03 23:32:02,596 - INFO - allennlp.common.params - model.encoder.input_size = 300
2023-04-03 23:32:02,597 - INFO - allennlp.common.params - model.encoder.hidden_size = 300
2023-04-03 23:32:02,598 - INFO - allennlp.common.params - model.encoder.num_layers = 1
2023-04-03 23:32:02,599 - INFO - allennlp.common.params - model.encoder.bias = True
2023-04-03 23:32:02,600 - INFO - allennlp.common.params - model.encoder.dropout = 0.0
2023-04-03 23:32:02,601 - INFO - allennlp.common.params - model.encoder.bidirectional = True
2023-04-03 23:32:02,601 - INFO - allennlp.common.params - model.encoder.stateful = False
2023-04-03 23:32:02,617 - INFO - allennlp.common.params - model.matrix_attention.type = dot_product
2023-04-03 23:32:02,618 - INFO - allennlp.common.params - model.projection_feedforward.input_dim = 2400
2023-04-03 23:32:02,619 - INFO - allennlp.common.params - model.projection_feedforward.num_layers = 1
2023-04-03 23:32:02,620 - INFO - allennlp.common.params - model.projection_feedforward.hidden_dims = 300
2023-04-03 23:32:02,621 - INFO - allennlp.common.params - model.projection_feedforward.activations = relu
2023-04-03 23:32:02,622 - INFO - allennlp.common.params - type = relu
2023-04-03 23:32:02,623 - INFO - allennlp.common.params - model.projection_feedforward.dropout = 0.0
2023-04-03 23:32:02,630 - INFO - allennlp.common.params - model.inference_encoder.type = lstm
2023-04-03 23:32:02,631 - INFO - allennlp.common.params - model.inference_encoder.input_size = 300
2023-04-03 23:32:02,632 - INFO - allennlp.common.params - model.inference_encoder.hidden_size = 300
2023-04-03 23:32:02,632 - INFO - allennlp.common.params - model.inference_encoder.num_layers = 1
2023-04-03 23:32:02,633 - INFO - allennlp.common.params - model.inference_encoder.bias = True
2023-04-03 23:32:02,634 - INFO - allennlp.common.params - model.inference_encoder.dropout = 0.0
2023-04-03 23:32:02,635 - INFO - allennlp.common.params - model.inference_encoder.bidirectional = True
2023-04-03 23:32:02,635 - INFO - allennlp.common.params - model.inference_encoder.stateful = False
2023-04-03 23:32:02,647 - INFO - allennlp.common.params - model.output_feedforward.input_dim = 2400
2023-04-03 23:32:02,648 - INFO - allennlp.common.params - model.output_feedforward.num_layers = 1
2023-04-03 23:32:02,649 - INFO - allennlp.common.params - model.output_feedforward.hidden_dims = 300
2023-04-03 23:32:02,649 - INFO - allennlp.common.params - model.output_feedforward.activations = relu
2023-04-03 23:32:02,650 - INFO - allennlp.common.params - type = relu
2023-04-03 23:32:02,651 - INFO - allennlp.common.params - model.output_feedforward.dropout = 0.5
2023-04-03 23:32:02,657 - INFO - allennlp.common.params - model.output_logit.input_dim = 300
2023-04-03 23:32:02,658 - INFO - allennlp.common.params - model.output_logit.num_layers = 1
2023-04-03 23:32:02,659 - INFO - allennlp.common.params - model.output_logit.hidden_dims = 3
2023-04-03 23:32:02,660 - INFO - allennlp.common.params - model.output_logit.activations = linear
2023-04-03 23:32:02,660 - INFO - allennlp.common.params - type = linear
2023-04-03 23:32:02,661 - INFO - allennlp.common.params - model.output_logit.dropout = 0.0
2023-04-03 23:32:02,663 - INFO - allennlp.common.params - model.dropout = 0.5
2023-04-03 23:32:02,664 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_uniform
2023-04-03 23:32:02,665 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0
2023-04-03 23:32:02,666 - INFO - allennlp.common.params - model.initializer.regexes.1.1.type = zero
2023-04-03 23:32:02,667 - INFO - allennlp.common.params - model.initializer.regexes.2.1.type = xavier_uniform
2023-04-03 23:32:02,667 - INFO - allennlp.common.params - model.initializer.regexes.2.1.gain = 1.0
2023-04-03 23:32:02,668 - INFO - allennlp.common.params - model.initializer.regexes.3.1.type = orthogonal
2023-04-03 23:32:02,669 - INFO - allennlp.common.params - model.initializer.regexes.3.1.gain = 1.0
2023-04-03 23:32:02,670 - INFO - allennlp.common.params - model.initializer.regexes.4.1.type = zero
2023-04-03 23:32:02,671 - INFO - allennlp.common.params - model.initializer.regexes.5.1.type = lstm_hidden_bias
2023-04-03 23:32:02,671 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None
2023-04-03 23:32:02,672 - INFO - allennlp.nn.initializers - Initializing parameters
2023-04-03 23:32:02,674 - INFO - allennlp.nn.initializers - Initializing _encoder._module.weight_ih_l0 using .*weight_ih.* initializer
2023-04-03 23:32:02,677 - INFO - allennlp.nn.initializers - Initializing _encoder._module.weight_hh_l0 using .*weight_hh.* initializer
2023-04-03 23:32:02,812 - INFO - allennlp.nn.initializers - Initializing _encoder._module.bias_ih_l0 using .*bias_ih.* initializer
2023-04-03 23:32:02,813 - INFO - allennlp.nn.initializers - Initializing _encoder._module.bias_hh_l0 using .*bias_hh.* initializer
2023-04-03 23:32:02,815 - INFO - allennlp.nn.initializers - Initializing _encoder._module.weight_ih_l0_reverse using .*weight_ih.* initializer
2023-04-03 23:32:02,819 - INFO - allennlp.nn.initializers - Initializing _encoder._module.weight_hh_l0_reverse using .*weight_hh.* initializer
2023-04-03 23:32:02,834 - INFO - allennlp.nn.initializers - Initializing _encoder._module.bias_ih_l0_reverse using .*bias_ih.* initializer
2023-04-03 23:32:02,835 - INFO - allennlp.nn.initializers - Initializing _encoder._module.bias_hh_l0_reverse using .*bias_hh.* initializer
2023-04-03 23:32:02,836 - INFO - allennlp.nn.initializers - Initializing _projection_feedforward._linear_layers.0.weight using .*linear_layers.*weight initializer
2023-04-03 23:32:02,842 - INFO - allennlp.nn.initializers - Initializing _projection_feedforward._linear_layers.0.bias using .*linear_layers.*bias initializer
2023-04-03 23:32:02,843 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.weight_ih_l0 using .*weight_ih.* initializer
2023-04-03 23:32:02,846 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.weight_hh_l0 using .*weight_hh.* initializer
2023-04-03 23:32:02,862 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.bias_ih_l0 using .*bias_ih.* initializer
2023-04-03 23:32:02,863 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.bias_hh_l0 using .*bias_hh.* initializer
2023-04-03 23:32:02,863 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.weight_ih_l0_reverse using .*weight_ih.* initializer
2023-04-03 23:32:02,867 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.weight_hh_l0_reverse using .*weight_hh.* initializer
2023-04-03 23:32:02,882 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.bias_ih_l0_reverse using .*bias_ih.* initializer
2023-04-03 23:32:02,883 - INFO - allennlp.nn.initializers - Initializing _inference_encoder._module.bias_hh_l0_reverse using .*bias_hh.* initializer
2023-04-03 23:32:02,883 - INFO - allennlp.nn.initializers - Initializing _output_feedforward._linear_layers.0.weight using .*linear_layers.*weight initializer
2023-04-03 23:32:02,891 - INFO - allennlp.nn.initializers - Initializing _output_feedforward._linear_layers.0.bias using .*linear_layers.*bias initializer
2023-04-03 23:32:02,892 - INFO - allennlp.nn.initializers - Initializing _output_logit._linear_layers.0.weight using .*linear_layers.*weight initializer
2023-04-03 23:32:02,893 - INFO - allennlp.nn.initializers - Initializing _output_logit._linear_layers.0.bias using .*linear_layers.*bias initializer
2023-04-03 23:32:02,893 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2023-04-03 23:32:02,894 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.weight
2023-04-03 23:32:34,772 - INFO - allennlp.common.params - trainer.type = gradient_descent
2023-04-03 23:32:34,774 - INFO - allennlp.common.params - trainer.cuda_device = None
2023-04-03 23:32:34,775 - INFO - allennlp.common.params - trainer.distributed = False
2023-04-03 23:32:34,776 - INFO - allennlp.common.params - trainer.world_size = 1
2023-04-03 23:32:34,777 - INFO - allennlp.common.params - trainer.patience = 5
2023-04-03 23:32:34,777 - INFO - allennlp.common.params - trainer.validation_metric = +accuracy
2023-04-03 23:32:34,778 - INFO - allennlp.common.params - trainer.num_epochs = 75
2023-04-03 23:32:34,779 - INFO - allennlp.common.params - trainer.grad_norm = 10
2023-04-03 23:32:34,780 - INFO - allennlp.common.params - trainer.grad_clipping = None
2023-04-03 23:32:34,781 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2023-04-03 23:32:34,781 - INFO - allennlp.common.params - trainer.use_amp = False
2023-04-03 23:32:34,782 - INFO - allennlp.common.params - trainer.no_grad = None
2023-04-03 23:32:34,783 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2023-04-03 23:32:34,784 - INFO - allennlp.common.params - trainer.moving_average = None
2023-04-03 23:32:34,785 - INFO - allennlp.common.params - trainer.callbacks = None
2023-04-03 23:32:34,785 - INFO - allennlp.common.params - trainer.enable_default_callbacks = True
2023-04-03 23:32:34,786 - INFO - allennlp.common.params - trainer.run_confidence_checks = True
2023-04-03 23:32:34,786 - INFO - allennlp.common.params - trainer.grad_scaling = True
2023-04-03 23:32:41,896 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2023-04-03 23:32:41,898 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2023-04-03 23:32:41,899 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0004
2023-04-03 23:32:41,899 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)
2023-04-03 23:32:41,900 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2023-04-03 23:32:41,901 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2023-04-03 23:32:41,902 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False
2023-04-03 23:32:41,902 - INFO - allennlp.training.optimizers - Number of trainable parameters: 14576103
2023-04-03 23:32:41,904 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2023-04-03 23:32:41,905 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2023-04-03 23:32:41,906 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.weight
2023-04-03 23:32:41,906 - INFO - allennlp.common.util - _encoder._module.weight_ih_l0
2023-04-03 23:32:41,907 - INFO - allennlp.common.util - _encoder._module.weight_hh_l0
2023-04-03 23:32:41,908 - INFO - allennlp.common.util - _encoder._module.bias_ih_l0
2023-04-03 23:32:41,908 - INFO - allennlp.common.util - _encoder._module.bias_hh_l0
2023-04-03 23:32:41,909 - INFO - allennlp.common.util - _encoder._module.weight_ih_l0_reverse
2023-04-03 23:32:41,909 - INFO - allennlp.common.util - _encoder._module.weight_hh_l0_reverse
2023-04-03 23:32:41,910 - INFO - allennlp.common.util - _encoder._module.bias_ih_l0_reverse
2023-04-03 23:32:41,911 - INFO - allennlp.common.util - _encoder._module.bias_hh_l0_reverse
2023-04-03 23:32:41,911 - INFO - allennlp.common.util - _projection_feedforward._linear_layers.0.weight
2023-04-03 23:32:41,912 - INFO - allennlp.common.util - _projection_feedforward._linear_layers.0.bias
2023-04-03 23:32:41,913 - INFO - allennlp.common.util - _inference_encoder._module.weight_ih_l0
2023-04-03 23:32:41,913 - INFO - allennlp.common.util - _inference_encoder._module.weight_hh_l0
2023-04-03 23:32:41,914 - INFO - allennlp.common.util - _inference_encoder._module.bias_ih_l0
2023-04-03 23:32:41,914 - INFO - allennlp.common.util - _inference_encoder._module.bias_hh_l0
2023-04-03 23:32:41,915 - INFO - allennlp.common.util - _inference_encoder._module.weight_ih_l0_reverse
2023-04-03 23:32:41,916 - INFO - allennlp.common.util - _inference_encoder._module.weight_hh_l0_reverse
2023-04-03 23:32:41,916 - INFO - allennlp.common.util - _inference_encoder._module.bias_ih_l0_reverse
2023-04-03 23:32:41,917 - INFO - allennlp.common.util - _inference_encoder._module.bias_hh_l0_reverse
2023-04-03 23:32:41,917 - INFO - allennlp.common.util - _output_feedforward._linear_layers.0.weight
2023-04-03 23:32:41,918 - INFO - allennlp.common.util - _output_feedforward._linear_layers.0.bias
2023-04-03 23:32:41,919 - INFO - allennlp.common.util - _output_logit._linear_layers.0.weight
2023-04-03 23:32:41,920 - INFO - allennlp.common.util - _output_logit._linear_layers.0.bias
2023-04-03 23:32:41,920 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = reduce_on_plateau
2023-04-03 23:32:41,921 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.mode = max
2023-04-03 23:32:41,922 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.factor = 0.5
2023-04-03 23:32:41,923 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.patience = 0
2023-04-03 23:32:41,923 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.verbose = False
2023-04-03 23:32:41,924 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold_mode = rel
2023-04-03 23:32:41,924 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold = 0.0001
2023-04-03 23:32:41,925 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cooldown = 0
2023-04-03 23:32:41,925 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.min_lr = 0
2023-04-03 23:32:41,926 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.eps = 1e-08
2023-04-03 23:32:41,927 - INFO - allennlp.common.params - trainer.checkpointer.type = default
2023-04-03 23:32:41,928 - INFO - allennlp.common.params - trainer.checkpointer.save_completed_epochs = True
2023-04-03 23:32:41,929 - INFO - allennlp.common.params - trainer.checkpointer.save_every_num_seconds = None
2023-04-03 23:32:41,929 - INFO - allennlp.common.params - trainer.checkpointer.save_every_num_batches = None
2023-04-03 23:32:41,930 - INFO - allennlp.common.params - trainer.checkpointer.keep_most_recent_by_count = 2
2023-04-03 23:32:41,933 - INFO - allennlp.common.params - trainer.checkpointer.keep_most_recent_by_age = None
2023-04-03 23:32:41,938 - INFO - allennlp.training.gradient_descent_trainer - Beginning training.
2023-04-03 23:32:41,939 - INFO - allennlp.training.gradient_descent_trainer - Epoch 0/74
2023-04-03 23:32:41,940 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.4G
2023-04-03 23:32:41,946 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 60M
2023-04-03 23:32:41,947 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-03 23:32:41,948 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-03 23:32:43,785 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2023-04-03 23:32:43,786 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['premise'] as the sorting keys
2023-04-03 23:32:47,969 - INFO - allennlp.training.callbacks.console_logger - Batch inputs
2023-04-03 23:32:47,971 - INFO - allennlp.training.callbacks.console_logger - batch_input/premise/tokens/tokens (Shape: 64 x 7)
tensor([[  14,  169,  215,  ...,   55,    3,    0],
        [  51,   15,   69,  ...,    2,  295,    0],
        [   2,  159,   26,  ...,    4,  662,    3],
        ...,
        [  51, 1148,  594,  ...,  726,    3,    0],
        [  13, 5565,   17,  ...,    2,  423,    3],
        [   2,   31, 6715,  ...,    4,  118,    3]], device='cuda:0')
2023-04-03 23:32:47,979 - INFO - allennlp.training.callbacks.console_logger - batch_input/hypothesis/tokens/tokens (Shape: 64 x 24)
tensor([[  169,   215,  2264,  ...,     0,     0,     0],
        [    4,    15,    10,  ...,     0,     0,     0],
        [    2,    26,   569,  ...,     0,     0,     0],
        ...,
        [13467,  1148,    10,  ...,     0,     0,     0],
        [    2,    31,     6,  ...,     0,     0,     0],
        [    2,    31,     6,  ...,     0,     0,     0]], device='cuda:0')
2023-04-03 23:32:47,987 - INFO - allennlp.training.callbacks.console_logger - Field : "batch_input/metadata" : (Length 64 of type "<class 'dict'>")
2023-04-03 23:32:47,988 - INFO - allennlp.training.callbacks.console_logger - batch_input/label (Shape: 64)
tensor([0, 2, 0,  ..., 2, 1, 0], device='cuda:0')
2023-04-03 23:32:52,045 - INFO - tqdm - accuracy: 0.3727, batch_loss: 1.0340, loss: 1.0943 ||:   1%|1         | 111/8583 [00:10<05:14, 26.93it/s]
2023-04-03 23:33:02,055 - INFO - tqdm - accuracy: 0.4555, batch_loss: 1.0335, loss: 1.0359 ||:   5%|4         | 406/8583 [00:20<05:23, 25.31it/s]
2023-04-03 23:33:12,143 - INFO - tqdm - accuracy: 0.4952, batch_loss: 0.8270, loss: 0.9956 ||:   8%|7         | 672/8583 [00:30<03:55, 33.62it/s]
2023-04-03 23:33:22,187 - INFO - tqdm - accuracy: 0.5245, batch_loss: 0.9763, loss: 0.9645 ||:  12%|#1        | 1005/8583 [00:40<04:40, 27.04it/s]
2023-04-03 23:33:32,208 - INFO - tqdm - accuracy: 0.5438, batch_loss: 0.6881, loss: 0.9407 ||:  15%|#4        | 1261/8583 [00:50<04:44, 25.77it/s]
2023-04-03 23:33:42,240 - INFO - tqdm - accuracy: 0.5593, batch_loss: 0.7269, loss: 0.9208 ||:  18%|#7        | 1515/8583 [01:00<05:06, 23.08it/s]
2023-04-03 23:33:52,263 - INFO - tqdm - accuracy: 0.5754, batch_loss: 0.7599, loss: 0.8981 ||:  21%|##1       | 1809/8583 [01:10<03:35, 31.36it/s]
2023-04-03 23:34:02,347 - INFO - tqdm - accuracy: 0.5892, batch_loss: 0.7089, loss: 0.8770 ||:  24%|##4       | 2087/8583 [01:20<04:07, 26.20it/s]
2023-04-03 23:34:12,435 - INFO - tqdm - accuracy: 0.6025, batch_loss: 0.6440, loss: 0.8571 ||:  28%|##7       | 2376/8583 [01:30<03:18, 31.22it/s]
2023-04-03 23:34:22,444 - INFO - tqdm - accuracy: 0.6144, batch_loss: 0.5860, loss: 0.8386 ||:  31%|###1      | 2673/8583 [01:40<03:36, 27.25it/s]
2023-04-03 23:34:32,487 - INFO - tqdm - accuracy: 0.6237, batch_loss: 0.6613, loss: 0.8242 ||:  34%|###4      | 2932/8583 [01:50<03:31, 26.66it/s]
2023-04-03 23:34:42,563 - INFO - tqdm - accuracy: 0.6344, batch_loss: 0.5535, loss: 0.8077 ||:  38%|###7      | 3245/8583 [02:00<02:36, 34.07it/s]
2023-04-03 23:34:52,656 - INFO - tqdm - accuracy: 0.6434, batch_loss: 0.5328, loss: 0.7935 ||:  41%|####1     | 3553/8583 [02:10<02:37, 31.90it/s]
2023-04-03 23:35:02,744 - INFO - tqdm - accuracy: 0.6517, batch_loss: 0.5712, loss: 0.7800 ||:  45%|####4     | 3859/8583 [02:20<03:06, 25.28it/s]
2023-04-03 23:35:12,778 - INFO - tqdm - accuracy: 0.6577, batch_loss: 0.6818, loss: 0.7693 ||:  48%|####8     | 4123/8583 [02:30<03:13, 23.07it/s]
2023-04-03 23:35:22,883 - INFO - tqdm - accuracy: 0.6641, batch_loss: 0.6046, loss: 0.7583 ||:  52%|#####1    | 4422/8583 [02:40<02:16, 30.54it/s]
2023-04-03 23:35:32,883 - INFO - tqdm - accuracy: 0.6702, batch_loss: 0.6628, loss: 0.7480 ||:  55%|#####4    | 4718/8583 [02:50<02:00, 32.02it/s]
2023-04-03 23:35:42,984 - INFO - tqdm - accuracy: 0.6762, batch_loss: 0.4832, loss: 0.7380 ||:  59%|#####8    | 5048/8583 [03:01<01:59, 29.52it/s]
2023-04-03 23:35:53,004 - INFO - tqdm - accuracy: 0.6810, batch_loss: 0.5803, loss: 0.7299 ||:  62%|######2   | 5330/8583 [03:11<01:39, 32.54it/s]
2023-04-03 23:36:03,038 - INFO - tqdm - accuracy: 0.6858, batch_loss: 0.4496, loss: 0.7216 ||:  66%|######5   | 5634/8583 [03:21<01:58, 24.92it/s]
2023-04-03 23:36:13,085 - INFO - tqdm - accuracy: 0.6903, batch_loss: 0.5928, loss: 0.7137 ||:  69%|######9   | 5937/8583 [03:31<01:28, 29.89it/s]
2023-04-03 23:36:23,147 - INFO - tqdm - accuracy: 0.6935, batch_loss: 0.6847, loss: 0.7080 ||:  72%|#######1  | 6178/8583 [03:41<01:41, 23.80it/s]
2023-04-03 23:36:33,303 - INFO - tqdm - accuracy: 0.6974, batch_loss: 0.5241, loss: 0.7010 ||:  75%|#######5  | 6478/8583 [03:51<01:11, 29.24it/s]
2023-04-03 23:36:43,415 - INFO - tqdm - accuracy: 0.7015, batch_loss: 0.7209, loss: 0.6943 ||:  79%|#######9  | 6794/8583 [04:01<00:59, 30.19it/s]
2023-04-03 23:36:53,469 - INFO - tqdm - accuracy: 0.7046, batch_loss: 0.5543, loss: 0.6886 ||:  82%|########2 | 7070/8583 [04:11<00:51, 29.65it/s]
2023-04-03 23:37:03,597 - INFO - tqdm - accuracy: 0.7074, batch_loss: 0.5545, loss: 0.6835 ||:  85%|########5 | 7321/8583 [04:21<00:55, 22.73it/s]
2023-04-03 23:37:13,698 - INFO - tqdm - accuracy: 0.7099, batch_loss: 0.5668, loss: 0.6790 ||:  88%|########8 | 7580/8583 [04:31<00:39, 25.18it/s]
2023-04-03 23:37:23,801 - INFO - tqdm - accuracy: 0.7128, batch_loss: 0.5788, loss: 0.6738 ||:  92%|#########1| 7867/8583 [04:41<00:22, 31.27it/s]
2023-04-03 23:37:33,869 - INFO - tqdm - accuracy: 0.7154, batch_loss: 0.5695, loss: 0.6690 ||:  95%|#########5| 8167/8583 [04:51<00:14, 28.50it/s]
2023-04-03 23:37:43,871 - INFO - tqdm - accuracy: 0.7176, batch_loss: 0.4233, loss: 0.6649 ||:  98%|#########8| 8431/8583 [05:01<00:05, 25.40it/s]
2023-04-03 23:37:48,087 - INFO - tqdm - accuracy: 0.7186, batch_loss: 0.5841, loss: 0.6633 ||: 100%|#########9| 8541/8583 [05:06<00:01, 27.90it/s]
2023-04-03 23:37:48,203 - INFO - tqdm - accuracy: 0.7186, batch_loss: 0.4923, loss: 0.6633 ||: 100%|#########9| 8544/8583 [05:06<00:01, 27.24it/s]
2023-04-03 23:37:48,316 - INFO - tqdm - accuracy: 0.7186, batch_loss: 0.4556, loss: 0.6632 ||: 100%|#########9| 8547/8583 [05:06<00:01, 27.04it/s]
2023-04-03 23:37:48,439 - INFO - tqdm - accuracy: 0.7187, batch_loss: 0.5223, loss: 0.6632 ||: 100%|#########9| 8550/8583 [05:06<00:01, 26.16it/s]
2023-04-03 23:37:48,562 - INFO - tqdm - accuracy: 0.7187, batch_loss: 0.4944, loss: 0.6631 ||: 100%|#########9| 8553/8583 [05:06<00:01, 25.63it/s]
2023-04-03 23:37:48,684 - INFO - tqdm - accuracy: 0.7187, batch_loss: 0.5377, loss: 0.6631 ||: 100%|#########9| 8556/8583 [05:06<00:01, 25.33it/s]
2023-04-03 23:37:48,804 - INFO - tqdm - accuracy: 0.7187, batch_loss: 0.5302, loss: 0.6630 ||: 100%|#########9| 8559/8583 [05:06<00:00, 25.18it/s]
2023-04-03 23:37:48,921 - INFO - tqdm - accuracy: 0.7188, batch_loss: 0.3227, loss: 0.6630 ||: 100%|#########9| 8562/8583 [05:06<00:00, 25.36it/s]
2023-04-03 23:37:49,029 - INFO - tqdm - accuracy: 0.7188, batch_loss: 0.6499, loss: 0.6630 ||: 100%|#########9| 8565/8583 [05:07<00:00, 26.02it/s]
2023-04-03 23:37:49,149 - INFO - tqdm - accuracy: 0.7188, batch_loss: 0.7326, loss: 0.6629 ||: 100%|#########9| 8568/8583 [05:07<00:00, 25.70it/s]
2023-04-03 23:37:49,264 - INFO - tqdm - accuracy: 0.7188, batch_loss: 0.4431, loss: 0.6629 ||: 100%|#########9| 8571/8583 [05:07<00:00, 25.83it/s]
2023-04-03 23:37:49,390 - INFO - tqdm - accuracy: 0.7188, batch_loss: 0.5461, loss: 0.6629 ||: 100%|#########9| 8574/8583 [05:07<00:00, 25.21it/s]
2023-04-03 23:37:49,503 - INFO - tqdm - accuracy: 0.7189, batch_loss: 0.3452, loss: 0.6628 ||: 100%|#########9| 8577/8583 [05:07<00:00, 25.59it/s]
2023-04-03 23:37:49,617 - INFO - tqdm - accuracy: 0.7189, batch_loss: 0.5185, loss: 0.6627 ||: 100%|#########9| 8580/8583 [05:07<00:00, 25.75it/s]
2023-04-03 23:37:49,724 - INFO - tqdm - accuracy: 0.7189, batch_loss: 0.5246, loss: 0.6627 ||: 100%|##########| 8583/8583 [05:07<00:00, 26.43it/s]
2023-04-03 23:37:50,197 - INFO - tqdm - accuracy: 0.7189, batch_loss: 0.5246, loss: 0.6627 ||: 100%|##########| 8583/8583 [05:08<00:00, 27.84it/s]
2023-04-03 23:37:50,198 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-03 23:37:50,200 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-03 23:37:50,236 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2023-04-03 23:37:50,237 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['premise'] as the sorting keys
2023-04-03 23:37:50,284 - INFO - allennlp.training.callbacks.console_logger - Batch inputs
2023-04-03 23:37:50,285 - INFO - allennlp.training.callbacks.console_logger - batch_input/premise/tokens/tokens (Shape: 64 x 13)
tensor([[   2,   81,   48,  ...,  668,    3,    0],
        [  14,   24,  842,  ...,   53,    3,    0],
        [ 822,   11,    4,  ...,    3,    0,    0],
        ...,
        [   2,   13, 3270,  ...,    3,    0,    0],
        [   2,  515,   15,  ...,  726,    3,    0],
        [   2,    7,    5,  ..., 2924,    3,    0]], device='cuda:0')
2023-04-03 23:37:50,288 - INFO - allennlp.training.callbacks.console_logger - batch_input/hypothesis/tokens/tokens (Shape: 64 x 16)
tensor([[   2,   48,    6,  ...,    0,    0,    0],
        [   4,   24,   10,  ...,    0,    0,    0],
        [ 692, 5181,  450,  ...,    0,    0,    0],
        ...,
        [   2,   13,    6,  ...,    0,    0,    0],
        [  15,   10,    5,  ...,    0,    0,    0],
        [   4,   44,    6,  ...,    0,    0,    0]], device='cuda:0')
2023-04-03 23:37:50,292 - INFO - allennlp.training.callbacks.console_logger - Field : "batch_input/metadata" : (Length 64 of type "<class 'dict'>")
2023-04-03 23:37:50,292 - INFO - allennlp.training.callbacks.console_logger - batch_input/label (Shape: 64)
tensor([0, 0, 1,  ..., 0, 0, 1], device='cuda:0')
2023-04-03 23:37:51,931 - INFO - tqdm - accuracy: 0.8243, batch_loss: 0.3656, loss: 0.4504 ||: 100%|##########| 154/154 [00:01<00:00, 89.01it/s]
2023-04-03 23:37:51,939 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-03 23:37:51,940 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.719  |     0.824
2023-04-03 23:37:51,941 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |    60.021  |       N/A
2023-04-03 23:37:51,941 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.663  |     0.450
2023-04-03 23:37:51,942 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7561.199  |       N/A
2023-04-03 23:37:52,643 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:10.703543
2023-04-03 23:37:52,644 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 6:22:19
2023-04-03 23:37:52,645 - INFO - allennlp.training.gradient_descent_trainer - Epoch 1/74
2023-04-03 23:37:52,646 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-03 23:37:52,647 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 592M
2023-04-03 23:37:52,648 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-03 23:37:52,649 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-03 23:38:22,984 - INFO - tqdm - accuracy: 0.7812, batch_loss: 0.4740, loss: 0.4740 ||:   0%|          | 1/8583 [00:30<72:18:49, 30.33s/it]
2023-04-03 23:38:33,101 - INFO - tqdm - accuracy: 0.8036, batch_loss: 0.7804, loss: 0.5031 ||:   3%|3         | 299/8583 [00:40<04:13, 32.71it/s]
2023-04-03 23:38:43,176 - INFO - tqdm - accuracy: 0.8005, batch_loss: 0.4962, loss: 0.5068 ||:   7%|6         | 598/8583 [00:50<04:02, 32.87it/s]
2023-04-03 23:38:53,213 - INFO - tqdm - accuracy: 0.7997, batch_loss: 0.5731, loss: 0.5093 ||:  10%|#         | 899/8583 [01:00<05:24, 23.66it/s]
2023-04-03 23:39:03,275 - INFO - tqdm - accuracy: 0.8008, batch_loss: 0.4351, loss: 0.5062 ||:  14%|#4        | 1213/8583 [01:10<04:09, 29.53it/s]
2023-04-03 23:39:13,338 - INFO - tqdm - accuracy: 0.8026, batch_loss: 0.4123, loss: 0.5048 ||:  18%|#7        | 1527/8583 [01:20<04:22, 26.93it/s]
2023-04-03 23:39:23,391 - INFO - tqdm - accuracy: 0.8025, batch_loss: 0.5988, loss: 0.5039 ||:  21%|##1       | 1820/8583 [01:30<03:50, 29.33it/s]
2023-04-03 23:39:33,464 - INFO - tqdm - accuracy: 0.8029, batch_loss: 0.6203, loss: 0.5033 ||:  24%|##4       | 2082/8583 [01:40<04:20, 24.99it/s]
2023-04-03 23:39:43,555 - INFO - tqdm - accuracy: 0.8034, batch_loss: 0.4126, loss: 0.5027 ||:  27%|##7       | 2345/8583 [01:50<03:51, 26.89it/s]
2023-04-03 23:39:53,633 - INFO - tqdm - accuracy: 0.8038, batch_loss: 0.4873, loss: 0.5022 ||:  31%|###1      | 2664/8583 [02:00<03:47, 26.04it/s]
2023-04-03 23:40:03,730 - INFO - tqdm - accuracy: 0.8036, batch_loss: 0.4585, loss: 0.5026 ||:  34%|###3      | 2916/8583 [02:11<04:02, 23.33it/s]
2023-04-03 23:40:13,815 - INFO - tqdm - accuracy: 0.8041, batch_loss: 0.4883, loss: 0.5013 ||:  37%|###7      | 3197/8583 [02:21<02:29, 36.12it/s]
2023-04-03 23:40:23,841 - INFO - tqdm - accuracy: 0.8041, batch_loss: 0.3635, loss: 0.5014 ||:  41%|####      | 3494/8583 [02:31<02:52, 29.58it/s]
2023-04-03 23:40:33,980 - INFO - tqdm - accuracy: 0.8046, batch_loss: 0.3853, loss: 0.5004 ||:  44%|####3     | 3766/8583 [02:41<02:34, 31.18it/s]
2023-04-03 23:40:44,045 - INFO - tqdm - accuracy: 0.8053, batch_loss: 0.5345, loss: 0.4990 ||:  47%|####7     | 4045/8583 [02:51<02:45, 27.46it/s]
2023-04-03 23:40:54,175 - INFO - tqdm - accuracy: 0.8058, batch_loss: 0.4019, loss: 0.4980 ||:  51%|#####     | 4369/8583 [03:01<02:06, 33.33it/s]
2023-04-03 23:41:04,276 - INFO - tqdm - accuracy: 0.8062, batch_loss: 0.5447, loss: 0.4973 ||:  54%|#####4    | 4677/8583 [03:11<02:44, 23.81it/s]
2023-04-03 23:41:14,303 - INFO - tqdm - accuracy: 0.8066, batch_loss: 0.3968, loss: 0.4965 ||:  57%|#####7    | 4934/8583 [03:21<01:56, 31.20it/s]
2023-04-03 23:41:24,409 - INFO - tqdm - accuracy: 0.8071, batch_loss: 0.4698, loss: 0.4952 ||:  61%|######    | 5233/8583 [03:31<02:23, 23.34it/s]
2023-04-03 23:41:34,515 - INFO - tqdm - accuracy: 0.8074, batch_loss: 0.5836, loss: 0.4948 ||:  64%|######3   | 5492/8583 [03:41<02:06, 24.52it/s]
2023-04-03 23:41:44,536 - INFO - tqdm - accuracy: 0.8080, batch_loss: 0.4392, loss: 0.4940 ||:  67%|######7   | 5761/8583 [03:51<01:56, 24.18it/s]
2023-04-03 23:41:54,613 - INFO - tqdm - accuracy: 0.8082, batch_loss: 0.4588, loss: 0.4936 ||:  70%|#######   | 6025/8583 [04:01<01:17, 33.01it/s]
2023-04-03 23:42:04,625 - INFO - tqdm - accuracy: 0.8086, batch_loss: 0.4438, loss: 0.4926 ||:  74%|#######3  | 6314/8583 [04:11<01:24, 26.93it/s]
2023-04-03 23:42:14,717 - INFO - tqdm - accuracy: 0.8088, batch_loss: 0.4996, loss: 0.4922 ||:  77%|#######7  | 6631/8583 [04:22<00:57, 33.71it/s]
2023-04-03 23:42:24,824 - INFO - tqdm - accuracy: 0.8092, batch_loss: 0.3354, loss: 0.4912 ||:  81%|########  | 6945/8583 [04:32<01:00, 27.14it/s]
2023-04-03 23:42:34,918 - INFO - tqdm - accuracy: 0.8096, batch_loss: 0.6534, loss: 0.4900 ||:  85%|########4 | 7257/8583 [04:42<00:37, 35.20it/s]
2023-04-03 23:42:45,000 - INFO - tqdm - accuracy: 0.8101, batch_loss: 0.5219, loss: 0.4890 ||:  88%|########7 | 7543/8583 [04:52<00:41, 25.21it/s]
2023-04-03 23:42:55,081 - INFO - tqdm - accuracy: 0.8103, batch_loss: 0.4473, loss: 0.4886 ||:  91%|######### | 7807/8583 [05:02<00:30, 25.61it/s]
2023-04-03 23:43:05,151 - INFO - tqdm - accuracy: 0.8106, batch_loss: 0.4799, loss: 0.4878 ||:  94%|#########4| 8101/8583 [05:12<00:17, 27.82it/s]
2023-04-03 23:43:15,235 - INFO - tqdm - accuracy: 0.8109, batch_loss: 0.3714, loss: 0.4872 ||:  98%|#########7| 8396/8583 [05:22<00:05, 34.56it/s]
2023-04-03 23:43:20,683 - INFO - tqdm - accuracy: 0.8109, batch_loss: 0.4101, loss: 0.4870 ||: 100%|#########9| 8541/8583 [05:28<00:01, 30.03it/s]
2023-04-03 23:43:20,851 - INFO - tqdm - accuracy: 0.8109, batch_loss: 0.4632, loss: 0.4870 ||: 100%|#########9| 8545/8583 [05:28<00:01, 27.74it/s]
2023-04-03 23:43:20,967 - INFO - tqdm - accuracy: 0.8109, batch_loss: 0.6416, loss: 0.4870 ||: 100%|#########9| 8548/8583 [05:28<00:01, 27.23it/s]
2023-04-03 23:43:21,069 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.3417, loss: 0.4870 ||: 100%|#########9| 8551/8583 [05:28<00:01, 27.81it/s]
2023-04-03 23:43:21,188 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.5067, loss: 0.4870 ||: 100%|#########9| 8554/8583 [05:28<00:01, 27.02it/s]
2023-04-03 23:43:21,309 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.5561, loss: 0.4870 ||: 100%|#########9| 8557/8583 [05:28<00:00, 26.35it/s]
2023-04-03 23:43:21,430 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.4148, loss: 0.4869 ||: 100%|#########9| 8560/8583 [05:28<00:00, 25.94it/s]
2023-04-03 23:43:21,538 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.4533, loss: 0.4869 ||: 100%|#########9| 8563/8583 [05:28<00:00, 26.42it/s]
2023-04-03 23:43:21,666 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.5167, loss: 0.4869 ||: 100%|#########9| 8566/8583 [05:29<00:00, 25.49it/s]
2023-04-03 23:43:21,799 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.4337, loss: 0.4869 ||: 100%|#########9| 8569/8583 [05:29<00:00, 24.52it/s]
2023-04-03 23:43:21,917 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.4608, loss: 0.4869 ||: 100%|#########9| 8572/8583 [05:29<00:00, 24.76it/s]
2023-04-03 23:43:22,040 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.5204, loss: 0.4869 ||: 100%|#########9| 8575/8583 [05:29<00:00, 24.65it/s]
2023-04-03 23:43:22,166 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.4245, loss: 0.4869 ||: 100%|#########9| 8578/8583 [05:29<00:00, 24.42it/s]
2023-04-03 23:43:22,286 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.5326, loss: 0.4869 ||: 100%|#########9| 8581/8583 [05:29<00:00, 24.61it/s]
2023-04-03 23:43:22,807 - INFO - tqdm - accuracy: 0.8110, batch_loss: 0.2690, loss: 0.4869 ||: 100%|##########| 8583/8583 [05:30<00:00, 26.00it/s]
2023-04-03 23:43:22,808 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-03 23:43:22,810 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-03 23:43:24,481 - INFO - tqdm - accuracy: 0.8549, batch_loss: 0.2923, loss: 0.3786 ||: 100%|##########| 154/154 [00:01<00:00, 92.20it/s]
2023-04-03 23:43:24,506 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-03 23:43:24,507 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.811  |     0.855
2023-04-03 23:43:24,507 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   591.617  |       N/A
2023-04-03 23:43:24,508 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.487  |     0.379
2023-04-03 23:43:24,508 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7795.762  |       N/A
2023-04-03 23:43:25,216 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:32.570448
2023-04-03 23:43:25,217 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 6:30:52
2023-04-03 23:43:25,217 - INFO - allennlp.training.gradient_descent_trainer - Epoch 2/74
2023-04-03 23:43:25,218 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-03 23:43:25,219 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-03 23:43:25,220 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-03 23:43:25,221 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-03 23:43:35,250 - INFO - tqdm - accuracy: 0.8212, batch_loss: 0.3533, loss: 0.4530 ||:   1%|1         | 118/8583 [00:10<05:42, 24.72it/s]
2023-04-03 23:43:45,279 - INFO - tqdm - accuracy: 0.8287, batch_loss: 0.3361, loss: 0.4438 ||:   5%|4         | 388/8583 [00:20<04:08, 32.92it/s]
2023-04-03 23:43:55,291 - INFO - tqdm - accuracy: 0.8288, batch_loss: 0.3853, loss: 0.4454 ||:   8%|8         | 687/8583 [00:30<04:07, 31.93it/s]
2023-04-03 23:44:05,398 - INFO - tqdm - accuracy: 0.8290, batch_loss: 0.4687, loss: 0.4458 ||:  12%|#1        | 1018/8583 [00:40<04:15, 29.59it/s]
2023-04-03 23:44:15,507 - INFO - tqdm - accuracy: 0.8294, batch_loss: 0.4073, loss: 0.4447 ||:  15%|#5        | 1317/8583 [00:50<04:50, 24.98it/s]
2023-04-03 23:44:25,553 - INFO - tqdm - accuracy: 0.8295, batch_loss: 0.4146, loss: 0.4450 ||:  19%|#8        | 1607/8583 [01:00<04:28, 25.97it/s]
2023-04-03 23:44:35,651 - INFO - tqdm - accuracy: 0.8299, batch_loss: 0.3191, loss: 0.4443 ||:  22%|##1       | 1865/8583 [01:10<03:58, 28.15it/s]
2023-04-03 23:44:45,693 - INFO - tqdm - accuracy: 0.8297, batch_loss: 0.5166, loss: 0.4449 ||:  25%|##5       | 2149/8583 [01:20<04:26, 24.11it/s]
2023-04-03 23:44:55,744 - INFO - tqdm - accuracy: 0.8301, batch_loss: 0.5146, loss: 0.4441 ||:  28%|##8       | 2405/8583 [01:30<03:38, 28.26it/s]
2023-04-03 23:45:05,786 - INFO - tqdm - accuracy: 0.8305, batch_loss: 0.6478, loss: 0.4439 ||:  31%|###1      | 2672/8583 [01:40<03:48, 25.91it/s]
2023-04-03 23:45:15,814 - INFO - tqdm - accuracy: 0.8310, batch_loss: 0.4916, loss: 0.4428 ||:  34%|###4      | 2956/8583 [01:50<02:57, 31.68it/s]
2023-04-03 23:45:25,895 - INFO - tqdm - accuracy: 0.8309, batch_loss: 0.6180, loss: 0.4421 ||:  38%|###7      | 3256/8583 [02:00<02:46, 31.97it/s]
2023-04-03 23:45:35,908 - INFO - tqdm - accuracy: 0.8313, batch_loss: 0.4569, loss: 0.4412 ||:  42%|####1     | 3602/8583 [02:10<02:38, 31.50it/s]
2023-04-03 23:45:45,923 - INFO - tqdm - accuracy: 0.8312, batch_loss: 0.3792, loss: 0.4412 ||:  46%|####5     | 3913/8583 [02:20<03:03, 25.39it/s]
2023-04-03 23:45:55,995 - INFO - tqdm - accuracy: 0.8313, batch_loss: 0.5933, loss: 0.4409 ||:  49%|####8     | 4190/8583 [02:30<02:26, 30.04it/s]
2023-04-03 23:46:06,092 - INFO - tqdm - accuracy: 0.8316, batch_loss: 0.6001, loss: 0.4405 ||:  53%|#####2    | 4521/8583 [02:40<01:56, 35.01it/s]
2023-04-03 23:46:16,194 - INFO - tqdm - accuracy: 0.8316, batch_loss: 0.5807, loss: 0.4403 ||:  56%|#####6    | 4817/8583 [02:50<01:54, 32.87it/s]
2023-04-03 23:46:26,248 - INFO - tqdm - accuracy: 0.8318, batch_loss: 0.3726, loss: 0.4399 ||:  60%|#####9    | 5107/8583 [03:01<02:14, 25.76it/s]
2023-04-03 23:46:36,269 - INFO - tqdm - accuracy: 0.8321, batch_loss: 0.4237, loss: 0.4393 ||:  63%|######2   | 5374/8583 [03:11<02:03, 26.05it/s]
2023-04-03 23:46:46,378 - INFO - tqdm - accuracy: 0.8322, batch_loss: 0.6650, loss: 0.4389 ||:  66%|######5   | 5657/8583 [03:21<01:28, 32.88it/s]
2023-04-03 23:46:56,423 - INFO - tqdm - accuracy: 0.8324, batch_loss: 0.5253, loss: 0.4385 ||:  69%|######9   | 5953/8583 [03:31<01:33, 28.24it/s]
2023-04-03 23:47:06,486 - INFO - tqdm - accuracy: 0.8323, batch_loss: 0.3538, loss: 0.4388 ||:  73%|#######2  | 6229/8583 [03:41<01:30, 26.08it/s]
2023-04-03 23:47:16,575 - INFO - tqdm - accuracy: 0.8324, batch_loss: 0.3070, loss: 0.4387 ||:  76%|#######5  | 6504/8583 [03:51<01:24, 24.69it/s]
2023-04-03 23:47:26,581 - INFO - tqdm - accuracy: 0.8325, batch_loss: 0.5146, loss: 0.4387 ||:  79%|#######8  | 6749/8583 [04:01<01:13, 24.91it/s]
2023-04-03 23:47:36,675 - INFO - tqdm - accuracy: 0.8328, batch_loss: 0.4499, loss: 0.4381 ||:  82%|########1 | 7035/8583 [04:11<00:44, 34.91it/s]
2023-04-03 23:47:46,728 - INFO - tqdm - accuracy: 0.8330, batch_loss: 0.4454, loss: 0.4376 ||:  86%|########5 | 7350/8583 [04:21<00:46, 26.27it/s]
2023-04-03 23:47:56,812 - INFO - tqdm - accuracy: 0.8332, batch_loss: 0.4648, loss: 0.4372 ||:  89%|########9 | 7661/8583 [04:31<00:37, 24.60it/s]
2023-04-03 23:48:06,849 - INFO - tqdm - accuracy: 0.8332, batch_loss: 0.5384, loss: 0.4372 ||:  93%|#########2| 7971/8583 [04:41<00:19, 31.18it/s]
2023-04-03 23:48:16,927 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.4434, loss: 0.4370 ||:  96%|#########5| 8216/8583 [04:51<00:15, 23.94it/s]
2023-04-03 23:48:27,011 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.4677, loss: 0.4369 ||:  99%|#########8| 8474/8583 [05:01<00:03, 31.25it/s]
2023-04-03 23:48:29,238 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.5171, loss: 0.4370 ||: 100%|#########9| 8542/8583 [05:04<00:01, 30.02it/s]
2023-04-03 23:48:29,370 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.4523, loss: 0.4370 ||: 100%|#########9| 8546/8583 [05:04<00:01, 30.11it/s]
2023-04-03 23:48:29,504 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.4103, loss: 0.4369 ||: 100%|#########9| 8550/8583 [05:04<00:01, 30.06it/s]
2023-04-03 23:48:29,630 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.2999, loss: 0.4369 ||: 100%|#########9| 8554/8583 [05:04<00:00, 30.57it/s]
2023-04-03 23:48:29,752 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.3909, loss: 0.4369 ||: 100%|#########9| 8558/8583 [05:04<00:00, 31.23it/s]
2023-04-03 23:48:29,893 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.4331, loss: 0.4369 ||: 100%|#########9| 8562/8583 [05:04<00:00, 30.23it/s]
2023-04-03 23:48:30,012 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.2827, loss: 0.4369 ||: 100%|#########9| 8566/8583 [05:04<00:00, 31.25it/s]
2023-04-03 23:48:30,137 - INFO - tqdm - accuracy: 0.8334, batch_loss: 0.3747, loss: 0.4369 ||: 100%|#########9| 8570/8583 [05:04<00:00, 31.47it/s]
2023-04-03 23:48:30,277 - INFO - tqdm - accuracy: 0.8333, batch_loss: 0.4714, loss: 0.4370 ||: 100%|#########9| 8574/8583 [05:05<00:00, 30.51it/s]
2023-04-03 23:48:30,431 - INFO - tqdm - accuracy: 0.8333, batch_loss: 0.3496, loss: 0.4369 ||: 100%|#########9| 8578/8583 [05:05<00:00, 28.98it/s]
2023-04-03 23:48:30,546 - INFO - tqdm - accuracy: 0.8333, batch_loss: 0.5610, loss: 0.4370 ||: 100%|#########9| 8581/8583 [05:05<00:00, 28.22it/s]
2023-04-03 23:48:31,089 - INFO - tqdm - accuracy: 0.8333, batch_loss: 0.5175, loss: 0.4370 ||: 100%|##########| 8583/8583 [05:05<00:00, 28.06it/s]
2023-04-03 23:48:31,091 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-03 23:48:31,093 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-03 23:48:32,861 - INFO - tqdm - accuracy: 0.8663, batch_loss: 0.3330, loss: 0.3552 ||: 100%|##########| 154/154 [00:01<00:00, 87.16it/s]
2023-04-03 23:48:32,895 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-03 23:48:32,895 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.833  |     0.866
2023-04-03 23:48:32,896 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.496  |       N/A
2023-04-03 23:48:32,896 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.437  |     0.355
2023-04-03 23:48:32,897 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.621  |       N/A
2023-04-03 23:48:33,734 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:08.516021
2023-04-03 23:48:33,735 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 6:20:22
2023-04-03 23:48:33,736 - INFO - allennlp.training.gradient_descent_trainer - Epoch 3/74
2023-04-03 23:48:33,736 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-03 23:48:33,738 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 571M
2023-04-03 23:48:33,739 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-03 23:48:33,740 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-03 23:49:08,389 - INFO - tqdm - accuracy: 0.9062, batch_loss: 0.3066, loss: 0.3066 ||:   0%|          | 1/8583 [00:34<82:35:45, 34.65s/it]
2023-04-03 23:49:18,420 - INFO - tqdm - accuracy: 0.8427, batch_loss: 0.4018, loss: 0.4150 ||:   3%|3         | 289/8583 [00:44<05:05, 27.16it/s]
2023-04-03 23:49:28,503 - INFO - tqdm - accuracy: 0.8440, batch_loss: 0.4771, loss: 0.4094 ||:   7%|6         | 586/8583 [00:54<03:59, 33.46it/s]
2023-04-03 23:49:38,612 - INFO - tqdm - accuracy: 0.8443, batch_loss: 0.5370, loss: 0.4106 ||:  10%|#         | 872/8583 [01:04<04:07, 31.21it/s]
2023-04-03 23:49:48,637 - INFO - tqdm - accuracy: 0.8457, batch_loss: 0.5130, loss: 0.4068 ||:  14%|#3        | 1189/8583 [01:14<04:58, 24.74it/s]
2023-04-03 23:49:58,711 - INFO - tqdm - accuracy: 0.8454, batch_loss: 0.4285, loss: 0.4073 ||:  17%|#7        | 1474/8583 [01:24<03:42, 31.89it/s]
2023-04-03 23:50:08,751 - INFO - tqdm - accuracy: 0.8459, batch_loss: 0.3186, loss: 0.4066 ||:  20%|##        | 1731/8583 [01:35<04:31, 25.22it/s]
2023-04-03 23:50:18,856 - INFO - tqdm - accuracy: 0.8459, batch_loss: 0.4768, loss: 0.4067 ||:  23%|##3       | 1980/8583 [01:45<04:18, 25.59it/s]
2023-04-03 23:50:28,928 - INFO - tqdm - accuracy: 0.8460, batch_loss: 0.2508, loss: 0.4066 ||:  26%|##6       | 2270/8583 [01:55<03:20, 31.43it/s]
2023-04-03 23:50:38,984 - INFO - tqdm - accuracy: 0.8459, batch_loss: 0.4738, loss: 0.4073 ||:  30%|##9       | 2555/8583 [02:05<03:54, 25.70it/s]
2023-04-03 23:50:49,082 - INFO - tqdm - accuracy: 0.8459, batch_loss: 0.2356, loss: 0.4074 ||:  33%|###2      | 2830/8583 [02:15<03:42, 25.83it/s]
2023-04-03 23:50:59,216 - INFO - tqdm - accuracy: 0.8457, batch_loss: 0.4503, loss: 0.4082 ||:  37%|###6      | 3133/8583 [02:25<03:02, 29.91it/s]
2023-04-03 23:51:09,231 - INFO - tqdm - accuracy: 0.8459, batch_loss: 0.4916, loss: 0.4077 ||:  40%|####      | 3450/8583 [02:35<02:28, 34.65it/s]
2023-04-03 23:51:19,315 - INFO - tqdm - accuracy: 0.8458, batch_loss: 0.2832, loss: 0.4081 ||:  44%|####4     | 3778/8583 [02:45<03:04, 25.99it/s]
2023-04-03 23:51:29,320 - INFO - tqdm - accuracy: 0.8459, batch_loss: 0.3732, loss: 0.4079 ||:  47%|####7     | 4049/8583 [02:55<02:24, 31.40it/s]
2023-04-03 23:51:39,401 - INFO - tqdm - accuracy: 0.8461, batch_loss: 0.2617, loss: 0.4073 ||:  51%|#####     | 4344/8583 [03:05<02:47, 25.35it/s]
2023-04-03 23:51:49,487 - INFO - tqdm - accuracy: 0.8463, batch_loss: 0.4511, loss: 0.4069 ||:  54%|#####3    | 4626/8583 [03:15<02:14, 29.32it/s]
2023-04-03 23:51:59,530 - INFO - tqdm - accuracy: 0.8463, batch_loss: 0.4754, loss: 0.4072 ||:  57%|#####7    | 4913/8583 [03:25<02:03, 29.80it/s]
2023-04-03 23:52:09,600 - INFO - tqdm - accuracy: 0.8464, batch_loss: 0.2721, loss: 0.4072 ||:  61%|######1   | 5237/8583 [03:35<01:59, 28.09it/s]
2023-04-03 23:52:19,605 - INFO - tqdm - accuracy: 0.8464, batch_loss: 0.3538, loss: 0.4070 ||:  64%|######3   | 5493/8583 [03:45<01:57, 26.30it/s]
2023-04-03 23:52:29,667 - INFO - tqdm - accuracy: 0.8465, batch_loss: 0.5271, loss: 0.4069 ||:  67%|######7   | 5783/8583 [03:55<01:35, 29.35it/s]
2023-04-03 23:52:39,795 - INFO - tqdm - accuracy: 0.8463, batch_loss: 0.4311, loss: 0.4073 ||:  71%|#######   | 6088/8583 [04:06<01:50, 22.61it/s]
2023-04-03 23:52:49,907 - INFO - tqdm - accuracy: 0.8463, batch_loss: 0.4504, loss: 0.4074 ||:  74%|#######4  | 6380/8583 [04:16<01:22, 26.67it/s]
2023-04-03 23:52:59,953 - INFO - tqdm - accuracy: 0.8464, batch_loss: 0.3672, loss: 0.4074 ||:  78%|#######7  | 6654/8583 [04:26<01:20, 23.83it/s]
2023-04-03 23:53:10,005 - INFO - tqdm - accuracy: 0.8466, batch_loss: 0.4255, loss: 0.4070 ||:  81%|########1 | 6976/8583 [04:36<00:50, 31.67it/s]
2023-04-03 23:53:20,013 - INFO - tqdm - accuracy: 0.8467, batch_loss: 0.4979, loss: 0.4067 ||:  85%|########4 | 7268/8583 [04:46<00:40, 32.29it/s]
2023-04-03 23:53:30,123 - INFO - tqdm - accuracy: 0.8467, batch_loss: 0.5696, loss: 0.4067 ||:  88%|########8 | 7592/8583 [04:56<00:30, 32.18it/s]
2023-04-03 23:53:40,147 - INFO - tqdm - accuracy: 0.8468, batch_loss: 0.3005, loss: 0.4063 ||:  92%|#########1| 7872/8583 [05:06<00:23, 30.90it/s]
2023-04-03 23:53:50,166 - INFO - tqdm - accuracy: 0.8468, batch_loss: 0.6398, loss: 0.4060 ||:  96%|#########5| 8210/8583 [05:16<00:11, 31.09it/s]
2023-04-03 23:54:00,265 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.2711, loss: 0.4059 ||: 100%|#########9| 8542/8583 [05:26<00:01, 34.09it/s]
2023-04-03 23:54:00,373 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.4167, loss: 0.4059 ||: 100%|#########9| 8546/8583 [05:26<00:01, 34.99it/s]
2023-04-03 23:54:00,486 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.4942, loss: 0.4060 ||: 100%|#########9| 8550/8583 [05:26<00:00, 35.05it/s]
2023-04-03 23:54:00,602 - INFO - tqdm - accuracy: 0.8469, batch_loss: 0.3673, loss: 0.4060 ||: 100%|#########9| 8554/8583 [05:26<00:00, 34.88it/s]
2023-04-03 23:54:00,741 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.3942, loss: 0.4060 ||: 100%|#########9| 8558/8583 [05:27<00:00, 32.80it/s]
2023-04-03 23:54:00,865 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.3464, loss: 0.4060 ||: 100%|#########9| 8562/8583 [05:27<00:00, 32.65it/s]
2023-04-03 23:54:00,977 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.3576, loss: 0.4059 ||: 100%|#########9| 8566/8583 [05:27<00:00, 33.54it/s]
2023-04-03 23:54:01,118 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.4710, loss: 0.4059 ||: 100%|#########9| 8570/8583 [05:27<00:00, 31.80it/s]
2023-04-03 23:54:01,279 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.3345, loss: 0.4059 ||: 100%|#########9| 8574/8583 [05:27<00:00, 29.34it/s]
2023-04-03 23:54:01,410 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.4438, loss: 0.4059 ||: 100%|#########9| 8578/8583 [05:27<00:00, 29.67it/s]
2023-04-03 23:54:01,546 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.4311, loss: 0.4059 ||: 100%|#########9| 8582/8583 [05:27<00:00, 29.62it/s]
2023-04-03 23:54:02,000 - INFO - tqdm - accuracy: 0.8470, batch_loss: 0.2758, loss: 0.4059 ||: 100%|##########| 8583/8583 [05:28<00:00, 26.15it/s]
2023-04-03 23:54:02,001 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-03 23:54:02,003 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-03 23:54:03,678 - INFO - tqdm - accuracy: 0.8715, batch_loss: 0.2306, loss: 0.3458 ||: 100%|##########| 154/154 [00:01<00:00, 91.94it/s]
2023-04-03 23:54:03,686 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-03 23:54:03,687 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.847  |     0.871
2023-04-03 23:54:03,688 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.696  |       N/A
2023-04-03 23:54:03,688 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.406  |     0.346
2023-04-03 23:54:03,689 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.664  |       N/A
2023-04-03 23:54:04,276 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:30.540358
2023-04-03 23:54:04,277 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 6:19:10
2023-04-03 23:54:04,278 - INFO - allennlp.training.gradient_descent_trainer - Epoch 4/74
2023-04-03 23:54:04,278 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-03 23:54:04,280 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 571M
2023-04-03 23:54:04,280 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-03 23:54:04,281 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-03 23:54:14,321 - INFO - tqdm - accuracy: 0.8592, batch_loss: 0.3928, loss: 0.3787 ||:   1%|1         | 111/8583 [00:10<04:58, 28.38it/s]
2023-04-03 23:54:24,390 - INFO - tqdm - accuracy: 0.8587, batch_loss: 0.6078, loss: 0.3806 ||:   4%|4         | 386/8583 [00:20<05:07, 26.68it/s]
2023-04-03 23:54:34,415 - INFO - tqdm - accuracy: 0.8594, batch_loss: 0.4843, loss: 0.3806 ||:   8%|7         | 648/8583 [00:30<05:06, 25.90it/s]
2023-04-03 23:54:44,528 - INFO - tqdm - accuracy: 0.8582, batch_loss: 0.4472, loss: 0.3831 ||:  11%|#         | 931/8583 [00:40<05:30, 23.19it/s]
2023-04-03 23:54:54,611 - INFO - tqdm - accuracy: 0.8579, batch_loss: 0.3868, loss: 0.3825 ||:  15%|#4        | 1259/8583 [00:50<03:51, 31.58it/s]
2023-04-03 23:55:04,635 - INFO - tqdm - accuracy: 0.8577, batch_loss: 0.2977, loss: 0.3830 ||:  18%|#8        | 1566/8583 [01:00<04:35, 25.43it/s]
2023-04-03 23:55:14,687 - INFO - tqdm - accuracy: 0.8576, batch_loss: 0.3105, loss: 0.3837 ||:  22%|##1       | 1853/8583 [01:10<04:12, 26.65it/s]
2023-04-03 23:55:24,795 - INFO - tqdm - accuracy: 0.8575, batch_loss: 0.3682, loss: 0.3838 ||:  25%|##5       | 2146/8583 [01:20<04:30, 23.82it/s]
2023-04-03 23:55:34,806 - INFO - tqdm - accuracy: 0.8572, batch_loss: 0.4020, loss: 0.3843 ||:  28%|##8       | 2427/8583 [01:30<04:08, 24.77it/s]
2023-04-03 23:55:44,894 - INFO - tqdm - accuracy: 0.8569, batch_loss: 0.1680, loss: 0.3844 ||:  31%|###1      | 2685/8583 [01:40<04:15, 23.05it/s]
2023-04-03 23:55:54,981 - INFO - tqdm - accuracy: 0.8569, batch_loss: 0.3550, loss: 0.3839 ||:  34%|###4      | 2947/8583 [01:50<03:39, 25.67it/s]
2023-04-03 23:56:05,083 - INFO - tqdm - accuracy: 0.8572, batch_loss: 0.3889, loss: 0.3836 ||:  38%|###7      | 3232/8583 [02:00<03:54, 22.79it/s]
2023-04-03 23:56:15,109 - INFO - tqdm - accuracy: 0.8573, batch_loss: 0.4663, loss: 0.3834 ||:  41%|####      | 3508/8583 [02:10<03:24, 24.85it/s]
2023-04-03 23:56:25,134 - INFO - tqdm - accuracy: 0.8574, batch_loss: 0.3222, loss: 0.3833 ||:  44%|####3     | 3767/8583 [02:20<02:38, 30.34it/s]
2023-04-03 23:56:35,144 - INFO - tqdm - accuracy: 0.8572, batch_loss: 0.4064, loss: 0.3835 ||:  47%|####6     | 4019/8583 [02:30<03:02, 25.02it/s]
2023-04-03 23:56:45,165 - INFO - tqdm - accuracy: 0.8571, batch_loss: 0.3439, loss: 0.3837 ||:  50%|#####     | 4318/8583 [02:40<02:33, 27.71it/s]
2023-04-03 23:56:55,220 - INFO - tqdm - accuracy: 0.8571, batch_loss: 0.3524, loss: 0.3832 ||:  54%|#####3    | 4604/8583 [02:50<01:56, 34.02it/s]
2023-04-03 23:57:05,287 - INFO - tqdm - accuracy: 0.8569, batch_loss: 0.2621, loss: 0.3837 ||:  57%|#####6    | 4890/8583 [03:01<02:35, 23.80it/s]
2023-04-03 23:57:15,296 - INFO - tqdm - accuracy: 0.8568, batch_loss: 0.3667, loss: 0.3838 ||:  60%|######    | 5160/8583 [03:11<01:46, 32.28it/s]
2023-04-03 23:57:25,348 - INFO - tqdm - accuracy: 0.8571, batch_loss: 0.4496, loss: 0.3835 ||:  63%|######3   | 5433/8583 [03:21<02:05, 25.13it/s]
2023-04-03 23:57:35,459 - INFO - tqdm - accuracy: 0.8571, batch_loss: 0.2865, loss: 0.3834 ||:  67%|######6   | 5721/8583 [03:31<01:51, 25.76it/s]
2023-04-03 23:57:45,563 - INFO - tqdm - accuracy: 0.8568, batch_loss: 0.4689, loss: 0.3841 ||:  69%|######9   | 5964/8583 [03:41<01:56, 22.50it/s]
2023-04-03 23:57:55,679 - INFO - tqdm - accuracy: 0.8568, batch_loss: 0.3936, loss: 0.3843 ||:  73%|#######2  | 6261/8583 [03:51<01:08, 33.90it/s]
2023-04-03 23:58:05,766 - INFO - tqdm - accuracy: 0.8566, batch_loss: 0.3967, loss: 0.3844 ||:  76%|#######6  | 6557/8583 [04:01<01:23, 24.30it/s]
2023-04-03 23:58:15,787 - INFO - tqdm - accuracy: 0.8566, batch_loss: 0.3543, loss: 0.3843 ||:  79%|#######9  | 6804/8583 [04:11<01:25, 20.92it/s]
2023-04-03 23:58:25,804 - INFO - tqdm - accuracy: 0.8567, batch_loss: 0.4053, loss: 0.3841 ||:  83%|########2 | 7106/8583 [04:21<00:45, 32.76it/s]
2023-04-03 23:58:35,829 - INFO - tqdm - accuracy: 0.8566, batch_loss: 0.4967, loss: 0.3844 ||:  86%|########5 | 7377/8583 [04:31<00:46, 25.89it/s]
2023-04-03 23:58:45,926 - INFO - tqdm - accuracy: 0.8566, batch_loss: 0.2964, loss: 0.3845 ||:  89%|########9 | 7646/8583 [04:41<00:35, 26.24it/s]
2023-04-03 23:58:56,020 - INFO - tqdm - accuracy: 0.8565, batch_loss: 0.3168, loss: 0.3846 ||:  93%|#########2| 7957/8583 [04:51<00:19, 32.08it/s]
2023-04-03 23:59:06,040 - INFO - tqdm - accuracy: 0.8565, batch_loss: 0.4616, loss: 0.3848 ||:  96%|#########5| 8229/8583 [05:01<00:14, 23.81it/s]
2023-04-03 23:59:16,071 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.4061, loss: 0.3848 ||:  99%|#########9| 8514/8583 [05:11<00:02, 26.36it/s]
2023-04-03 23:59:17,059 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.3214, loss: 0.3848 ||: 100%|#########9| 8543/8583 [05:12<00:01, 30.76it/s]
2023-04-03 23:59:17,203 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.5011, loss: 0.3848 ||: 100%|#########9| 8547/8583 [05:12<00:01, 29.79it/s]
2023-04-03 23:59:17,326 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.4154, loss: 0.3848 ||: 100%|#########9| 8551/8583 [05:13<00:01, 30.53it/s]
2023-04-03 23:59:17,475 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.4925, loss: 0.3848 ||: 100%|#########9| 8555/8583 [05:13<00:00, 29.32it/s]
2023-04-03 23:59:17,577 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.2957, loss: 0.3848 ||: 100%|#########9| 8558/8583 [05:13<00:00, 29.36it/s]
2023-04-03 23:59:17,683 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.3818, loss: 0.3848 ||: 100%|#########9| 8561/8583 [05:13<00:00, 29.08it/s]
2023-04-03 23:59:17,791 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.3202, loss: 0.3849 ||: 100%|#########9| 8564/8583 [05:13<00:00, 28.70it/s]
2023-04-03 23:59:17,903 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.3678, loss: 0.3849 ||: 100%|#########9| 8567/8583 [05:13<00:00, 28.14it/s]
2023-04-03 23:59:18,012 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.3711, loss: 0.3849 ||: 100%|#########9| 8570/8583 [05:13<00:00, 27.94it/s]
2023-04-03 23:59:18,127 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.3960, loss: 0.3849 ||: 100%|#########9| 8573/8583 [05:13<00:00, 27.41it/s]
2023-04-03 23:59:18,247 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.3965, loss: 0.3849 ||: 100%|#########9| 8576/8583 [05:13<00:00, 26.65it/s]
2023-04-03 23:59:18,363 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.2693, loss: 0.3848 ||: 100%|#########9| 8579/8583 [05:14<00:00, 26.42it/s]
2023-04-03 23:59:18,492 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.2085, loss: 0.3848 ||: 100%|##########| 8583/8583 [05:14<00:00, 27.88it/s]
2023-04-03 23:59:18,939 - INFO - tqdm - accuracy: 0.8564, batch_loss: 0.2085, loss: 0.3848 ||: 100%|##########| 8583/8583 [05:14<00:00, 27.28it/s]
2023-04-03 23:59:18,941 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-03 23:59:18,942 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-03 23:59:20,674 - INFO - tqdm - accuracy: 0.8776, batch_loss: 0.5313, loss: 0.3314 ||: 100%|##########| 154/154 [00:01<00:00, 88.96it/s]
2023-04-03 23:59:20,682 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-03 23:59:20,683 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.856  |     0.878
2023-04-03 23:59:20,684 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.656  |       N/A
2023-04-03 23:59:20,684 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.385  |     0.331
2023-04-03 23:59:20,685 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.664  |       N/A
2023-04-03 23:59:21,481 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:17.203632
2023-04-03 23:59:21,482 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 6:13:02
2023-04-03 23:59:21,483 - INFO - allennlp.training.gradient_descent_trainer - Epoch 5/74
2023-04-03 23:59:21,484 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-03 23:59:21,485 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 571M
2023-04-03 23:59:21,486 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-03 23:59:21,487 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-03 23:59:31,551 - INFO - tqdm - accuracy: 0.8627, batch_loss: 0.2525, loss: 0.3641 ||:   1%|1         | 112/8583 [00:10<05:52, 24.05it/s]
2023-04-03 23:59:41,662 - INFO - tqdm - accuracy: 0.8621, batch_loss: 0.5790, loss: 0.3678 ||:   5%|4         | 411/8583 [00:20<04:32, 30.03it/s]
2023-04-03 23:59:51,731 - INFO - tqdm - accuracy: 0.8636, batch_loss: 0.4275, loss: 0.3656 ||:   8%|8         | 708/8583 [00:30<05:08, 25.54it/s]
2023-04-04 00:00:01,834 - INFO - tqdm - accuracy: 0.8639, batch_loss: 0.3232, loss: 0.3655 ||:  12%|#1        | 988/8583 [00:40<04:25, 28.57it/s]
2023-04-04 00:00:11,943 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.2428, loss: 0.3671 ||:  15%|#4        | 1285/8583 [00:50<03:25, 35.55it/s]
2023-04-04 00:00:22,062 - INFO - tqdm - accuracy: 0.8641, batch_loss: 0.3730, loss: 0.3656 ||:  18%|#8        | 1586/8583 [01:00<03:52, 30.12it/s]
2023-04-04 00:00:32,168 - INFO - tqdm - accuracy: 0.8643, batch_loss: 0.4532, loss: 0.3653 ||:  22%|##2       | 1914/8583 [01:10<03:12, 34.60it/s]
2023-04-04 00:00:42,218 - INFO - tqdm - accuracy: 0.8639, batch_loss: 0.4279, loss: 0.3667 ||:  25%|##5       | 2188/8583 [01:20<04:31, 23.60it/s]
2023-04-04 00:00:52,284 - INFO - tqdm - accuracy: 0.8643, batch_loss: 0.2234, loss: 0.3660 ||:  29%|##9       | 2491/8583 [01:30<03:35, 28.28it/s]
2023-04-04 00:01:02,299 - INFO - tqdm - accuracy: 0.8643, batch_loss: 0.4730, loss: 0.3657 ||:  32%|###2      | 2761/8583 [01:40<04:26, 21.89it/s]
2023-04-04 00:01:12,316 - INFO - tqdm - accuracy: 0.8645, batch_loss: 0.4011, loss: 0.3655 ||:  35%|###5      | 3018/8583 [01:50<03:28, 26.70it/s]
2023-04-04 00:01:22,412 - INFO - tqdm - accuracy: 0.8644, batch_loss: 0.3429, loss: 0.3654 ||:  39%|###8      | 3309/8583 [02:00<03:34, 24.59it/s]
2023-04-04 00:01:32,540 - INFO - tqdm - accuracy: 0.8644, batch_loss: 0.3329, loss: 0.3652 ||:  42%|####1     | 3574/8583 [02:11<03:34, 23.31it/s]
2023-04-04 00:01:42,555 - INFO - tqdm - accuracy: 0.8643, batch_loss: 0.4373, loss: 0.3658 ||:  45%|####4     | 3854/8583 [02:21<02:22, 33.09it/s]
2023-04-04 00:01:52,597 - INFO - tqdm - accuracy: 0.8645, batch_loss: 0.5732, loss: 0.3655 ||:  48%|####8     | 4136/8583 [02:31<02:55, 25.38it/s]
2023-04-04 00:02:02,664 - INFO - tqdm - accuracy: 0.8645, batch_loss: 0.3434, loss: 0.3654 ||:  52%|#####1    | 4460/8583 [02:41<02:09, 31.81it/s]
2023-04-04 00:02:12,717 - INFO - tqdm - accuracy: 0.8647, batch_loss: 0.3162, loss: 0.3653 ||:  55%|#####5    | 4763/8583 [02:51<02:03, 31.04it/s]
2023-04-04 00:02:22,797 - INFO - tqdm - accuracy: 0.8648, batch_loss: 0.4180, loss: 0.3649 ||:  59%|#####9    | 5068/8583 [03:01<01:55, 30.32it/s]
2023-04-04 00:02:32,872 - INFO - tqdm - accuracy: 0.8645, batch_loss: 0.2642, loss: 0.3654 ||:  62%|######2   | 5342/8583 [03:11<02:12, 24.52it/s]
2023-04-04 00:02:42,965 - INFO - tqdm - accuracy: 0.8646, batch_loss: 0.4280, loss: 0.3655 ||:  66%|######5   | 5661/8583 [03:21<01:30, 32.29it/s]
2023-04-04 00:02:52,981 - INFO - tqdm - accuracy: 0.8641, batch_loss: 0.3312, loss: 0.3665 ||:  70%|######9   | 5983/8583 [03:31<01:34, 27.60it/s]
2023-04-04 00:03:03,025 - INFO - tqdm - accuracy: 0.8641, batch_loss: 0.3331, loss: 0.3667 ||:  73%|#######2  | 6259/8583 [03:41<01:31, 25.41it/s]
2023-04-04 00:03:13,065 - INFO - tqdm - accuracy: 0.8639, batch_loss: 0.4293, loss: 0.3671 ||:  76%|#######6  | 6548/8583 [03:51<01:20, 25.40it/s]
2023-04-04 00:03:23,108 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.4184, loss: 0.3670 ||:  79%|#######9  | 6807/8583 [04:01<01:05, 27.17it/s]
2023-04-04 00:03:33,230 - INFO - tqdm - accuracy: 0.8639, batch_loss: 0.4485, loss: 0.3670 ||:  83%|########2 | 7112/8583 [04:11<00:50, 29.04it/s]
2023-04-04 00:03:43,299 - INFO - tqdm - accuracy: 0.8639, batch_loss: 0.3132, loss: 0.3673 ||:  86%|########6 | 7424/8583 [04:21<00:36, 31.87it/s]
2023-04-04 00:03:53,410 - INFO - tqdm - accuracy: 0.8641, batch_loss: 0.3073, loss: 0.3670 ||:  90%|########9 | 7709/8583 [04:31<00:33, 25.88it/s]
2023-04-04 00:04:03,480 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.4023, loss: 0.3672 ||:  93%|#########3| 8001/8583 [04:41<00:16, 34.97it/s]
2023-04-04 00:04:13,490 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.2889, loss: 0.3670 ||:  97%|#########6| 8309/8583 [04:52<00:08, 31.45it/s]
2023-04-04 00:04:21,900 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.1803, loss: 0.3671 ||: 100%|#########9| 8541/8583 [05:00<00:01, 29.92it/s]
2023-04-04 00:04:22,056 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.2610, loss: 0.3671 ||: 100%|#########9| 8545/8583 [05:00<00:01, 28.44it/s]
2023-04-04 00:04:22,184 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3818, loss: 0.3671 ||: 100%|#########9| 8549/8583 [05:00<00:01, 29.27it/s]
2023-04-04 00:04:22,323 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3512, loss: 0.3671 ||: 100%|#########9| 8553/8583 [05:00<00:01, 29.13it/s]
2023-04-04 00:04:22,429 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.4000, loss: 0.3671 ||: 100%|#########9| 8556/8583 [05:00<00:00, 28.91it/s]
2023-04-04 00:04:22,533 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.2737, loss: 0.3671 ||: 100%|#########9| 8559/8583 [05:01<00:00, 28.91it/s]
2023-04-04 00:04:22,634 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.1968, loss: 0.3671 ||: 100%|#########9| 8562/8583 [05:01<00:00, 29.12it/s]
2023-04-04 00:04:22,734 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.5173, loss: 0.3671 ||: 100%|#########9| 8565/8583 [05:01<00:00, 29.31it/s]
2023-04-04 00:04:22,849 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3634, loss: 0.3671 ||: 100%|#########9| 8568/8583 [05:01<00:00, 28.32it/s]
2023-04-04 00:04:22,965 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3446, loss: 0.3671 ||: 100%|#########9| 8571/8583 [05:01<00:00, 27.60it/s]
2023-04-04 00:04:23,076 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3836, loss: 0.3671 ||: 100%|#########9| 8574/8583 [05:01<00:00, 27.42it/s]
2023-04-04 00:04:23,189 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.4847, loss: 0.3671 ||: 100%|#########9| 8577/8583 [05:01<00:00, 27.15it/s]
2023-04-04 00:04:23,315 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3935, loss: 0.3671 ||: 100%|#########9| 8580/8583 [05:01<00:00, 26.08it/s]
2023-04-04 00:04:23,424 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3657, loss: 0.3671 ||: 100%|##########| 8583/8583 [05:01<00:00, 26.49it/s]
2023-04-04 00:04:23,879 - INFO - tqdm - accuracy: 0.8640, batch_loss: 0.3657, loss: 0.3671 ||: 100%|##########| 8583/8583 [05:02<00:00, 28.38it/s]
2023-04-04 00:04:23,881 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:04:23,882 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:04:25,570 - INFO - tqdm - accuracy: 0.8780, batch_loss: 0.3186, loss: 0.3249 ||: 100%|##########| 154/154 [00:01<00:00, 97.09it/s]
2023-04-04 00:04:25,574 - INFO - tqdm - accuracy: 0.8780, batch_loss: 0.3186, loss: 0.3249 ||: 100%|##########| 154/154 [00:01<00:00, 91.07it/s]
2023-04-04 00:04:25,581 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:04:25,581 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.864  |     0.878
2023-04-04 00:04:25,582 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   571.188  |       N/A
2023-04-04 00:04:25,582 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.367  |     0.325
2023-04-04 00:04:25,583 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.672  |       N/A
2023-04-04 00:04:26,255 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:04.771828
2023-04-04 00:04:26,256 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 6:04:51
2023-04-04 00:04:26,257 - INFO - allennlp.training.gradient_descent_trainer - Epoch 6/74
2023-04-04 00:04:26,258 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:04:26,259 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 553M
2023-04-04 00:04:26,260 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:04:26,261 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:04:56,526 - INFO - tqdm - accuracy: 0.9062, batch_loss: 0.3568, loss: 0.3568 ||:   0%|          | 1/8583 [00:30<72:08:44, 30.26s/it]
2023-04-04 00:05:06,580 - INFO - tqdm - accuracy: 0.8718, batch_loss: 0.2932, loss: 0.3505 ||:   3%|3         | 295/8583 [00:40<04:22, 31.55it/s]
2023-04-04 00:05:16,671 - INFO - tqdm - accuracy: 0.8729, batch_loss: 0.3448, loss: 0.3453 ||:   7%|6         | 589/8583 [00:50<04:14, 31.36it/s]
2023-04-04 00:05:26,702 - INFO - tqdm - accuracy: 0.8708, batch_loss: 0.4517, loss: 0.3497 ||:  10%|#         | 881/8583 [01:00<05:34, 23.04it/s]
2023-04-04 00:05:36,724 - INFO - tqdm - accuracy: 0.8704, batch_loss: 0.3709, loss: 0.3512 ||:  14%|#3        | 1170/8583 [01:10<03:58, 31.08it/s]
2023-04-04 00:05:46,777 - INFO - tqdm - accuracy: 0.8706, batch_loss: 0.3355, loss: 0.3509 ||:  17%|#6        | 1431/8583 [01:20<04:59, 23.86it/s]
2023-04-04 00:05:56,818 - INFO - tqdm - accuracy: 0.8702, batch_loss: 0.2890, loss: 0.3518 ||:  20%|##        | 1739/8583 [01:30<03:47, 30.12it/s]
2023-04-04 00:06:06,879 - INFO - tqdm - accuracy: 0.8701, batch_loss: 0.3057, loss: 0.3509 ||:  23%|##3       | 1999/8583 [01:40<03:21, 32.65it/s]
2023-04-04 00:06:16,972 - INFO - tqdm - accuracy: 0.8711, batch_loss: 0.2876, loss: 0.3492 ||:  27%|##6       | 2311/8583 [01:50<04:02, 25.86it/s]
2023-04-04 00:06:27,029 - INFO - tqdm - accuracy: 0.8713, batch_loss: 0.2124, loss: 0.3489 ||:  30%|###       | 2580/8583 [02:00<04:04, 24.58it/s]
2023-04-04 00:06:37,133 - INFO - tqdm - accuracy: 0.8714, batch_loss: 0.2694, loss: 0.3487 ||:  34%|###3      | 2879/8583 [02:10<03:20, 28.50it/s]
2023-04-04 00:06:47,202 - INFO - tqdm - accuracy: 0.8712, batch_loss: 0.3164, loss: 0.3490 ||:  37%|###6      | 3172/8583 [02:20<03:43, 24.23it/s]
2023-04-04 00:06:57,260 - INFO - tqdm - accuracy: 0.8706, batch_loss: 0.4870, loss: 0.3502 ||:  40%|####      | 3439/8583 [02:30<03:32, 24.25it/s]
2023-04-04 00:07:07,301 - INFO - tqdm - accuracy: 0.8703, batch_loss: 0.2815, loss: 0.3510 ||:  43%|####3     | 3698/8583 [02:41<02:47, 29.11it/s]
2023-04-04 00:07:17,348 - INFO - tqdm - accuracy: 0.8703, batch_loss: 0.3681, loss: 0.3512 ||:  47%|####6     | 4022/8583 [02:51<02:35, 29.40it/s]
2023-04-04 00:07:27,423 - INFO - tqdm - accuracy: 0.8702, batch_loss: 0.2451, loss: 0.3515 ||:  50%|#####     | 4304/8583 [03:01<02:28, 28.86it/s]
2023-04-04 00:07:37,532 - INFO - tqdm - accuracy: 0.8700, batch_loss: 0.2827, loss: 0.3519 ||:  54%|#####3    | 4625/8583 [03:11<02:07, 31.08it/s]
2023-04-04 00:07:47,649 - INFO - tqdm - accuracy: 0.8698, batch_loss: 0.4704, loss: 0.3525 ||:  57%|#####6    | 4868/8583 [03:21<02:38, 23.37it/s]
2023-04-04 00:07:57,655 - INFO - tqdm - accuracy: 0.8698, batch_loss: 0.5770, loss: 0.3524 ||:  60%|#####9    | 5133/8583 [03:31<02:00, 28.62it/s]
2023-04-04 00:08:07,723 - INFO - tqdm - accuracy: 0.8698, batch_loss: 0.3274, loss: 0.3522 ||:  64%|######3   | 5452/8583 [03:41<01:31, 34.18it/s]
2023-04-04 00:08:17,799 - INFO - tqdm - accuracy: 0.8700, batch_loss: 0.3001, loss: 0.3522 ||:  67%|######7   | 5765/8583 [03:51<01:26, 32.63it/s]
2023-04-04 00:08:27,890 - INFO - tqdm - accuracy: 0.8700, batch_loss: 0.4561, loss: 0.3523 ||:  70%|#######   | 6009/8583 [04:01<01:41, 25.47it/s]
2023-04-04 00:08:37,984 - INFO - tqdm - accuracy: 0.8700, batch_loss: 0.2627, loss: 0.3524 ||:  73%|#######3  | 6272/8583 [04:11<01:31, 25.32it/s]
2023-04-04 00:08:47,990 - INFO - tqdm - accuracy: 0.8701, batch_loss: 0.2898, loss: 0.3521 ||:  77%|#######6  | 6588/8583 [04:21<00:57, 34.78it/s]
2023-04-04 00:08:58,017 - INFO - tqdm - accuracy: 0.8702, batch_loss: 0.2312, loss: 0.3518 ||:  80%|########  | 6894/8583 [04:31<00:54, 31.05it/s]
2023-04-04 00:09:08,123 - INFO - tqdm - accuracy: 0.8700, batch_loss: 0.2662, loss: 0.3521 ||:  84%|########3 | 7186/8583 [04:41<00:43, 31.75it/s]
2023-04-04 00:09:18,266 - INFO - tqdm - accuracy: 0.8699, batch_loss: 0.3794, loss: 0.3523 ||:  87%|########6 | 7465/8583 [04:52<00:50, 22.34it/s]
2023-04-04 00:09:28,360 - INFO - tqdm - accuracy: 0.8698, batch_loss: 0.3280, loss: 0.3523 ||:  90%|######### | 7729/8583 [05:02<00:28, 30.23it/s]
2023-04-04 00:09:38,364 - INFO - tqdm - accuracy: 0.8699, batch_loss: 0.1958, loss: 0.3522 ||:  93%|#########3| 7985/8583 [05:12<00:24, 24.79it/s]
2023-04-04 00:09:48,389 - INFO - tqdm - accuracy: 0.8698, batch_loss: 0.5375, loss: 0.3525 ||:  96%|#########6| 8245/8583 [05:22<00:12, 26.30it/s]
2023-04-04 00:09:58,439 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3170, loss: 0.3530 ||:  99%|#########9| 8508/8583 [05:32<00:02, 26.25it/s]
2023-04-04 00:09:59,707 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.4456, loss: 0.3529 ||: 100%|#########9| 8541/8583 [05:33<00:01, 26.19it/s]
2023-04-04 00:09:59,813 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.2756, loss: 0.3529 ||: 100%|#########9| 8544/8583 [05:33<00:01, 26.77it/s]
2023-04-04 00:09:59,918 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3340, loss: 0.3529 ||: 100%|#########9| 8547/8583 [05:33<00:01, 27.29it/s]
2023-04-04 00:10:00,032 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3864, loss: 0.3529 ||: 100%|#########9| 8550/8583 [05:33<00:01, 27.00it/s]
2023-04-04 00:10:00,143 - INFO - tqdm - accuracy: 0.8697, batch_loss: 0.3987, loss: 0.3529 ||: 100%|#########9| 8553/8583 [05:33<00:01, 27.04it/s]
2023-04-04 00:10:00,253 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.4427, loss: 0.3529 ||: 100%|#########9| 8556/8583 [05:33<00:00, 27.09it/s]
2023-04-04 00:10:00,365 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3478, loss: 0.3529 ||: 100%|#########9| 8559/8583 [05:34<00:00, 27.00it/s]
2023-04-04 00:10:00,470 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.5646, loss: 0.3529 ||: 100%|#########9| 8562/8583 [05:34<00:00, 27.46it/s]
2023-04-04 00:10:00,582 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3683, loss: 0.3529 ||: 100%|#########9| 8565/8583 [05:34<00:00, 27.26it/s]
2023-04-04 00:10:00,700 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.2649, loss: 0.3529 ||: 100%|#########9| 8568/8583 [05:34<00:00, 26.65it/s]
2023-04-04 00:10:00,834 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.4135, loss: 0.3529 ||: 100%|#########9| 8571/8583 [05:34<00:00, 25.26it/s]
2023-04-04 00:10:00,955 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3756, loss: 0.3530 ||: 100%|#########9| 8574/8583 [05:34<00:00, 25.10it/s]
2023-04-04 00:10:01,081 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3471, loss: 0.3530 ||: 100%|#########9| 8577/8583 [05:34<00:00, 24.72it/s]
2023-04-04 00:10:01,194 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.2322, loss: 0.3530 ||: 100%|#########9| 8580/8583 [05:34<00:00, 25.22it/s]
2023-04-04 00:10:01,324 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3411, loss: 0.3530 ||: 100%|##########| 8583/8583 [05:35<00:00, 24.52it/s]
2023-04-04 00:10:01,798 - INFO - tqdm - accuracy: 0.8696, batch_loss: 0.3411, loss: 0.3530 ||: 100%|##########| 8583/8583 [05:35<00:00, 25.58it/s]
2023-04-04 00:10:01,799 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:10:01,801 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:10:03,514 - INFO - tqdm - accuracy: 0.8787, batch_loss: 0.2424, loss: 0.3318 ||: 100%|##########| 154/154 [00:01<00:00, 94.28it/s]
2023-04-04 00:10:03,520 - INFO - tqdm - accuracy: 0.8787, batch_loss: 0.2424, loss: 0.3318 ||: 100%|##########| 154/154 [00:01<00:00, 89.60it/s]
2023-04-04 00:10:03,530 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:10:03,531 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.870  |     0.879
2023-04-04 00:10:03,531 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   552.545  |       N/A
2023-04-04 00:10:03,532 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.353  |     0.332
2023-04-04 00:10:03,532 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.672  |       N/A
2023-04-04 00:10:04,262 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:38.005377
2023-04-04 00:10:04,263 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 6:02:55
2023-04-04 00:10:04,264 - INFO - allennlp.training.gradient_descent_trainer - Epoch 7/74
2023-04-04 00:10:04,265 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:10:04,266 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 00:10:04,267 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:10:04,267 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:10:14,413 - INFO - tqdm - accuracy: 0.8752, batch_loss: 0.2533, loss: 0.3370 ||:   2%|1         | 136/8583 [00:10<04:31, 31.11it/s]
2023-04-04 00:10:24,507 - INFO - tqdm - accuracy: 0.8737, batch_loss: 0.1753, loss: 0.3380 ||:   5%|4         | 421/8583 [00:20<04:07, 33.03it/s]
2023-04-04 00:10:34,639 - INFO - tqdm - accuracy: 0.8758, batch_loss: 0.3361, loss: 0.3361 ||:   8%|8         | 725/8583 [00:30<04:03, 32.27it/s]
2023-04-04 00:10:44,747 - INFO - tqdm - accuracy: 0.8764, batch_loss: 0.2882, loss: 0.3342 ||:  12%|#1        | 1019/8583 [00:40<05:08, 24.52it/s]
2023-04-04 00:10:54,811 - INFO - tqdm - accuracy: 0.8756, batch_loss: 0.3402, loss: 0.3362 ||:  15%|#5        | 1297/8583 [00:50<03:42, 32.77it/s]
2023-04-04 00:11:04,834 - INFO - tqdm - accuracy: 0.8759, batch_loss: 0.2166, loss: 0.3371 ||:  18%|#8        | 1581/8583 [01:00<04:25, 26.39it/s]
2023-04-04 00:11:14,901 - INFO - tqdm - accuracy: 0.8768, batch_loss: 0.4466, loss: 0.3357 ||:  22%|##2       | 1915/8583 [01:10<03:03, 36.35it/s]
2023-04-04 00:11:24,929 - INFO - tqdm - accuracy: 0.8765, batch_loss: 0.2415, loss: 0.3366 ||:  26%|##5       | 2223/8583 [01:20<03:21, 31.61it/s]
2023-04-04 00:11:35,021 - INFO - tqdm - accuracy: 0.8764, batch_loss: 0.3221, loss: 0.3372 ||:  29%|##9       | 2495/8583 [01:30<03:34, 28.37it/s]
2023-04-04 00:11:45,105 - INFO - tqdm - accuracy: 0.8764, batch_loss: 0.3158, loss: 0.3374 ||:  33%|###2      | 2811/8583 [01:40<02:59, 32.18it/s]
2023-04-04 00:11:55,135 - INFO - tqdm - accuracy: 0.8759, batch_loss: 0.3334, loss: 0.3386 ||:  36%|###6      | 3114/8583 [01:50<03:54, 23.33it/s]
2023-04-04 00:12:05,142 - INFO - tqdm - accuracy: 0.8759, batch_loss: 0.2846, loss: 0.3386 ||:  40%|###9      | 3409/8583 [02:00<03:13, 26.71it/s]
2023-04-04 00:12:15,219 - INFO - tqdm - accuracy: 0.8757, batch_loss: 0.3278, loss: 0.3391 ||:  43%|####3     | 3695/8583 [02:10<02:21, 34.62it/s]
2023-04-04 00:12:25,319 - INFO - tqdm - accuracy: 0.8758, batch_loss: 0.4171, loss: 0.3386 ||:  47%|####6     | 4008/8583 [02:21<02:27, 31.09it/s]
2023-04-04 00:12:35,343 - INFO - tqdm - accuracy: 0.8758, batch_loss: 0.3754, loss: 0.3390 ||:  50%|#####     | 4313/8583 [02:31<02:17, 31.00it/s]
2023-04-04 00:12:45,355 - INFO - tqdm - accuracy: 0.8754, batch_loss: 0.2876, loss: 0.3396 ||:  53%|#####3    | 4584/8583 [02:41<02:05, 31.79it/s]
2023-04-04 00:12:55,464 - INFO - tqdm - accuracy: 0.8750, batch_loss: 0.4487, loss: 0.3403 ||:  57%|#####6    | 4888/8583 [02:51<01:51, 33.16it/s]
2023-04-04 00:13:05,486 - INFO - tqdm - accuracy: 0.8750, batch_loss: 0.3255, loss: 0.3405 ||:  60%|######    | 5183/8583 [03:01<02:10, 26.04it/s]
2023-04-04 00:13:15,598 - INFO - tqdm - accuracy: 0.8749, batch_loss: 0.4440, loss: 0.3406 ||:  64%|######3   | 5459/8583 [03:11<01:38, 31.86it/s]
2023-04-04 00:13:25,683 - INFO - tqdm - accuracy: 0.8748, batch_loss: 0.2420, loss: 0.3406 ||:  67%|######6   | 5749/8583 [03:21<01:52, 25.22it/s]
2023-04-04 00:13:35,718 - INFO - tqdm - accuracy: 0.8747, batch_loss: 0.3369, loss: 0.3406 ||:  71%|#######   | 6062/8583 [03:31<01:32, 27.26it/s]
2023-04-04 00:13:45,804 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3200, loss: 0.3410 ||:  74%|#######3  | 6342/8583 [03:41<01:34, 23.79it/s]
2023-04-04 00:13:55,904 - INFO - tqdm - accuracy: 0.8748, batch_loss: 0.3051, loss: 0.3410 ||:  77%|#######7  | 6621/8583 [03:51<00:59, 33.12it/s]
2023-04-04 00:14:05,946 - INFO - tqdm - accuracy: 0.8748, batch_loss: 0.2923, loss: 0.3409 ||:  81%|########  | 6914/8583 [04:01<00:55, 30.23it/s]
2023-04-04 00:14:15,964 - INFO - tqdm - accuracy: 0.8747, batch_loss: 0.4176, loss: 0.3409 ||:  85%|########4 | 7259/8583 [04:11<00:41, 32.16it/s]
2023-04-04 00:14:25,981 - INFO - tqdm - accuracy: 0.8747, batch_loss: 0.3611, loss: 0.3409 ||:  88%|########8 | 7591/8583 [04:21<00:28, 34.36it/s]
2023-04-04 00:14:36,062 - INFO - tqdm - accuracy: 0.8747, batch_loss: 0.2557, loss: 0.3407 ||:  92%|#########2| 7909/8583 [04:31<00:22, 29.63it/s]
2023-04-04 00:14:46,202 - INFO - tqdm - accuracy: 0.8747, batch_loss: 0.4028, loss: 0.3407 ||:  96%|#########5| 8198/8583 [04:41<00:12, 29.89it/s]
2023-04-04 00:14:56,297 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3232, loss: 0.3408 ||:  99%|#########8| 8474/8583 [04:52<00:04, 25.39it/s]
2023-04-04 00:14:58,873 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.4526, loss: 0.3409 ||: 100%|#########9| 8541/8583 [04:54<00:01, 25.70it/s]
2023-04-04 00:14:58,997 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.5164, loss: 0.3409 ||: 100%|#########9| 8544/8583 [04:54<00:01, 25.25it/s]
2023-04-04 00:14:59,138 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3630, loss: 0.3409 ||: 100%|#########9| 8547/8583 [04:54<00:01, 23.87it/s]
2023-04-04 00:14:59,276 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3130, loss: 0.3409 ||: 100%|#########9| 8550/8583 [04:55<00:01, 23.21it/s]
2023-04-04 00:14:59,400 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.2427, loss: 0.3409 ||: 100%|#########9| 8553/8583 [04:55<00:01, 23.49it/s]
2023-04-04 00:14:59,521 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3617, loss: 0.3409 ||: 100%|#########9| 8556/8583 [04:55<00:01, 23.85it/s]
2023-04-04 00:14:59,660 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3365, loss: 0.3409 ||: 100%|#########9| 8559/8583 [04:55<00:01, 23.16it/s]
2023-04-04 00:14:59,805 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3556, loss: 0.3409 ||: 100%|#########9| 8562/8583 [04:55<00:00, 22.35it/s]
2023-04-04 00:14:59,928 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.4965, loss: 0.3409 ||: 100%|#########9| 8565/8583 [04:55<00:00, 22.90it/s]
2023-04-04 00:15:00,044 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3029, loss: 0.3409 ||: 100%|#########9| 8568/8583 [04:55<00:00, 23.72it/s]
2023-04-04 00:15:00,167 - INFO - tqdm - accuracy: 0.8746, batch_loss: 0.3383, loss: 0.3410 ||: 100%|#########9| 8571/8583 [04:55<00:00, 23.93it/s]
2023-04-04 00:15:00,286 - INFO - tqdm - accuracy: 0.8745, batch_loss: 0.4075, loss: 0.3410 ||: 100%|#########9| 8574/8583 [04:56<00:00, 24.28it/s]
2023-04-04 00:15:00,420 - INFO - tqdm - accuracy: 0.8745, batch_loss: 0.3762, loss: 0.3410 ||: 100%|#########9| 8578/8583 [04:56<00:00, 26.08it/s]
2023-04-04 00:15:00,558 - INFO - tqdm - accuracy: 0.8745, batch_loss: 0.4430, loss: 0.3410 ||: 100%|#########9| 8582/8583 [04:56<00:00, 27.03it/s]
2023-04-04 00:15:01,023 - INFO - tqdm - accuracy: 0.8745, batch_loss: 0.6098, loss: 0.3410 ||: 100%|##########| 8583/8583 [04:56<00:00, 28.92it/s]
2023-04-04 00:15:01,025 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:15:01,027 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:15:02,741 - INFO - tqdm - accuracy: 0.8813, batch_loss: 0.3035, loss: 0.3255 ||: 100%|##########| 154/154 [00:01<00:00, 89.88it/s]
2023-04-04 00:15:02,748 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:15:02,749 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.875  |     0.881
2023-04-04 00:15:02,749 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.066  |       N/A
2023-04-04 00:15:02,750 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.341  |     0.325
2023-04-04 00:15:02,751 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.672  |       N/A
2023-04-04 00:15:03,390 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:04:59.126195
2023-04-04 00:15:03,391 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:54:39
2023-04-04 00:15:03,392 - INFO - allennlp.training.gradient_descent_trainer - Epoch 8/74
2023-04-04 00:15:03,392 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:15:03,393 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 563M
2023-04-04 00:15:03,395 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:15:03,395 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:15:13,435 - INFO - tqdm - accuracy: 0.8813, batch_loss: 0.2212, loss: 0.3293 ||:   1%|1         | 126/8583 [00:10<04:35, 30.65it/s]
2023-04-04 00:15:23,444 - INFO - tqdm - accuracy: 0.8791, batch_loss: 0.4906, loss: 0.3316 ||:   5%|4         | 423/8583 [00:20<04:46, 28.51it/s]
2023-04-04 00:15:33,558 - INFO - tqdm - accuracy: 0.8809, batch_loss: 0.2324, loss: 0.3267 ||:   8%|7         | 680/8583 [00:30<05:24, 24.36it/s]
2023-04-04 00:15:43,652 - INFO - tqdm - accuracy: 0.8821, batch_loss: 0.2933, loss: 0.3249 ||:  12%|#1        | 990/8583 [00:40<03:40, 34.44it/s]
2023-04-04 00:15:53,745 - INFO - tqdm - accuracy: 0.8810, batch_loss: 0.3541, loss: 0.3264 ||:  15%|#5        | 1307/8583 [00:50<04:51, 24.92it/s]
2023-04-04 00:16:03,746 - INFO - tqdm - accuracy: 0.8812, batch_loss: 0.3357, loss: 0.3265 ||:  18%|#8        | 1574/8583 [01:00<04:16, 27.35it/s]
2023-04-04 00:16:13,773 - INFO - tqdm - accuracy: 0.8807, batch_loss: 0.3814, loss: 0.3266 ||:  22%|##1       | 1861/8583 [01:10<04:11, 26.67it/s]
2023-04-04 00:16:23,775 - INFO - tqdm - accuracy: 0.8806, batch_loss: 0.3198, loss: 0.3263 ||:  25%|##5       | 2177/8583 [01:20<03:03, 34.85it/s]
2023-04-04 00:16:33,797 - INFO - tqdm - accuracy: 0.8810, batch_loss: 0.2643, loss: 0.3256 ||:  29%|##8       | 2482/8583 [01:30<03:36, 28.16it/s]
2023-04-04 00:16:43,817 - INFO - tqdm - accuracy: 0.8807, batch_loss: 0.4495, loss: 0.3262 ||:  32%|###1      | 2720/8583 [01:40<04:04, 24.02it/s]
2023-04-04 00:16:53,875 - INFO - tqdm - accuracy: 0.8812, batch_loss: 0.2737, loss: 0.3258 ||:  35%|###4      | 2986/8583 [01:50<03:50, 24.26it/s]
2023-04-04 00:17:03,896 - INFO - tqdm - accuracy: 0.8808, batch_loss: 0.3051, loss: 0.3264 ||:  38%|###7      | 3246/8583 [02:00<03:31, 25.27it/s]
2023-04-04 00:17:13,907 - INFO - tqdm - accuracy: 0.8807, batch_loss: 0.3346, loss: 0.3266 ||:  42%|####1     | 3574/8583 [02:10<02:46, 30.10it/s]
2023-04-04 00:17:23,934 - INFO - tqdm - accuracy: 0.8803, batch_loss: 0.2933, loss: 0.3273 ||:  45%|####4     | 3833/8583 [02:20<03:04, 25.80it/s]
2023-04-04 00:17:33,969 - INFO - tqdm - accuracy: 0.8799, batch_loss: 0.1882, loss: 0.3283 ||:  48%|####7     | 4087/8583 [02:30<02:43, 27.51it/s]
2023-04-04 00:17:44,100 - INFO - tqdm - accuracy: 0.8798, batch_loss: 0.2305, loss: 0.3282 ||:  51%|#####     | 4375/8583 [02:40<02:18, 30.39it/s]
2023-04-04 00:17:54,135 - INFO - tqdm - accuracy: 0.8797, batch_loss: 0.3347, loss: 0.3286 ||:  54%|#####4    | 4643/8583 [02:50<02:45, 23.86it/s]
2023-04-04 00:18:04,238 - INFO - tqdm - accuracy: 0.8799, batch_loss: 0.4194, loss: 0.3283 ||:  57%|#####7    | 4910/8583 [03:00<02:33, 23.91it/s]
2023-04-04 00:18:14,259 - INFO - tqdm - accuracy: 0.8798, batch_loss: 0.2395, loss: 0.3284 ||:  60%|######    | 5177/8583 [03:10<02:14, 25.36it/s]
2023-04-04 00:18:24,307 - INFO - tqdm - accuracy: 0.8798, batch_loss: 0.2773, loss: 0.3283 ||:  63%|######3   | 5446/8583 [03:20<01:59, 26.27it/s]
2023-04-04 00:18:34,422 - INFO - tqdm - accuracy: 0.8796, batch_loss: 0.3565, loss: 0.3286 ||:  67%|######6   | 5711/8583 [03:31<02:00, 23.80it/s]
2023-04-04 00:18:44,545 - INFO - tqdm - accuracy: 0.8794, batch_loss: 0.5904, loss: 0.3293 ||:  70%|#######   | 6010/8583 [03:41<01:27, 29.26it/s]
2023-04-04 00:18:54,639 - INFO - tqdm - accuracy: 0.8794, batch_loss: 0.3341, loss: 0.3293 ||:  74%|#######3  | 6309/8583 [03:51<01:09, 32.67it/s]
2023-04-04 00:19:04,655 - INFO - tqdm - accuracy: 0.8794, batch_loss: 0.4370, loss: 0.3293 ||:  77%|#######7  | 6628/8583 [04:01<01:04, 30.20it/s]
2023-04-04 00:19:14,774 - INFO - tqdm - accuracy: 0.8794, batch_loss: 0.2919, loss: 0.3295 ||:  81%|########  | 6924/8583 [04:11<00:50, 32.83it/s]
2023-04-04 00:19:24,805 - INFO - tqdm - accuracy: 0.8793, batch_loss: 0.3433, loss: 0.3297 ||:  84%|########4 | 7224/8583 [04:21<00:39, 34.77it/s]
2023-04-04 00:19:34,880 - INFO - tqdm - accuracy: 0.8791, batch_loss: 0.3211, loss: 0.3301 ||:  88%|########7 | 7546/8583 [04:31<00:32, 32.12it/s]
2023-04-04 00:19:44,938 - INFO - tqdm - accuracy: 0.8792, batch_loss: 0.3925, loss: 0.3300 ||:  92%|#########1| 7874/8583 [04:41<00:22, 31.14it/s]
2023-04-04 00:19:55,017 - INFO - tqdm - accuracy: 0.8791, batch_loss: 0.2351, loss: 0.3302 ||:  95%|#########4| 8128/8583 [04:51<00:18, 24.11it/s]
2023-04-04 00:20:05,055 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.3951, loss: 0.3302 ||:  98%|#########7| 8369/8583 [05:01<00:08, 24.57it/s]
2023-04-04 00:20:11,348 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.4262, loss: 0.3303 ||: 100%|#########9| 8542/8583 [05:07<00:01, 34.37it/s]
2023-04-04 00:20:11,459 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.4233, loss: 0.3303 ||: 100%|#########9| 8546/8583 [05:08<00:01, 34.81it/s]
2023-04-04 00:20:11,563 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.3184, loss: 0.3303 ||: 100%|#########9| 8550/8583 [05:08<00:00, 35.85it/s]
2023-04-04 00:20:11,680 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.3038, loss: 0.3303 ||: 100%|#########9| 8554/8583 [05:08<00:00, 35.35it/s]
2023-04-04 00:20:11,782 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.3776, loss: 0.3303 ||: 100%|#########9| 8558/8583 [05:08<00:00, 36.39it/s]
2023-04-04 00:20:11,898 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.2361, loss: 0.3303 ||: 100%|#########9| 8562/8583 [05:08<00:00, 35.86it/s]
2023-04-04 00:20:12,002 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.4508, loss: 0.3304 ||: 100%|#########9| 8566/8583 [05:08<00:00, 36.62it/s]
2023-04-04 00:20:12,123 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.3224, loss: 0.3304 ||: 100%|#########9| 8570/8583 [05:08<00:00, 35.45it/s]
2023-04-04 00:20:12,231 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.3845, loss: 0.3304 ||: 100%|#########9| 8574/8583 [05:08<00:00, 35.88it/s]
2023-04-04 00:20:12,348 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.4363, loss: 0.3304 ||: 100%|#########9| 8578/8583 [05:08<00:00, 35.33it/s]
2023-04-04 00:20:12,463 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.4286, loss: 0.3304 ||: 100%|#########9| 8582/8583 [05:09<00:00, 35.17it/s]
2023-04-04 00:20:12,889 - INFO - tqdm - accuracy: 0.8790, batch_loss: 0.4055, loss: 0.3304 ||: 100%|##########| 8583/8583 [05:09<00:00, 27.73it/s]
2023-04-04 00:20:12,891 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:20:12,892 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:20:14,674 - INFO - tqdm - accuracy: 0.8797, batch_loss: 0.3421, loss: 0.3236 ||: 100%|##########| 154/154 [00:01<00:00, 86.45it/s]
2023-04-04 00:20:14,681 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:20:14,682 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.879  |     0.880
2023-04-04 00:20:14,682 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   563.144  |       N/A
2023-04-04 00:20:14,683 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.330  |     0.324
2023-04-04 00:20:14,683 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.672  |       N/A
2023-04-04 00:20:15,461 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:12.069381
2023-04-04 00:20:15,462 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:48:40
2023-04-04 00:20:15,462 - INFO - allennlp.training.gradient_descent_trainer - Epoch 9/74
2023-04-04 00:20:15,463 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:20:15,464 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 00:20:15,465 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:20:15,466 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:20:44,928 - INFO - tqdm - accuracy: 0.8750, batch_loss: 0.2541, loss: 0.2541 ||:   0%|          | 1/8583 [00:29<70:13:57, 29.46s/it]
2023-04-04 00:20:55,023 - INFO - tqdm - accuracy: 0.8875, batch_loss: 0.4459, loss: 0.3154 ||:   4%|3         | 317/8583 [00:39<03:55, 35.12it/s]
2023-04-04 00:21:05,122 - INFO - tqdm - accuracy: 0.8870, batch_loss: 0.3576, loss: 0.3141 ||:   7%|6         | 598/8583 [00:49<03:58, 33.41it/s]
2023-04-04 00:21:15,239 - INFO - tqdm - accuracy: 0.8868, batch_loss: 0.1886, loss: 0.3132 ||:  11%|#         | 924/8583 [00:59<03:55, 32.58it/s]
2023-04-04 00:21:25,364 - INFO - tqdm - accuracy: 0.8879, batch_loss: 0.3309, loss: 0.3106 ||:  14%|#3        | 1196/8583 [01:09<05:11, 23.74it/s]
2023-04-04 00:21:35,482 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.4143, loss: 0.3102 ||:  17%|#7        | 1482/8583 [01:20<03:40, 32.27it/s]
2023-04-04 00:21:45,578 - INFO - tqdm - accuracy: 0.8880, batch_loss: 0.1766, loss: 0.3090 ||:  20%|##        | 1758/8583 [01:30<03:47, 30.03it/s]
2023-04-04 00:21:55,593 - INFO - tqdm - accuracy: 0.8880, batch_loss: 0.3999, loss: 0.3093 ||:  24%|##3       | 2022/8583 [01:40<04:11, 26.13it/s]
2023-04-04 00:22:05,619 - INFO - tqdm - accuracy: 0.8887, batch_loss: 0.1868, loss: 0.3081 ||:  27%|##6       | 2310/8583 [01:50<03:26, 30.42it/s]
2023-04-04 00:22:15,688 - INFO - tqdm - accuracy: 0.8887, batch_loss: 0.3922, loss: 0.3073 ||:  31%|###       | 2650/8583 [02:00<02:50, 34.80it/s]
2023-04-04 00:22:25,725 - INFO - tqdm - accuracy: 0.8886, batch_loss: 0.2657, loss: 0.3072 ||:  34%|###4      | 2939/8583 [02:10<02:36, 35.97it/s]
2023-04-04 00:22:35,773 - INFO - tqdm - accuracy: 0.8887, batch_loss: 0.3094, loss: 0.3068 ||:  37%|###7      | 3203/8583 [02:20<03:17, 27.24it/s]
2023-04-04 00:22:45,796 - INFO - tqdm - accuracy: 0.8888, batch_loss: 0.2794, loss: 0.3063 ||:  40%|####      | 3470/8583 [02:30<03:23, 25.08it/s]
2023-04-04 00:22:55,877 - INFO - tqdm - accuracy: 0.8886, batch_loss: 0.4553, loss: 0.3065 ||:  44%|####3     | 3740/8583 [02:40<03:17, 24.51it/s]
2023-04-04 00:23:05,972 - INFO - tqdm - accuracy: 0.8888, batch_loss: 0.2085, loss: 0.3063 ||:  47%|####7     | 4036/8583 [02:50<02:57, 25.58it/s]
2023-04-04 00:23:16,076 - INFO - tqdm - accuracy: 0.8885, batch_loss: 0.4116, loss: 0.3065 ||:  50%|#####     | 4332/8583 [03:00<02:06, 33.71it/s]
2023-04-04 00:23:26,124 - INFO - tqdm - accuracy: 0.8886, batch_loss: 0.2484, loss: 0.3063 ||:  54%|#####3    | 4616/8583 [03:10<02:25, 27.30it/s]
2023-04-04 00:23:36,230 - INFO - tqdm - accuracy: 0.8887, batch_loss: 0.3582, loss: 0.3062 ||:  57%|#####7    | 4893/8583 [03:20<01:51, 33.05it/s]
2023-04-04 00:23:46,232 - INFO - tqdm - accuracy: 0.8887, batch_loss: 0.1880, loss: 0.3059 ||:  61%|######    | 5205/8583 [03:30<01:53, 29.75it/s]
2023-04-04 00:23:56,301 - INFO - tqdm - accuracy: 0.8884, batch_loss: 0.3428, loss: 0.3066 ||:  64%|######3   | 5492/8583 [03:40<01:28, 34.86it/s]
2023-04-04 00:24:06,369 - INFO - tqdm - accuracy: 0.8883, batch_loss: 0.2946, loss: 0.3066 ||:  67%|######7   | 5783/8583 [03:50<01:38, 28.41it/s]
2023-04-04 00:24:16,385 - INFO - tqdm - accuracy: 0.8883, batch_loss: 0.3006, loss: 0.3065 ||:  71%|#######   | 6054/8583 [04:00<01:35, 26.40it/s]
2023-04-04 00:24:26,440 - INFO - tqdm - accuracy: 0.8884, batch_loss: 0.2751, loss: 0.3065 ||:  74%|#######3  | 6328/8583 [04:10<01:33, 24.12it/s]
2023-04-04 00:24:36,547 - INFO - tqdm - accuracy: 0.8883, batch_loss: 0.3734, loss: 0.3067 ||:  77%|#######7  | 6622/8583 [04:21<01:04, 30.56it/s]
2023-04-04 00:24:46,612 - INFO - tqdm - accuracy: 0.8881, batch_loss: 0.3158, loss: 0.3070 ||:  81%|########  | 6926/8583 [04:31<01:09, 23.88it/s]
2023-04-04 00:24:56,685 - INFO - tqdm - accuracy: 0.8880, batch_loss: 0.4405, loss: 0.3075 ||:  84%|########3 | 7198/8583 [04:41<00:54, 25.30it/s]
2023-04-04 00:25:06,797 - INFO - tqdm - accuracy: 0.8880, batch_loss: 0.2042, loss: 0.3076 ||:  87%|########6 | 7459/8583 [04:51<00:44, 25.29it/s]
2023-04-04 00:25:16,874 - INFO - tqdm - accuracy: 0.8880, batch_loss: 0.3463, loss: 0.3076 ||:  90%|########9 | 7721/8583 [05:01<00:29, 29.49it/s]
2023-04-04 00:25:26,903 - INFO - tqdm - accuracy: 0.8880, batch_loss: 0.3756, loss: 0.3076 ||:  93%|#########3| 8009/8583 [05:11<00:22, 25.10it/s]
2023-04-04 00:25:36,994 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.2282, loss: 0.3079 ||:  97%|#########6| 8291/8583 [05:21<00:11, 24.88it/s]
2023-04-04 00:25:46,210 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.2836, loss: 0.3080 ||: 100%|#########9| 8542/8583 [05:30<00:01, 30.58it/s]
2023-04-04 00:25:46,338 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.3041, loss: 0.3080 ||: 100%|#########9| 8546/8583 [05:30<00:01, 30.82it/s]
2023-04-04 00:25:46,487 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.5194, loss: 0.3080 ||: 100%|#########9| 8550/8583 [05:31<00:01, 29.51it/s]
2023-04-04 00:25:46,608 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.3767, loss: 0.3080 ||: 100%|#########9| 8553/8583 [05:31<00:01, 28.16it/s]
2023-04-04 00:25:46,748 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.1410, loss: 0.3080 ||: 100%|#########9| 8556/8583 [05:31<00:01, 26.07it/s]
2023-04-04 00:25:46,855 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.4247, loss: 0.3080 ||: 100%|#########9| 8559/8583 [05:31<00:00, 26.56it/s]
2023-04-04 00:25:46,961 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.2788, loss: 0.3080 ||: 100%|#########9| 8562/8583 [05:31<00:00, 27.05it/s]
2023-04-04 00:25:47,094 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.1662, loss: 0.3080 ||: 100%|#########9| 8565/8583 [05:31<00:00, 25.62it/s]
2023-04-04 00:25:47,261 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.5014, loss: 0.3080 ||: 100%|#########9| 8568/8583 [05:31<00:00, 22.78it/s]
2023-04-04 00:25:47,410 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.4458, loss: 0.3080 ||: 100%|#########9| 8571/8583 [05:31<00:00, 21.94it/s]
2023-04-04 00:25:47,536 - INFO - tqdm - accuracy: 0.8878, batch_loss: 0.3014, loss: 0.3080 ||: 100%|#########9| 8574/8583 [05:32<00:00, 22.48it/s]
2023-04-04 00:25:47,680 - INFO - tqdm - accuracy: 0.8877, batch_loss: 0.4808, loss: 0.3081 ||: 100%|#########9| 8577/8583 [05:32<00:00, 21.98it/s]
2023-04-04 00:25:47,812 - INFO - tqdm - accuracy: 0.8877, batch_loss: 0.3092, loss: 0.3081 ||: 100%|#########9| 8580/8583 [05:32<00:00, 22.16it/s]
2023-04-04 00:25:47,932 - INFO - tqdm - accuracy: 0.8877, batch_loss: 0.4615, loss: 0.3081 ||: 100%|##########| 8583/8583 [05:32<00:00, 22.94it/s]
2023-04-04 00:25:48,382 - INFO - tqdm - accuracy: 0.8877, batch_loss: 0.4615, loss: 0.3081 ||: 100%|##########| 8583/8583 [05:32<00:00, 25.78it/s]
2023-04-04 00:25:48,383 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:25:48,385 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:25:50,154 - INFO - tqdm - accuracy: 0.8828, batch_loss: 0.2754, loss: 0.3214 ||: 100%|##########| 154/154 [00:01<00:00, 87.07it/s]
2023-04-04 00:25:50,162 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:25:50,163 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.888  |     0.883
2023-04-04 00:25:50,163 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.268  |       N/A
2023-04-04 00:25:50,164 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.308  |     0.321
2023-04-04 00:25:50,165 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.676  |       N/A
2023-04-04 00:25:50,940 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:35.477534
2023-04-04 00:25:50,941 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:45:23
2023-04-04 00:25:50,942 - INFO - allennlp.training.gradient_descent_trainer - Epoch 10/74
2023-04-04 00:25:50,942 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:25:50,943 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 571M
2023-04-04 00:25:50,944 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:25:50,946 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:26:01,032 - INFO - tqdm - accuracy: 0.8930, batch_loss: 0.1867, loss: 0.2922 ||:   1%|1         | 125/8583 [00:10<04:21, 32.31it/s]
2023-04-04 00:26:11,082 - INFO - tqdm - accuracy: 0.8921, batch_loss: 0.3608, loss: 0.2961 ||:   5%|5         | 437/8583 [00:20<05:04, 26.79it/s]
2023-04-04 00:26:21,097 - INFO - tqdm - accuracy: 0.8932, batch_loss: 0.3344, loss: 0.2970 ||:   8%|8         | 725/8583 [00:30<05:10, 25.34it/s]
2023-04-04 00:26:31,146 - INFO - tqdm - accuracy: 0.8921, batch_loss: 0.4710, loss: 0.2989 ||:  12%|#1        | 1018/8583 [00:40<03:57, 31.79it/s]
2023-04-04 00:26:41,237 - INFO - tqdm - accuracy: 0.8926, batch_loss: 0.2606, loss: 0.2974 ||:  15%|#5        | 1320/8583 [00:50<04:11, 28.84it/s]
2023-04-04 00:26:51,237 - INFO - tqdm - accuracy: 0.8930, batch_loss: 0.2467, loss: 0.2966 ||:  19%|#8        | 1597/8583 [01:00<04:37, 25.14it/s]
2023-04-04 00:27:01,366 - INFO - tqdm - accuracy: 0.8935, batch_loss: 0.3577, loss: 0.2947 ||:  22%|##1       | 1887/8583 [01:10<03:34, 31.20it/s]
2023-04-04 00:27:11,423 - INFO - tqdm - accuracy: 0.8929, batch_loss: 0.4175, loss: 0.2961 ||:  25%|##5       | 2161/8583 [01:20<04:04, 26.24it/s]
2023-04-04 00:27:21,514 - INFO - tqdm - accuracy: 0.8927, batch_loss: 0.3869, loss: 0.2960 ||:  29%|##8       | 2468/8583 [01:30<03:06, 32.82it/s]
2023-04-04 00:27:31,569 - INFO - tqdm - accuracy: 0.8928, batch_loss: 0.2342, loss: 0.2959 ||:  33%|###2      | 2790/8583 [01:40<03:24, 28.32it/s]
2023-04-04 00:27:41,641 - INFO - tqdm - accuracy: 0.8926, batch_loss: 0.3365, loss: 0.2962 ||:  36%|###6      | 3116/8583 [01:50<02:25, 37.66it/s]
2023-04-04 00:27:51,669 - INFO - tqdm - accuracy: 0.8925, batch_loss: 0.3048, loss: 0.2964 ||:  40%|###9      | 3419/8583 [02:00<03:15, 26.39it/s]
2023-04-04 00:28:01,712 - INFO - tqdm - accuracy: 0.8920, batch_loss: 0.5146, loss: 0.2972 ||:  43%|####3     | 3711/8583 [02:10<02:45, 29.39it/s]
2023-04-04 00:28:11,741 - INFO - tqdm - accuracy: 0.8917, batch_loss: 0.4236, loss: 0.2976 ||:  47%|####6     | 4006/8583 [02:20<03:01, 25.26it/s]
2023-04-04 00:28:21,780 - INFO - tqdm - accuracy: 0.8915, batch_loss: 0.2522, loss: 0.2981 ||:  50%|####9     | 4276/8583 [02:30<02:10, 32.90it/s]
2023-04-04 00:28:31,830 - INFO - tqdm - accuracy: 0.8916, batch_loss: 0.3522, loss: 0.2978 ||:  53%|#####3    | 4588/8583 [02:40<02:04, 32.15it/s]
2023-04-04 00:28:41,884 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.2651, loss: 0.2980 ||:  57%|#####7    | 4914/8583 [02:50<02:19, 26.28it/s]
2023-04-04 00:28:51,994 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.2698, loss: 0.2980 ||:  60%|######    | 5170/8583 [03:01<02:07, 26.76it/s]
2023-04-04 00:29:02,092 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.3747, loss: 0.2981 ||:  63%|######3   | 5436/8583 [03:11<02:08, 24.47it/s]
2023-04-04 00:29:12,216 - INFO - tqdm - accuracy: 0.8915, batch_loss: 0.2381, loss: 0.2980 ||:  67%|######6   | 5737/8583 [03:21<01:33, 30.45it/s]
2023-04-04 00:29:22,248 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.3595, loss: 0.2984 ||:  70%|#######   | 6009/8583 [03:31<01:28, 29.03it/s]
2023-04-04 00:29:32,360 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.3973, loss: 0.2986 ||:  74%|#######3  | 6332/8583 [03:41<01:06, 33.86it/s]
2023-04-04 00:29:42,400 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.1832, loss: 0.2987 ||:  78%|#######7  | 6672/8583 [03:51<01:02, 30.35it/s]
2023-04-04 00:29:52,455 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.2310, loss: 0.2987 ||:  81%|########1 | 6953/8583 [04:01<01:03, 25.50it/s]
2023-04-04 00:30:02,574 - INFO - tqdm - accuracy: 0.8915, batch_loss: 0.4958, loss: 0.2987 ||:  84%|########4 | 7211/8583 [04:11<00:45, 30.04it/s]
2023-04-04 00:30:12,683 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.1523, loss: 0.2988 ||:  87%|########7 | 7478/8583 [04:21<00:45, 24.36it/s]
2023-04-04 00:30:22,709 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.3790, loss: 0.2989 ||:  90%|######### | 7760/8583 [04:31<00:26, 31.17it/s]
2023-04-04 00:30:32,727 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.3462, loss: 0.2989 ||:  94%|#########3| 8053/8583 [04:41<00:19, 27.89it/s]
2023-04-04 00:30:42,809 - INFO - tqdm - accuracy: 0.8914, batch_loss: 0.3460, loss: 0.2990 ||:  97%|#########7| 8332/8583 [04:51<00:09, 26.42it/s]
2023-04-04 00:30:50,422 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.2251, loss: 0.2991 ||: 100%|#########9| 8544/8583 [04:59<00:01, 28.39it/s]
2023-04-04 00:30:50,532 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.3397, loss: 0.2991 ||: 100%|#########9| 8547/8583 [04:59<00:01, 28.03it/s]
2023-04-04 00:30:50,649 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.3473, loss: 0.2992 ||: 100%|#########9| 8551/8583 [04:59<00:01, 29.89it/s]
2023-04-04 00:30:50,776 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.3621, loss: 0.2991 ||: 100%|#########9| 8555/8583 [04:59<00:00, 30.37it/s]
2023-04-04 00:30:50,893 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.2693, loss: 0.2992 ||: 100%|#########9| 8559/8583 [04:59<00:00, 31.51it/s]
2023-04-04 00:30:51,007 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.1625, loss: 0.2991 ||: 100%|#########9| 8563/8583 [05:00<00:00, 32.57it/s]
2023-04-04 00:30:51,126 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.2702, loss: 0.2991 ||: 100%|#########9| 8567/8583 [05:00<00:00, 32.85it/s]
2023-04-04 00:30:51,235 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.3761, loss: 0.2991 ||: 100%|#########9| 8571/8583 [05:00<00:00, 33.99it/s]
2023-04-04 00:30:51,348 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.4215, loss: 0.2992 ||: 100%|#########9| 8575/8583 [05:00<00:00, 34.63it/s]
2023-04-04 00:30:51,470 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.4582, loss: 0.2992 ||: 100%|#########9| 8579/8583 [05:00<00:00, 34.04it/s]
2023-04-04 00:30:51,595 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.4012, loss: 0.2992 ||: 100%|##########| 8583/8583 [05:00<00:00, 33.33it/s]
2023-04-04 00:30:52,001 - INFO - tqdm - accuracy: 0.8913, batch_loss: 0.4012, loss: 0.2992 ||: 100%|##########| 8583/8583 [05:01<00:00, 28.51it/s]
2023-04-04 00:30:52,002 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:30:52,003 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:30:53,721 - INFO - tqdm - accuracy: 0.8850, batch_loss: 0.3699, loss: 0.3179 ||: 100%|##########| 154/154 [00:01<00:00, 96.36it/s]
2023-04-04 00:30:53,726 - INFO - tqdm - accuracy: 0.8850, batch_loss: 0.3699, loss: 0.3179 ||: 100%|##########| 154/154 [00:01<00:00, 89.44it/s]
2023-04-04 00:30:53,733 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:30:53,734 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.891  |     0.885
2023-04-04 00:30:53,734 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.849  |       N/A
2023-04-04 00:30:53,735 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.299  |     0.318
2023-04-04 00:30:53,736 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.676  |       N/A
2023-04-04 00:30:54,304 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:03.362372
2023-04-04 00:30:54,305 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:38:35
2023-04-04 00:30:54,306 - INFO - allennlp.training.gradient_descent_trainer - Epoch 11/74
2023-04-04 00:30:54,306 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:30:54,308 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 00:30:54,309 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:30:54,310 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:31:24,612 - INFO - tqdm - accuracy: 0.9531, batch_loss: 0.2587, loss: 0.2587 ||:   0%|          | 1/8583 [00:30<72:14:03, 30.30s/it]
2023-04-04 00:31:34,646 - INFO - tqdm - accuracy: 0.8966, batch_loss: 0.2945, loss: 0.2918 ||:   3%|2         | 253/8583 [00:40<05:14, 26.50it/s]
2023-04-04 00:31:44,672 - INFO - tqdm - accuracy: 0.8966, batch_loss: 0.4068, loss: 0.2861 ||:   6%|6         | 534/8583 [00:50<04:23, 30.57it/s]
2023-04-04 00:31:54,743 - INFO - tqdm - accuracy: 0.8964, batch_loss: 0.3068, loss: 0.2885 ||:  10%|#         | 864/8583 [01:00<04:23, 29.28it/s]
2023-04-04 00:32:04,859 - INFO - tqdm - accuracy: 0.8972, batch_loss: 0.3352, loss: 0.2882 ||:  13%|#3        | 1132/8583 [01:10<04:06, 30.28it/s]
2023-04-04 00:32:14,917 - INFO - tqdm - accuracy: 0.8969, batch_loss: 0.4673, loss: 0.2885 ||:  17%|#6        | 1430/8583 [01:20<04:16, 27.87it/s]
2023-04-04 00:32:25,007 - INFO - tqdm - accuracy: 0.8969, batch_loss: 0.1992, loss: 0.2885 ||:  20%|#9        | 1714/8583 [01:30<04:36, 24.86it/s]
2023-04-04 00:32:35,094 - INFO - tqdm - accuracy: 0.8961, batch_loss: 0.4525, loss: 0.2891 ||:  23%|##3       | 1975/8583 [01:40<04:07, 26.67it/s]
2023-04-04 00:32:45,121 - INFO - tqdm - accuracy: 0.8958, batch_loss: 0.3656, loss: 0.2892 ||:  27%|##6       | 2282/8583 [01:50<03:58, 26.43it/s]
2023-04-04 00:32:55,200 - INFO - tqdm - accuracy: 0.8956, batch_loss: 0.2530, loss: 0.2890 ||:  30%|##9       | 2555/8583 [02:00<03:53, 25.81it/s]
2023-04-04 00:33:05,222 - INFO - tqdm - accuracy: 0.8954, batch_loss: 0.3441, loss: 0.2896 ||:  33%|###3      | 2869/8583 [02:10<03:02, 31.37it/s]
2023-04-04 00:33:15,312 - INFO - tqdm - accuracy: 0.8957, batch_loss: 0.2289, loss: 0.2890 ||:  37%|###6      | 3151/8583 [02:21<03:35, 25.24it/s]
2023-04-04 00:33:25,372 - INFO - tqdm - accuracy: 0.8953, batch_loss: 0.2878, loss: 0.2905 ||:  40%|####      | 3453/8583 [02:31<03:08, 27.15it/s]
2023-04-04 00:33:35,452 - INFO - tqdm - accuracy: 0.8952, batch_loss: 0.2320, loss: 0.2902 ||:  44%|####3     | 3772/8583 [02:41<02:54, 27.59it/s]
2023-04-04 00:33:45,532 - INFO - tqdm - accuracy: 0.8949, batch_loss: 0.3328, loss: 0.2907 ||:  47%|####6     | 4022/8583 [02:51<02:58, 25.58it/s]
2023-04-04 00:33:55,598 - INFO - tqdm - accuracy: 0.8947, batch_loss: 0.4508, loss: 0.2911 ||:  50%|#####     | 4294/8583 [03:01<02:41, 26.60it/s]
2023-04-04 00:34:05,616 - INFO - tqdm - accuracy: 0.8947, batch_loss: 0.2481, loss: 0.2909 ||:  53%|#####3    | 4550/8583 [03:11<02:23, 28.04it/s]
2023-04-04 00:34:15,715 - INFO - tqdm - accuracy: 0.8946, batch_loss: 0.2794, loss: 0.2906 ||:  56%|#####6    | 4821/8583 [03:21<02:18, 27.24it/s]
2023-04-04 00:34:25,749 - INFO - tqdm - accuracy: 0.8946, batch_loss: 0.2000, loss: 0.2906 ||:  60%|#####9    | 5132/8583 [03:31<01:57, 29.30it/s]
2023-04-04 00:34:35,858 - INFO - tqdm - accuracy: 0.8944, batch_loss: 0.2105, loss: 0.2910 ||:  63%|######3   | 5417/8583 [03:41<01:56, 27.09it/s]
2023-04-04 00:34:45,978 - INFO - tqdm - accuracy: 0.8941, batch_loss: 0.1950, loss: 0.2914 ||:  67%|######6   | 5721/8583 [03:51<01:33, 30.50it/s]
2023-04-04 00:34:56,036 - INFO - tqdm - accuracy: 0.8941, batch_loss: 0.2826, loss: 0.2916 ||:  70%|#######   | 6047/8583 [04:01<01:18, 32.49it/s]
2023-04-04 00:35:06,040 - INFO - tqdm - accuracy: 0.8940, batch_loss: 0.3182, loss: 0.2918 ||:  74%|#######3  | 6320/8583 [04:11<01:24, 26.87it/s]
2023-04-04 00:35:16,151 - INFO - tqdm - accuracy: 0.8938, batch_loss: 0.1980, loss: 0.2923 ||:  77%|#######7  | 6639/8583 [04:21<01:00, 31.93it/s]
2023-04-04 00:35:26,224 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.1331, loss: 0.2926 ||:  81%|########  | 6952/8583 [04:31<00:48, 33.89it/s]
2023-04-04 00:35:36,276 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2050, loss: 0.2928 ||:  84%|########4 | 7218/8583 [04:41<00:51, 26.37it/s]
2023-04-04 00:35:46,344 - INFO - tqdm - accuracy: 0.8936, batch_loss: 0.2840, loss: 0.2929 ||:  87%|########7 | 7495/8583 [04:52<00:38, 28.56it/s]
2023-04-04 00:35:56,395 - INFO - tqdm - accuracy: 0.8936, batch_loss: 0.2764, loss: 0.2928 ||:  90%|######### | 7762/8583 [05:02<00:32, 24.95it/s]
2023-04-04 00:36:06,429 - INFO - tqdm - accuracy: 0.8936, batch_loss: 0.3366, loss: 0.2928 ||:  94%|#########3| 8036/8583 [05:12<00:22, 24.38it/s]
2023-04-04 00:36:16,480 - INFO - tqdm - accuracy: 0.8936, batch_loss: 0.3066, loss: 0.2929 ||:  97%|#########7| 8340/8583 [05:22<00:08, 29.04it/s]
2023-04-04 00:36:24,628 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.3358, loss: 0.2928 ||: 100%|#########9| 8542/8583 [05:30<00:01, 25.47it/s]
2023-04-04 00:36:24,757 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2351, loss: 0.2928 ||: 100%|#########9| 8545/8583 [05:30<00:01, 24.75it/s]
2023-04-04 00:36:24,876 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2738, loss: 0.2928 ||: 100%|#########9| 8548/8583 [05:30<00:01, 24.88it/s]
2023-04-04 00:36:24,992 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2648, loss: 0.2929 ||: 100%|#########9| 8551/8583 [05:30<00:01, 25.16it/s]
2023-04-04 00:36:25,110 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2422, loss: 0.2929 ||: 100%|#########9| 8554/8583 [05:30<00:01, 25.27it/s]
2023-04-04 00:36:25,220 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.3164, loss: 0.2929 ||: 100%|#########9| 8557/8583 [05:30<00:01, 25.82it/s]
2023-04-04 00:36:25,325 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.3039, loss: 0.2929 ||: 100%|#########9| 8560/8583 [05:31<00:00, 26.56it/s]
2023-04-04 00:36:25,442 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2280, loss: 0.2929 ||: 100%|#########9| 8563/8583 [05:31<00:00, 26.29it/s]
2023-04-04 00:36:25,560 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2434, loss: 0.2929 ||: 100%|#########9| 8566/8583 [05:31<00:00, 26.04it/s]
2023-04-04 00:36:25,699 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2510, loss: 0.2929 ||: 100%|#########9| 8569/8583 [05:31<00:00, 24.52it/s]
2023-04-04 00:36:25,821 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.3342, loss: 0.2928 ||: 100%|#########9| 8572/8583 [05:31<00:00, 24.51it/s]
2023-04-04 00:36:25,945 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2572, loss: 0.2929 ||: 100%|#########9| 8575/8583 [05:31<00:00, 24.42it/s]
2023-04-04 00:36:26,072 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.2644, loss: 0.2929 ||: 100%|#########9| 8578/8583 [05:31<00:00, 24.22it/s]
2023-04-04 00:36:26,195 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.3145, loss: 0.2929 ||: 100%|#########9| 8581/8583 [05:31<00:00, 24.23it/s]
2023-04-04 00:36:26,726 - INFO - tqdm - accuracy: 0.8937, batch_loss: 0.1484, loss: 0.2929 ||: 100%|##########| 8583/8583 [05:32<00:00, 25.82it/s]
2023-04-04 00:36:26,727 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:36:26,728 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:36:28,443 - INFO - tqdm - accuracy: 0.8839, batch_loss: 0.3479, loss: 0.3212 ||: 100%|##########| 154/154 [00:01<00:00, 89.88it/s]
2023-04-04 00:36:28,468 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:36:28,468 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.894  |     0.884
2023-04-04 00:36:28,469 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   569.932  |       N/A
2023-04-04 00:36:28,470 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.293  |     0.321
2023-04-04 00:36:28,470 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.688  |       N/A
2023-04-04 00:36:29,234 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:34.928486
2023-04-04 00:36:29,235 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:34:49
2023-04-04 00:36:29,236 - INFO - allennlp.training.gradient_descent_trainer - Epoch 12/74
2023-04-04 00:36:29,237 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:36:29,238 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 00:36:29,239 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:36:29,241 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:36:39,250 - INFO - tqdm - accuracy: 0.8938, batch_loss: 0.3169, loss: 0.2938 ||:   1%|1         | 109/8583 [00:10<05:11, 27.22it/s]
2023-04-04 00:36:49,269 - INFO - tqdm - accuracy: 0.8984, batch_loss: 0.2861, loss: 0.2871 ||:   5%|4         | 414/8583 [00:20<04:43, 28.80it/s]
2023-04-04 00:36:59,326 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.1999, loss: 0.2834 ||:   9%|8         | 733/8583 [00:30<04:08, 31.55it/s]
2023-04-04 00:37:09,334 - INFO - tqdm - accuracy: 0.9000, batch_loss: 0.2802, loss: 0.2807 ||:  12%|#1        | 1020/8583 [00:40<05:00, 25.16it/s]
2023-04-04 00:37:19,464 - INFO - tqdm - accuracy: 0.8993, batch_loss: 0.2327, loss: 0.2818 ||:  16%|#5        | 1344/8583 [00:50<04:05, 29.46it/s]
2023-04-04 00:37:29,492 - INFO - tqdm - accuracy: 0.8994, batch_loss: 0.1538, loss: 0.2815 ||:  19%|#8        | 1600/8583 [01:00<04:13, 27.50it/s]
2023-04-04 00:37:39,515 - INFO - tqdm - accuracy: 0.8998, batch_loss: 0.3551, loss: 0.2803 ||:  22%|##1       | 1853/8583 [01:10<04:08, 27.04it/s]
2023-04-04 00:37:49,573 - INFO - tqdm - accuracy: 0.9000, batch_loss: 0.2114, loss: 0.2789 ||:  25%|##5       | 2150/8583 [01:20<03:23, 31.55it/s]
2023-04-04 00:37:59,682 - INFO - tqdm - accuracy: 0.8997, batch_loss: 0.3179, loss: 0.2785 ||:  28%|##8       | 2440/8583 [01:30<03:21, 30.56it/s]
2023-04-04 00:38:09,715 - INFO - tqdm - accuracy: 0.8993, batch_loss: 0.2903, loss: 0.2787 ||:  32%|###1      | 2738/8583 [01:40<03:12, 30.34it/s]
2023-04-04 00:38:19,735 - INFO - tqdm - accuracy: 0.8993, batch_loss: 0.2535, loss: 0.2792 ||:  35%|###5      | 3026/8583 [01:50<03:22, 27.42it/s]
2023-04-04 00:38:29,798 - INFO - tqdm - accuracy: 0.8993, batch_loss: 0.2518, loss: 0.2792 ||:  38%|###8      | 3299/8583 [02:00<03:30, 25.14it/s]
2023-04-04 00:38:39,811 - INFO - tqdm - accuracy: 0.8992, batch_loss: 0.4103, loss: 0.2791 ||:  42%|####1     | 3589/8583 [02:10<02:30, 33.18it/s]
2023-04-04 00:38:49,847 - INFO - tqdm - accuracy: 0.8992, batch_loss: 0.2764, loss: 0.2792 ||:  46%|####5     | 3921/8583 [02:20<02:21, 32.98it/s]
2023-04-04 00:38:59,946 - INFO - tqdm - accuracy: 0.8993, batch_loss: 0.1842, loss: 0.2790 ||:  49%|####8     | 4202/8583 [02:30<02:13, 32.75it/s]
2023-04-04 00:39:10,032 - INFO - tqdm - accuracy: 0.8995, batch_loss: 0.3954, loss: 0.2788 ||:  52%|#####2    | 4464/8583 [02:40<02:38, 25.99it/s]
2023-04-04 00:39:20,083 - INFO - tqdm - accuracy: 0.8993, batch_loss: 0.3901, loss: 0.2792 ||:  56%|#####5    | 4781/8583 [02:50<01:54, 33.19it/s]
2023-04-04 00:39:30,122 - INFO - tqdm - accuracy: 0.8994, batch_loss: 0.3415, loss: 0.2788 ||:  59%|#####8    | 5047/8583 [03:00<02:24, 24.45it/s]
2023-04-04 00:39:40,222 - INFO - tqdm - accuracy: 0.8996, batch_loss: 0.2588, loss: 0.2784 ||:  62%|######2   | 5343/8583 [03:10<02:05, 25.84it/s]
2023-04-04 00:39:50,319 - INFO - tqdm - accuracy: 0.8995, batch_loss: 0.2315, loss: 0.2786 ||:  65%|######5   | 5619/8583 [03:21<01:54, 25.89it/s]
2023-04-04 00:40:00,397 - INFO - tqdm - accuracy: 0.8996, batch_loss: 0.2745, loss: 0.2784 ||:  69%|######8   | 5889/8583 [03:31<01:26, 31.08it/s]
2023-04-04 00:40:10,514 - INFO - tqdm - accuracy: 0.8994, batch_loss: 0.2186, loss: 0.2786 ||:  72%|#######1  | 6149/8583 [03:41<01:41, 24.04it/s]
2023-04-04 00:40:20,519 - INFO - tqdm - accuracy: 0.8994, batch_loss: 0.2036, loss: 0.2784 ||:  75%|#######4  | 6414/8583 [03:51<01:10, 30.65it/s]
2023-04-04 00:40:30,588 - INFO - tqdm - accuracy: 0.8992, batch_loss: 0.3486, loss: 0.2786 ||:  78%|#######8  | 6717/8583 [04:01<00:53, 34.81it/s]
2023-04-04 00:40:40,589 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.1885, loss: 0.2788 ||:  82%|########1 | 7009/8583 [04:11<00:52, 30.27it/s]
2023-04-04 00:40:50,653 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.3584, loss: 0.2789 ||:  85%|########5 | 7327/8583 [04:21<00:45, 27.44it/s]
2023-04-04 00:41:00,706 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.2366, loss: 0.2791 ||:  89%|########8 | 7614/8583 [04:31<00:28, 33.47it/s]
2023-04-04 00:41:10,755 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.1384, loss: 0.2792 ||:  92%|#########2| 7930/8583 [04:41<00:23, 28.31it/s]
2023-04-04 00:41:20,821 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.2463, loss: 0.2793 ||:  96%|#########5| 8221/8583 [04:51<00:15, 23.57it/s]
2023-04-04 00:41:30,889 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.2240, loss: 0.2792 ||:  99%|#########8| 8470/8583 [05:01<00:04, 24.10it/s]
2023-04-04 00:41:33,413 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.2703, loss: 0.2792 ||: 100%|#########9| 8542/8583 [05:04<00:01, 30.92it/s]
2023-04-04 00:41:33,555 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.2803, loss: 0.2792 ||: 100%|#########9| 8546/8583 [05:04<00:01, 30.03it/s]
2023-04-04 00:41:33,682 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.2651, loss: 0.2792 ||: 100%|#########9| 8550/8583 [05:04<00:01, 30.46it/s]
2023-04-04 00:41:33,809 - INFO - tqdm - accuracy: 0.8991, batch_loss: 0.2036, loss: 0.2792 ||: 100%|#########9| 8554/8583 [05:04<00:00, 30.73it/s]
2023-04-04 00:41:33,936 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.3839, loss: 0.2792 ||: 100%|#########9| 8558/8583 [05:04<00:00, 30.98it/s]
2023-04-04 00:41:34,047 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.1779, loss: 0.2792 ||: 100%|#########9| 8562/8583 [05:04<00:00, 32.38it/s]
2023-04-04 00:41:34,176 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.2355, loss: 0.2792 ||: 100%|#########9| 8566/8583 [05:04<00:00, 31.98it/s]
2023-04-04 00:41:34,308 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.1857, loss: 0.2792 ||: 100%|#########9| 8570/8583 [05:05<00:00, 31.41it/s]
2023-04-04 00:41:34,434 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.5462, loss: 0.2792 ||: 100%|#########9| 8574/8583 [05:05<00:00, 31.55it/s]
2023-04-04 00:41:34,543 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.3594, loss: 0.2792 ||: 100%|#########9| 8578/8583 [05:05<00:00, 32.90it/s]
2023-04-04 00:41:34,678 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.2431, loss: 0.2792 ||: 100%|#########9| 8582/8583 [05:05<00:00, 31.82it/s]
2023-04-04 00:41:35,128 - INFO - tqdm - accuracy: 0.8990, batch_loss: 0.4063, loss: 0.2792 ||: 100%|##########| 8583/8583 [05:05<00:00, 28.06it/s]
2023-04-04 00:41:35,130 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:41:35,131 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:41:36,852 - INFO - tqdm - accuracy: 0.8844, batch_loss: 0.3321, loss: 0.3167 ||: 100%|##########| 154/154 [00:01<00:00, 95.60it/s]
2023-04-04 00:41:36,856 - INFO - tqdm - accuracy: 0.8844, batch_loss: 0.3321, loss: 0.3167 ||: 100%|##########| 154/154 [00:01<00:00, 89.34it/s]
2023-04-04 00:41:36,875 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:41:36,875 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.899  |     0.884
2023-04-04 00:41:36,876 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   569.694  |       N/A
2023-04-04 00:41:36,877 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.279  |     0.317
2023-04-04 00:41:36,878 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.688  |       N/A
2023-04-04 00:41:37,576 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:08.340444
2023-04-04 00:41:37,577 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:28:40
2023-04-04 00:41:37,578 - INFO - allennlp.training.gradient_descent_trainer - Epoch 13/74
2023-04-04 00:41:37,578 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:41:37,579 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 571M
2023-04-04 00:41:37,580 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:41:37,581 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:41:47,638 - INFO - tqdm - accuracy: 0.9077, batch_loss: 0.2336, loss: 0.2556 ||:   2%|1         | 137/8583 [00:10<04:19, 32.51it/s]
2023-04-04 00:41:57,663 - INFO - tqdm - accuracy: 0.9032, batch_loss: 0.3797, loss: 0.2676 ||:   5%|4         | 425/8583 [00:20<04:35, 29.61it/s]
2023-04-04 00:42:07,711 - INFO - tqdm - accuracy: 0.9035, batch_loss: 0.2483, loss: 0.2675 ||:   8%|8         | 716/8583 [00:30<05:26, 24.13it/s]
2023-04-04 00:42:17,796 - INFO - tqdm - accuracy: 0.9039, batch_loss: 0.3152, loss: 0.2664 ||:  12%|#1        | 1019/8583 [00:40<03:44, 33.66it/s]
2023-04-04 00:42:27,836 - INFO - tqdm - accuracy: 0.9027, batch_loss: 0.2910, loss: 0.2699 ||:  16%|#5        | 1346/8583 [00:50<03:50, 31.46it/s]
2023-04-04 00:42:37,877 - INFO - tqdm - accuracy: 0.9031, batch_loss: 0.1971, loss: 0.2687 ||:  19%|#9        | 1670/8583 [01:00<03:41, 31.14it/s]
2023-04-04 00:42:47,923 - INFO - tqdm - accuracy: 0.9024, batch_loss: 0.3024, loss: 0.2705 ||:  23%|##3       | 1983/8583 [01:10<03:00, 36.47it/s]
2023-04-04 00:42:57,987 - INFO - tqdm - accuracy: 0.9025, batch_loss: 0.1481, loss: 0.2700 ||:  26%|##6       | 2272/8583 [01:20<03:18, 31.86it/s]
2023-04-04 00:43:08,030 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.1945, loss: 0.2706 ||:  29%|##9       | 2531/8583 [01:30<03:57, 25.53it/s]
2023-04-04 00:43:18,062 - INFO - tqdm - accuracy: 0.9020, batch_loss: 0.3412, loss: 0.2711 ||:  33%|###2      | 2792/8583 [01:40<03:22, 28.61it/s]
2023-04-04 00:43:28,134 - INFO - tqdm - accuracy: 0.9017, batch_loss: 0.2534, loss: 0.2718 ||:  36%|###5      | 3078/8583 [01:50<02:37, 35.00it/s]
2023-04-04 00:43:38,151 - INFO - tqdm - accuracy: 0.9018, batch_loss: 0.1834, loss: 0.2718 ||:  39%|###9      | 3365/8583 [02:00<03:29, 24.90it/s]
2023-04-04 00:43:48,244 - INFO - tqdm - accuracy: 0.9017, batch_loss: 0.3484, loss: 0.2718 ||:  42%|####2     | 3631/8583 [02:10<03:17, 25.12it/s]
2023-04-04 00:43:58,324 - INFO - tqdm - accuracy: 0.9014, batch_loss: 0.2917, loss: 0.2721 ||:  46%|####5     | 3906/8583 [02:20<03:02, 25.65it/s]
2023-04-04 00:44:08,334 - INFO - tqdm - accuracy: 0.9011, batch_loss: 0.1480, loss: 0.2725 ||:  49%|####8     | 4172/8583 [02:30<02:23, 30.73it/s]
2023-04-04 00:44:18,399 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.3225, loss: 0.2724 ||:  52%|#####2    | 4478/8583 [02:40<02:26, 27.94it/s]
2023-04-04 00:44:28,488 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2575, loss: 0.2730 ||:  56%|#####5    | 4779/8583 [02:50<02:08, 29.50it/s]
2023-04-04 00:44:38,574 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.4009, loss: 0.2729 ||:  59%|#####8    | 5036/8583 [03:00<02:25, 24.39it/s]
2023-04-04 00:44:48,583 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2542, loss: 0.2730 ||:  62%|######1   | 5300/8583 [03:11<02:10, 25.13it/s]
2023-04-04 00:44:58,627 - INFO - tqdm - accuracy: 0.9009, batch_loss: 0.2145, loss: 0.2730 ||:  65%|######4   | 5554/8583 [03:21<01:53, 26.66it/s]
2023-04-04 00:45:08,648 - INFO - tqdm - accuracy: 0.9009, batch_loss: 0.3765, loss: 0.2730 ||:  68%|######7   | 5808/8583 [03:31<02:02, 22.68it/s]
2023-04-04 00:45:18,768 - INFO - tqdm - accuracy: 0.9008, batch_loss: 0.3916, loss: 0.2729 ||:  71%|#######   | 6068/8583 [03:41<01:44, 23.97it/s]
2023-04-04 00:45:28,830 - INFO - tqdm - accuracy: 0.9009, batch_loss: 0.2664, loss: 0.2730 ||:  74%|#######4  | 6382/8583 [03:51<01:29, 24.71it/s]
2023-04-04 00:45:38,945 - INFO - tqdm - accuracy: 0.9009, batch_loss: 0.3162, loss: 0.2728 ||:  78%|#######7  | 6658/8583 [04:01<01:15, 25.55it/s]
2023-04-04 00:45:48,977 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.3106, loss: 0.2726 ||:  81%|########  | 6927/8583 [04:11<01:07, 24.36it/s]
2023-04-04 00:45:58,994 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.3220, loss: 0.2726 ||:  84%|########3 | 7191/8583 [04:21<01:01, 22.63it/s]
2023-04-04 00:46:09,005 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.3223, loss: 0.2727 ||:  87%|########7 | 7474/8583 [04:31<00:31, 34.98it/s]
2023-04-04 00:46:19,083 - INFO - tqdm - accuracy: 0.9009, batch_loss: 0.2150, loss: 0.2727 ||:  90%|######### | 7763/8583 [04:41<00:29, 27.48it/s]
2023-04-04 00:46:29,123 - INFO - tqdm - accuracy: 0.9009, batch_loss: 0.2274, loss: 0.2727 ||:  93%|#########3| 8025/8583 [04:51<00:20, 27.46it/s]
2023-04-04 00:46:39,253 - INFO - tqdm - accuracy: 0.9009, batch_loss: 0.1980, loss: 0.2726 ||:  97%|#########7| 8332/8583 [05:01<00:10, 22.92it/s]
2023-04-04 00:46:46,817 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2413, loss: 0.2723 ||: 100%|#########9| 8543/8583 [05:09<00:01, 31.87it/s]
2023-04-04 00:46:46,946 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2386, loss: 0.2723 ||: 100%|#########9| 8547/8583 [05:09<00:01, 31.57it/s]
2023-04-04 00:46:47,087 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.1552, loss: 0.2723 ||: 100%|#########9| 8551/8583 [05:09<00:01, 30.54it/s]
2023-04-04 00:46:47,201 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.1652, loss: 0.2723 ||: 100%|#########9| 8555/8583 [05:09<00:00, 31.76it/s]
2023-04-04 00:46:47,329 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.4072, loss: 0.2723 ||: 100%|#########9| 8559/8583 [05:09<00:00, 31.67it/s]
2023-04-04 00:46:47,451 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2261, loss: 0.2723 ||: 100%|#########9| 8563/8583 [05:09<00:00, 31.95it/s]
2023-04-04 00:46:47,575 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.3491, loss: 0.2723 ||: 100%|#########9| 8567/8583 [05:09<00:00, 32.06it/s]
2023-04-04 00:46:47,691 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2315, loss: 0.2723 ||: 100%|#########9| 8571/8583 [05:10<00:00, 32.78it/s]
2023-04-04 00:46:47,824 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2059, loss: 0.2723 ||: 100%|#########9| 8575/8583 [05:10<00:00, 31.87it/s]
2023-04-04 00:46:47,947 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.2513, loss: 0.2723 ||: 100%|#########9| 8579/8583 [05:10<00:00, 32.09it/s]
2023-04-04 00:46:48,081 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.1333, loss: 0.2723 ||: 100%|##########| 8583/8583 [05:10<00:00, 31.40it/s]
2023-04-04 00:46:48,547 - INFO - tqdm - accuracy: 0.9010, batch_loss: 0.1333, loss: 0.2723 ||: 100%|##########| 8583/8583 [05:10<00:00, 27.60it/s]
2023-04-04 00:46:48,548 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:46:48,550 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:46:50,287 - INFO - tqdm - accuracy: 0.8856, batch_loss: 0.2349, loss: 0.3176 ||: 100%|##########| 154/154 [00:01<00:00, 88.69it/s]
2023-04-04 00:46:50,296 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:46:50,297 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.901  |     0.886
2023-04-04 00:46:50,297 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.567  |       N/A
2023-04-04 00:46:50,298 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.272  |     0.318
2023-04-04 00:46:50,299 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.691  |       N/A
2023-04-04 00:46:51,003 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:13.425052
2023-04-04 00:46:51,004 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:23:02
2023-04-04 00:46:51,004 - INFO - allennlp.training.gradient_descent_trainer - Epoch 14/74
2023-04-04 00:46:51,005 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:46:51,006 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 00:46:51,007 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:46:51,008 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:47:21,225 - INFO - tqdm - accuracy: 0.8750, batch_loss: 0.2462, loss: 0.2462 ||:   0%|          | 1/8583 [00:30<72:01:51, 30.22s/it]
2023-04-04 00:47:31,274 - INFO - tqdm - accuracy: 0.9017, batch_loss: 0.4642, loss: 0.2757 ||:   3%|3         | 277/8583 [00:40<04:47, 28.93it/s]
2023-04-04 00:47:41,379 - INFO - tqdm - accuracy: 0.9049, batch_loss: 0.3676, loss: 0.2686 ||:   6%|6         | 549/8583 [00:50<05:23, 24.82it/s]
2023-04-04 00:47:51,382 - INFO - tqdm - accuracy: 0.9047, batch_loss: 0.3309, loss: 0.2678 ||:   9%|9         | 809/8583 [01:00<04:12, 30.83it/s]
2023-04-04 00:48:01,393 - INFO - tqdm - accuracy: 0.9030, batch_loss: 0.2461, loss: 0.2705 ||:  13%|#2        | 1112/8583 [01:10<03:36, 34.51it/s]
2023-04-04 00:48:11,405 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.3242, loss: 0.2694 ||:  16%|#6        | 1376/8583 [01:20<05:00, 23.96it/s]
2023-04-04 00:48:21,511 - INFO - tqdm - accuracy: 0.9031, batch_loss: 0.2812, loss: 0.2688 ||:  19%|#9        | 1667/8583 [01:30<04:29, 25.66it/s]
2023-04-04 00:48:31,616 - INFO - tqdm - accuracy: 0.9031, batch_loss: 0.3847, loss: 0.2684 ||:  22%|##2       | 1916/8583 [01:40<04:44, 23.42it/s]
2023-04-04 00:48:41,706 - INFO - tqdm - accuracy: 0.9031, batch_loss: 0.3002, loss: 0.2685 ||:  25%|##5       | 2180/8583 [01:50<03:38, 29.30it/s]
2023-04-04 00:48:51,715 - INFO - tqdm - accuracy: 0.9027, batch_loss: 0.2223, loss: 0.2697 ||:  29%|##8       | 2465/8583 [02:00<03:39, 27.88it/s]
2023-04-04 00:49:01,729 - INFO - tqdm - accuracy: 0.9024, batch_loss: 0.2478, loss: 0.2700 ||:  32%|###2      | 2764/8583 [02:10<03:09, 30.70it/s]
2023-04-04 00:49:11,848 - INFO - tqdm - accuracy: 0.9023, batch_loss: 0.2588, loss: 0.2698 ||:  36%|###6      | 3091/8583 [02:20<03:40, 24.89it/s]
2023-04-04 00:49:21,967 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2123, loss: 0.2698 ||:  39%|###8      | 3341/8583 [02:30<03:07, 27.92it/s]
2023-04-04 00:49:32,065 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.2559, loss: 0.2695 ||:  43%|####2     | 3648/8583 [02:41<02:38, 31.19it/s]
2023-04-04 00:49:42,086 - INFO - tqdm - accuracy: 0.9023, batch_loss: 0.2234, loss: 0.2693 ||:  46%|####6     | 3964/8583 [02:51<02:24, 31.92it/s]
2023-04-04 00:49:52,202 - INFO - tqdm - accuracy: 0.9024, batch_loss: 0.3622, loss: 0.2694 ||:  49%|####9     | 4242/8583 [03:01<02:35, 27.85it/s]
2023-04-04 00:50:02,275 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.1504, loss: 0.2694 ||:  53%|#####3    | 4562/8583 [03:11<02:13, 30.13it/s]
2023-04-04 00:50:12,324 - INFO - tqdm - accuracy: 0.9024, batch_loss: 0.2549, loss: 0.2692 ||:  56%|#####6    | 4846/8583 [03:21<02:04, 30.09it/s]
2023-04-04 00:50:22,332 - INFO - tqdm - accuracy: 0.9024, batch_loss: 0.2142, loss: 0.2692 ||:  60%|#####9    | 5126/8583 [03:31<02:00, 28.70it/s]
2023-04-04 00:50:32,336 - INFO - tqdm - accuracy: 0.9027, batch_loss: 0.1818, loss: 0.2688 ||:  63%|######2   | 5403/8583 [03:41<01:41, 31.39it/s]
2023-04-04 00:50:42,380 - INFO - tqdm - accuracy: 0.9027, batch_loss: 0.2616, loss: 0.2684 ||:  67%|######6   | 5724/8583 [03:51<02:03, 23.23it/s]
2023-04-04 00:50:52,449 - INFO - tqdm - accuracy: 0.9026, batch_loss: 0.3092, loss: 0.2686 ||:  70%|#######   | 6025/8583 [04:01<01:19, 32.17it/s]
2023-04-04 00:51:02,475 - INFO - tqdm - accuracy: 0.9025, batch_loss: 0.1290, loss: 0.2688 ||:  74%|#######3  | 6336/8583 [04:11<01:22, 27.18it/s]
2023-04-04 00:51:12,562 - INFO - tqdm - accuracy: 0.9024, batch_loss: 0.2672, loss: 0.2688 ||:  77%|#######7  | 6621/8583 [04:21<01:15, 25.92it/s]
2023-04-04 00:51:22,678 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.1111, loss: 0.2693 ||:  81%|########  | 6937/8583 [04:31<00:50, 32.49it/s]
2023-04-04 00:51:32,694 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.1829, loss: 0.2695 ||:  84%|########3 | 7196/8583 [04:41<00:52, 26.45it/s]
2023-04-04 00:51:42,713 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2152, loss: 0.2698 ||:  87%|########7 | 7495/8583 [04:51<00:44, 24.27it/s]
2023-04-04 00:51:52,839 - INFO - tqdm - accuracy: 0.9023, batch_loss: 0.3342, loss: 0.2694 ||:  91%|######### | 7789/8583 [05:01<00:32, 24.25it/s]
2023-04-04 00:52:02,851 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.2267, loss: 0.2695 ||:  94%|#########3| 8041/8583 [05:11<00:20, 26.23it/s]
2023-04-04 00:52:12,901 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.3134, loss: 0.2696 ||:  97%|#########6| 8316/8583 [05:21<00:09, 26.92it/s]
2023-04-04 00:52:21,542 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.4043, loss: 0.2697 ||: 100%|#########9| 8543/8583 [05:30<00:01, 24.45it/s]
2023-04-04 00:52:21,681 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.3401, loss: 0.2697 ||: 100%|#########9| 8546/8583 [05:30<00:01, 23.52it/s]
2023-04-04 00:52:21,801 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.3470, loss: 0.2698 ||: 100%|#########9| 8549/8583 [05:30<00:01, 23.97it/s]
2023-04-04 00:52:21,925 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2329, loss: 0.2697 ||: 100%|#########9| 8552/8583 [05:30<00:01, 23.99it/s]
2023-04-04 00:52:22,068 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.3577, loss: 0.2697 ||: 100%|#########9| 8555/8583 [05:31<00:01, 23.00it/s]
2023-04-04 00:52:22,179 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2604, loss: 0.2697 ||: 100%|#########9| 8558/8583 [05:31<00:01, 24.07it/s]
2023-04-04 00:52:22,302 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.1905, loss: 0.2697 ||: 100%|#########9| 8561/8583 [05:31<00:00, 24.19it/s]
2023-04-04 00:52:22,436 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.4012, loss: 0.2697 ||: 100%|#########9| 8564/8583 [05:31<00:00, 23.63it/s]
2023-04-04 00:52:22,557 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2566, loss: 0.2697 ||: 100%|#########9| 8567/8583 [05:31<00:00, 23.95it/s]
2023-04-04 00:52:22,671 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2603, loss: 0.2697 ||: 100%|#########9| 8570/8583 [05:31<00:00, 24.63it/s]
2023-04-04 00:52:22,788 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2522, loss: 0.2697 ||: 100%|#########9| 8573/8583 [05:31<00:00, 24.89it/s]
2023-04-04 00:52:22,906 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.2954, loss: 0.2697 ||: 100%|#########9| 8576/8583 [05:31<00:00, 25.07it/s]
2023-04-04 00:52:23,025 - INFO - tqdm - accuracy: 0.9021, batch_loss: 0.2240, loss: 0.2697 ||: 100%|#########9| 8579/8583 [05:32<00:00, 25.14it/s]
2023-04-04 00:52:23,152 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.2757, loss: 0.2697 ||: 100%|#########9| 8582/8583 [05:32<00:00, 24.63it/s]
2023-04-04 00:52:23,656 - INFO - tqdm - accuracy: 0.9022, batch_loss: 0.2406, loss: 0.2697 ||: 100%|##########| 8583/8583 [05:32<00:00, 25.80it/s]
2023-04-04 00:52:23,658 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:52:23,659 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:52:25,367 - INFO - tqdm - accuracy: 0.8861, batch_loss: 0.3523, loss: 0.3186 ||: 100%|##########| 154/154 [00:01<00:00, 90.24it/s]
2023-04-04 00:52:25,374 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:52:25,375 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.902  |     0.886
2023-04-04 00:52:25,376 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.266  |       N/A
2023-04-04 00:52:25,376 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.270  |     0.319
2023-04-04 00:52:25,377 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.691  |       N/A
2023-04-04 00:52:25,941 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:34.936521
2023-04-04 00:52:25,942 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:18:53
2023-04-04 00:52:25,943 - INFO - allennlp.training.gradient_descent_trainer - Epoch 15/74
2023-04-04 00:52:25,943 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:52:25,945 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 00:52:25,946 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:52:25,947 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:52:36,005 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.1988, loss: 0.2586 ||:   1%|1         | 126/8583 [00:10<04:07, 34.18it/s]
2023-04-04 00:52:46,151 - INFO - tqdm - accuracy: 0.9030, batch_loss: 0.2265, loss: 0.2690 ||:   5%|5         | 453/8583 [00:20<04:49, 28.11it/s]
2023-04-04 00:52:56,200 - INFO - tqdm - accuracy: 0.9027, batch_loss: 0.2951, loss: 0.2690 ||:   9%|8         | 740/8583 [00:30<04:10, 31.27it/s]
2023-04-04 00:53:06,241 - INFO - tqdm - accuracy: 0.9034, batch_loss: 0.1866, loss: 0.2685 ||:  12%|#2        | 1058/8583 [00:40<03:48, 32.95it/s]
2023-04-04 00:53:16,269 - INFO - tqdm - accuracy: 0.9041, batch_loss: 0.2671, loss: 0.2671 ||:  16%|#5        | 1346/8583 [00:50<04:03, 29.77it/s]
2023-04-04 00:53:26,324 - INFO - tqdm - accuracy: 0.9042, batch_loss: 0.2263, loss: 0.2660 ||:  19%|#9        | 1647/8583 [01:00<04:36, 25.07it/s]
2023-04-04 00:53:36,379 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.4244, loss: 0.2654 ||:  22%|##2       | 1897/8583 [01:10<04:23, 25.35it/s]
2023-04-04 00:53:46,392 - INFO - tqdm - accuracy: 0.9048, batch_loss: 0.1764, loss: 0.2652 ||:  26%|##5       | 2190/8583 [01:20<04:13, 25.24it/s]
2023-04-04 00:53:56,421 - INFO - tqdm - accuracy: 0.9050, batch_loss: 0.1465, loss: 0.2647 ||:  29%|##8       | 2466/8583 [01:30<04:06, 24.83it/s]
2023-04-04 00:54:06,508 - INFO - tqdm - accuracy: 0.9047, batch_loss: 0.2784, loss: 0.2649 ||:  32%|###1      | 2721/8583 [01:40<03:54, 24.96it/s]
2023-04-04 00:54:16,571 - INFO - tqdm - accuracy: 0.9047, batch_loss: 0.2818, loss: 0.2643 ||:  35%|###5      | 3023/8583 [01:50<02:55, 31.65it/s]
2023-04-04 00:54:26,606 - INFO - tqdm - accuracy: 0.9048, batch_loss: 0.2319, loss: 0.2640 ||:  39%|###8      | 3334/8583 [02:00<02:45, 31.68it/s]
2023-04-04 00:54:36,606 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.1774, loss: 0.2641 ||:  42%|####2     | 3623/8583 [02:10<03:11, 25.95it/s]
2023-04-04 00:54:46,667 - INFO - tqdm - accuracy: 0.9045, batch_loss: 0.2035, loss: 0.2643 ||:  45%|####5     | 3882/8583 [02:20<02:53, 27.09it/s]
2023-04-04 00:54:56,765 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.1745, loss: 0.2643 ||:  49%|####8     | 4190/8583 [02:30<02:08, 34.26it/s]
2023-04-04 00:55:06,803 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.2740, loss: 0.2642 ||:  52%|#####2    | 4470/8583 [02:40<02:39, 25.83it/s]
2023-04-04 00:55:16,829 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.3329, loss: 0.2641 ||:  55%|#####5    | 4729/8583 [02:50<02:05, 30.67it/s]
2023-04-04 00:55:26,948 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.4217, loss: 0.2643 ||:  58%|#####8    | 5000/8583 [03:00<02:30, 23.78it/s]
2023-04-04 00:55:36,983 - INFO - tqdm - accuracy: 0.9042, batch_loss: 0.3024, loss: 0.2644 ||:  61%|######1   | 5257/8583 [03:11<02:11, 25.24it/s]
2023-04-04 00:55:47,079 - INFO - tqdm - accuracy: 0.9041, batch_loss: 0.2697, loss: 0.2648 ||:  64%|######4   | 5508/8583 [03:21<01:59, 25.81it/s]
2023-04-04 00:55:57,159 - INFO - tqdm - accuracy: 0.9040, batch_loss: 0.2350, loss: 0.2646 ||:  67%|######7   | 5779/8583 [03:31<01:30, 30.98it/s]
2023-04-04 00:56:07,250 - INFO - tqdm - accuracy: 0.9039, batch_loss: 0.2481, loss: 0.2650 ||:  71%|#######   | 6065/8583 [03:41<01:20, 31.22it/s]
2023-04-04 00:56:17,361 - INFO - tqdm - accuracy: 0.9038, batch_loss: 0.2360, loss: 0.2651 ||:  74%|#######4  | 6369/8583 [03:51<01:15, 29.25it/s]
2023-04-04 00:56:27,438 - INFO - tqdm - accuracy: 0.9038, batch_loss: 0.2658, loss: 0.2653 ||:  78%|#######7  | 6664/8583 [04:01<01:01, 31.20it/s]
2023-04-04 00:56:37,462 - INFO - tqdm - accuracy: 0.9038, batch_loss: 0.3322, loss: 0.2653 ||:  81%|########1 | 6956/8583 [04:11<01:01, 26.27it/s]
2023-04-04 00:56:47,554 - INFO - tqdm - accuracy: 0.9036, batch_loss: 0.4543, loss: 0.2656 ||:  85%|########4 | 7260/8583 [04:21<00:40, 32.44it/s]
2023-04-04 00:56:57,632 - INFO - tqdm - accuracy: 0.9035, batch_loss: 0.2275, loss: 0.2658 ||:  88%|########8 | 7573/8583 [04:31<00:32, 31.50it/s]
2023-04-04 00:57:07,662 - INFO - tqdm - accuracy: 0.9035, batch_loss: 0.3170, loss: 0.2658 ||:  92%|#########1| 7880/8583 [04:41<00:25, 27.49it/s]
2023-04-04 00:57:17,682 - INFO - tqdm - accuracy: 0.9034, batch_loss: 0.2694, loss: 0.2661 ||:  95%|#########5| 8158/8583 [04:51<00:16, 25.76it/s]
2023-04-04 00:57:27,691 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.3164, loss: 0.2663 ||:  98%|#########7| 8404/8583 [05:01<00:07, 22.51it/s]
2023-04-04 00:57:32,331 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.2441, loss: 0.2664 ||: 100%|#########9| 8543/8583 [05:06<00:01, 31.39it/s]
2023-04-04 00:57:32,481 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.2231, loss: 0.2664 ||: 100%|#########9| 8547/8583 [05:06<00:01, 29.82it/s]
2023-04-04 00:57:32,642 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.1827, loss: 0.2663 ||: 100%|#########9| 8551/8583 [05:06<00:01, 28.12it/s]
2023-04-04 00:57:32,764 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.2684, loss: 0.2663 ||: 100%|#########9| 8554/8583 [05:06<00:01, 27.16it/s]
2023-04-04 00:57:32,883 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.1453, loss: 0.2663 ||: 100%|#########9| 8557/8583 [05:06<00:00, 26.61it/s]
2023-04-04 00:57:32,998 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.3178, loss: 0.2663 ||: 100%|#########9| 8560/8583 [05:07<00:00, 26.52it/s]
2023-04-04 00:57:33,110 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.2130, loss: 0.2663 ||: 100%|#########9| 8563/8583 [05:07<00:00, 26.59it/s]
2023-04-04 00:57:33,232 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.3505, loss: 0.2663 ||: 100%|#########9| 8566/8583 [05:07<00:00, 25.95it/s]
2023-04-04 00:57:33,338 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.3054, loss: 0.2663 ||: 100%|#########9| 8569/8583 [05:07<00:00, 26.57it/s]
2023-04-04 00:57:33,473 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.3041, loss: 0.2663 ||: 100%|#########9| 8573/8583 [05:07<00:00, 27.63it/s]
2023-04-04 00:57:33,590 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.2697, loss: 0.2663 ||: 100%|#########9| 8576/8583 [05:07<00:00, 27.06it/s]
2023-04-04 00:57:33,697 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.3046, loss: 0.2664 ||: 100%|#########9| 8579/8583 [05:07<00:00, 27.34it/s]
2023-04-04 00:57:33,819 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.1509, loss: 0.2664 ||: 100%|#########9| 8582/8583 [05:07<00:00, 26.49it/s]
2023-04-04 00:57:34,269 - INFO - tqdm - accuracy: 0.9033, batch_loss: 0.2879, loss: 0.2664 ||: 100%|##########| 8583/8583 [05:08<00:00, 27.84it/s]
2023-04-04 00:57:34,271 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 00:57:34,272 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 00:57:35,990 - INFO - tqdm - accuracy: 0.8863, batch_loss: 0.2208, loss: 0.3199 ||: 100%|##########| 154/154 [00:01<00:00, 89.69it/s]
2023-04-04 00:57:36,001 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 00:57:36,002 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.903  |     0.886
2023-04-04 00:57:36,003 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.372  |       N/A
2023-04-04 00:57:36,003 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.266  |     0.320
2023-04-04 00:57:36,004 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.691  |       N/A
2023-04-04 00:57:36,620 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:10.677222
2023-04-04 00:57:36,621 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:13:04
2023-04-04 00:57:36,622 - INFO - allennlp.training.gradient_descent_trainer - Epoch 16/74
2023-04-04 00:57:36,623 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 00:57:36,624 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 571M
2023-04-04 00:57:36,625 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 00:57:36,626 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 00:57:46,659 - INFO - tqdm - accuracy: 0.9073, batch_loss: 0.2041, loss: 0.2571 ||:   1%|1         | 117/8583 [00:10<05:07, 27.52it/s]
2023-04-04 00:57:56,681 - INFO - tqdm - accuracy: 0.9049, batch_loss: 0.3363, loss: 0.2621 ||:   4%|4         | 363/8583 [00:20<05:48, 23.57it/s]
2023-04-04 00:58:06,783 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.3531, loss: 0.2658 ||:   8%|7         | 657/8583 [00:30<04:14, 31.11it/s]
2023-04-04 00:58:16,784 - INFO - tqdm - accuracy: 0.9047, batch_loss: 0.3003, loss: 0.2641 ||:  11%|#1        | 977/8583 [00:40<03:59, 31.74it/s]
2023-04-04 00:58:26,883 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.2014, loss: 0.2640 ||:  15%|#5        | 1302/8583 [00:50<04:01, 30.17it/s]
2023-04-04 00:58:36,929 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.2506, loss: 0.2630 ||:  19%|#8        | 1596/8583 [01:00<04:31, 25.75it/s]
2023-04-04 00:58:46,942 - INFO - tqdm - accuracy: 0.9035, batch_loss: 0.3071, loss: 0.2656 ||:  22%|##1       | 1870/8583 [01:10<03:31, 31.78it/s]
2023-04-04 00:58:57,006 - INFO - tqdm - accuracy: 0.9039, batch_loss: 0.2652, loss: 0.2651 ||:  26%|##5       | 2202/8583 [01:20<03:28, 30.63it/s]
2023-04-04 00:59:07,130 - INFO - tqdm - accuracy: 0.9040, batch_loss: 0.1583, loss: 0.2650 ||:  29%|##8       | 2470/8583 [01:30<04:03, 25.10it/s]
2023-04-04 00:59:17,192 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.3958, loss: 0.2645 ||:  32%|###1      | 2727/8583 [01:40<03:41, 26.48it/s]
2023-04-04 00:59:27,227 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.2333, loss: 0.2640 ||:  36%|###5      | 3050/8583 [01:50<02:58, 31.03it/s]
2023-04-04 00:59:37,315 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.2738, loss: 0.2637 ||:  39%|###8      | 3340/8583 [02:00<02:56, 29.72it/s]
2023-04-04 00:59:47,353 - INFO - tqdm - accuracy: 0.9051, batch_loss: 0.1918, loss: 0.2629 ||:  43%|####2     | 3659/8583 [02:10<02:28, 33.08it/s]
2023-04-04 00:59:57,417 - INFO - tqdm - accuracy: 0.9050, batch_loss: 0.3573, loss: 0.2626 ||:  46%|####6     | 3967/8583 [02:20<02:56, 26.19it/s]
2023-04-04 01:00:07,506 - INFO - tqdm - accuracy: 0.9050, batch_loss: 0.2497, loss: 0.2628 ||:  50%|####9     | 4255/8583 [02:30<02:14, 32.27it/s]
2023-04-04 01:00:17,617 - INFO - tqdm - accuracy: 0.9051, batch_loss: 0.2545, loss: 0.2627 ||:  53%|#####2    | 4513/8583 [02:40<02:58, 22.86it/s]
2023-04-04 01:00:27,646 - INFO - tqdm - accuracy: 0.9050, batch_loss: 0.3050, loss: 0.2627 ||:  56%|#####6    | 4824/8583 [02:51<01:44, 36.12it/s]
2023-04-04 01:00:37,681 - INFO - tqdm - accuracy: 0.9048, batch_loss: 0.2593, loss: 0.2632 ||:  60%|#####9    | 5117/8583 [03:01<02:20, 24.59it/s]
2023-04-04 01:00:47,763 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.1874, loss: 0.2634 ||:  63%|######2   | 5370/8583 [03:11<02:06, 25.34it/s]
2023-04-04 01:00:57,794 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.3193, loss: 0.2636 ||:  66%|######5   | 5635/8583 [03:21<02:02, 24.09it/s]
2023-04-04 01:01:07,858 - INFO - tqdm - accuracy: 0.9045, batch_loss: 0.1604, loss: 0.2633 ||:  69%|######8   | 5896/8583 [03:31<01:32, 28.95it/s]
2023-04-04 01:01:17,911 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.1925, loss: 0.2633 ||:  72%|#######1  | 6178/8583 [03:41<01:36, 24.91it/s]
2023-04-04 01:01:27,950 - INFO - tqdm - accuracy: 0.9046, batch_loss: 0.2579, loss: 0.2633 ||:  75%|#######5  | 6469/8583 [03:51<01:06, 31.65it/s]
2023-04-04 01:01:37,964 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.4047, loss: 0.2636 ||:  79%|#######8  | 6746/8583 [04:01<00:59, 30.66it/s]
2023-04-04 01:01:48,011 - INFO - tqdm - accuracy: 0.9045, batch_loss: 0.3843, loss: 0.2636 ||:  82%|########1 | 7027/8583 [04:11<00:58, 26.43it/s]
2023-04-04 01:01:58,098 - INFO - tqdm - accuracy: 0.9045, batch_loss: 0.2499, loss: 0.2635 ||:  85%|########5 | 7303/8583 [04:21<00:37, 34.34it/s]
2023-04-04 01:02:08,191 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.1863, loss: 0.2636 ||:  89%|########8 | 7628/8583 [04:31<00:28, 33.07it/s]
2023-04-04 01:02:18,250 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.2954, loss: 0.2638 ||:  92%|#########2| 7920/8583 [04:41<00:27, 24.51it/s]
2023-04-04 01:02:28,293 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.2302, loss: 0.2642 ||:  95%|#########5| 8172/8583 [04:51<00:16, 25.24it/s]
2023-04-04 01:02:38,309 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.2882, loss: 0.2642 ||:  98%|#########8| 8434/8583 [05:01<00:04, 32.13it/s]
2023-04-04 01:02:41,486 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.4072, loss: 0.2641 ||: 100%|#########9| 8542/8583 [05:04<00:01, 33.66it/s]
2023-04-04 01:02:41,624 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.3068, loss: 0.2641 ||: 100%|#########9| 8546/8583 [05:04<00:01, 32.07it/s]
2023-04-04 01:02:41,757 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.2480, loss: 0.2641 ||: 100%|#########9| 8550/8583 [05:05<00:01, 31.46it/s]
2023-04-04 01:02:41,874 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.4280, loss: 0.2641 ||: 100%|#########9| 8554/8583 [05:05<00:00, 32.22it/s]
2023-04-04 01:02:41,999 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.2291, loss: 0.2641 ||: 100%|#########9| 8558/8583 [05:05<00:00, 32.17it/s]
2023-04-04 01:02:42,138 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.1521, loss: 0.2641 ||: 100%|#########9| 8562/8583 [05:05<00:00, 31.07it/s]
2023-04-04 01:02:42,286 - INFO - tqdm - accuracy: 0.9044, batch_loss: 0.1561, loss: 0.2640 ||: 100%|#########9| 8566/8583 [05:05<00:00, 29.73it/s]
2023-04-04 01:02:42,388 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.2090, loss: 0.2641 ||: 100%|#########9| 8569/8583 [05:05<00:00, 29.66it/s]
2023-04-04 01:02:42,497 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.2679, loss: 0.2641 ||: 100%|#########9| 8572/8583 [05:05<00:00, 29.02it/s]
2023-04-04 01:02:42,618 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.3422, loss: 0.2641 ||: 100%|#########9| 8576/8583 [05:05<00:00, 30.29it/s]
2023-04-04 01:02:42,757 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.3346, loss: 0.2641 ||: 100%|#########9| 8580/8583 [05:06<00:00, 29.76it/s]
2023-04-04 01:02:42,858 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.3334, loss: 0.2641 ||: 100%|##########| 8583/8583 [05:06<00:00, 29.73it/s]
2023-04-04 01:02:43,266 - INFO - tqdm - accuracy: 0.9043, batch_loss: 0.3334, loss: 0.2641 ||: 100%|##########| 8583/8583 [05:06<00:00, 27.99it/s]
2023-04-04 01:02:43,268 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 01:02:43,269 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 01:02:44,994 - INFO - tqdm - accuracy: 0.8871, batch_loss: 0.2190, loss: 0.3201 ||: 100%|##########| 154/154 [00:01<00:00, 89.31it/s]
2023-04-04 01:02:45,049 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 01:02:45,050 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.904  |     0.887
2023-04-04 01:02:45,051 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   571.043  |       N/A
2023-04-04 01:02:45,052 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.264  |     0.320
2023-04-04 01:02:45,052 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.715  |       N/A
2023-04-04 01:02:45,762 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:09.140105
2023-04-04 01:02:45,763 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:07:13
2023-04-04 01:02:45,763 - INFO - allennlp.training.gradient_descent_trainer - Epoch 17/74
2023-04-04 01:02:45,764 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 01:02:45,766 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 01:02:45,767 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 01:02:45,768 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 01:03:14,710 - INFO - tqdm - accuracy: 0.8594, batch_loss: 0.2982, loss: 0.2982 ||:   0%|          | 1/8583 [00:28<68:59:33, 28.94s/it]
2023-04-04 01:03:24,747 - INFO - tqdm - accuracy: 0.9083, batch_loss: 0.2061, loss: 0.2578 ||:   3%|2         | 253/8583 [00:38<05:32, 25.07it/s]
2023-04-04 01:03:34,776 - INFO - tqdm - accuracy: 0.9061, batch_loss: 0.2488, loss: 0.2599 ||:   7%|6         | 559/8583 [00:49<04:27, 29.98it/s]
2023-04-04 01:03:44,912 - INFO - tqdm - accuracy: 0.9039, batch_loss: 0.2873, loss: 0.2643 ||:  10%|9         | 855/8583 [00:59<05:29, 23.48it/s]
2023-04-04 01:03:54,923 - INFO - tqdm - accuracy: 0.9051, batch_loss: 0.1551, loss: 0.2618 ||:  14%|#3        | 1165/8583 [01:09<04:23, 28.17it/s]
2023-04-04 01:04:04,975 - INFO - tqdm - accuracy: 0.9050, batch_loss: 0.2723, loss: 0.2622 ||:  17%|#6        | 1434/8583 [01:19<04:22, 27.26it/s]
2023-04-04 01:04:15,049 - INFO - tqdm - accuracy: 0.9052, batch_loss: 0.4053, loss: 0.2623 ||:  20%|##        | 1754/8583 [01:29<03:46, 30.19it/s]
2023-04-04 01:04:25,134 - INFO - tqdm - accuracy: 0.9048, batch_loss: 0.1780, loss: 0.2626 ||:  24%|##3       | 2041/8583 [01:39<04:36, 23.62it/s]
2023-04-04 01:04:35,201 - INFO - tqdm - accuracy: 0.9047, batch_loss: 0.3087, loss: 0.2622 ||:  28%|##7       | 2372/8583 [01:49<03:07, 33.13it/s]
2023-04-04 01:04:45,223 - INFO - tqdm - accuracy: 0.9048, batch_loss: 0.3088, loss: 0.2620 ||:  31%|###       | 2629/8583 [01:59<03:42, 26.80it/s]
2023-04-04 01:04:55,351 - INFO - tqdm - accuracy: 0.9049, batch_loss: 0.2517, loss: 0.2621 ||:  34%|###3      | 2882/8583 [02:09<04:09, 22.82it/s]
2023-04-04 01:05:05,470 - INFO - tqdm - accuracy: 0.9050, batch_loss: 0.1825, loss: 0.2619 ||:  36%|###6      | 3108/8583 [02:19<04:07, 22.09it/s]
2023-04-04 01:05:15,477 - INFO - tqdm - accuracy: 0.9054, batch_loss: 0.2328, loss: 0.2611 ||:  39%|###9      | 3387/8583 [02:29<03:02, 28.40it/s]
2023-04-04 01:05:25,545 - INFO - tqdm - accuracy: 0.9056, batch_loss: 0.2639, loss: 0.2606 ||:  43%|####3     | 3692/8583 [02:39<02:19, 35.00it/s]
2023-04-04 01:05:35,602 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.3729, loss: 0.2609 ||:  47%|####6     | 4026/8583 [02:49<02:10, 34.88it/s]
2023-04-04 01:05:45,684 - INFO - tqdm - accuracy: 0.9053, batch_loss: 0.1391, loss: 0.2609 ||:  51%|#####     | 4340/8583 [02:59<02:40, 26.42it/s]
2023-04-04 01:05:55,776 - INFO - tqdm - accuracy: 0.9052, batch_loss: 0.3538, loss: 0.2611 ||:  54%|#####3    | 4624/8583 [03:10<02:05, 31.63it/s]
2023-04-04 01:06:05,865 - INFO - tqdm - accuracy: 0.9054, batch_loss: 0.1570, loss: 0.2608 ||:  58%|#####7    | 4959/8583 [03:20<02:11, 27.51it/s]
2023-04-04 01:06:15,936 - INFO - tqdm - accuracy: 0.9054, batch_loss: 0.2093, loss: 0.2610 ||:  62%|######1   | 5303/8583 [03:30<01:35, 34.40it/s]
2023-04-04 01:06:25,988 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.1779, loss: 0.2609 ||:  65%|######5   | 5593/8583 [03:40<01:55, 25.82it/s]
2023-04-04 01:06:36,006 - INFO - tqdm - accuracy: 0.9054, batch_loss: 0.2908, loss: 0.2607 ||:  68%|######8   | 5846/8583 [03:50<01:44, 26.07it/s]
2023-04-04 01:06:46,086 - INFO - tqdm - accuracy: 0.9053, batch_loss: 0.1557, loss: 0.2611 ||:  71%|#######1  | 6120/8583 [04:00<01:45, 23.33it/s]
2023-04-04 01:06:56,106 - INFO - tqdm - accuracy: 0.9054, batch_loss: 0.2613, loss: 0.2608 ||:  75%|#######4  | 6425/8583 [04:10<01:01, 35.28it/s]
2023-04-04 01:07:06,197 - INFO - tqdm - accuracy: 0.9053, batch_loss: 0.2340, loss: 0.2612 ||:  78%|#######8  | 6716/8583 [04:20<00:58, 31.97it/s]
2023-04-04 01:07:16,238 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.2943, loss: 0.2609 ||:  81%|########1 | 6971/8583 [04:30<01:01, 26.16it/s]
2023-04-04 01:07:26,309 - INFO - tqdm - accuracy: 0.9056, batch_loss: 0.0655, loss: 0.2606 ||:  84%|########4 | 7252/8583 [04:40<00:41, 32.41it/s]
2023-04-04 01:07:36,318 - INFO - tqdm - accuracy: 0.9056, batch_loss: 0.2240, loss: 0.2607 ||:  89%|########8 | 7598/8583 [04:50<00:30, 31.78it/s]
2023-04-04 01:07:46,407 - INFO - tqdm - accuracy: 0.9056, batch_loss: 0.1809, loss: 0.2610 ||:  92%|#########2| 7899/8583 [05:00<00:20, 33.69it/s]
2023-04-04 01:07:56,423 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.2554, loss: 0.2612 ||:  96%|#########5| 8236/8583 [05:10<00:08, 38.79it/s]
2023-04-04 01:08:04,850 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.3346, loss: 0.2615 ||: 100%|#########9| 8542/8583 [05:19<00:01, 34.44it/s]
2023-04-04 01:08:04,958 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.4636, loss: 0.2615 ||: 100%|#########9| 8546/8583 [05:19<00:01, 35.24it/s]
2023-04-04 01:08:05,070 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.2857, loss: 0.2615 ||: 100%|#########9| 8550/8583 [05:19<00:00, 35.32it/s]
2023-04-04 01:08:05,172 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.2271, loss: 0.2615 ||: 100%|#########9| 8554/8583 [05:19<00:00, 36.42it/s]
2023-04-04 01:08:05,279 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.1964, loss: 0.2615 ||: 100%|#########9| 8558/8583 [05:19<00:00, 36.78it/s]
2023-04-04 01:08:05,394 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.1915, loss: 0.2615 ||: 100%|#########9| 8562/8583 [05:19<00:00, 36.15it/s]
2023-04-04 01:08:05,497 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.1964, loss: 0.2615 ||: 100%|#########9| 8566/8583 [05:19<00:00, 36.83it/s]
2023-04-04 01:08:05,609 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.2383, loss: 0.2615 ||: 100%|#########9| 8570/8583 [05:19<00:00, 36.53it/s]
2023-04-04 01:08:05,714 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.3230, loss: 0.2615 ||: 100%|#########9| 8574/8583 [05:19<00:00, 37.00it/s]
2023-04-04 01:08:05,822 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.5333, loss: 0.2616 ||: 100%|#########9| 8578/8583 [05:20<00:00, 37.02it/s]
2023-04-04 01:08:05,945 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.1734, loss: 0.2615 ||: 100%|#########9| 8582/8583 [05:20<00:00, 35.52it/s]
2023-04-04 01:08:06,373 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.2454, loss: 0.2615 ||: 100%|##########| 8583/8583 [05:20<00:00, 26.77it/s]
2023-04-04 01:08:06,375 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 01:08:06,376 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 01:08:08,061 - INFO - tqdm - accuracy: 0.8862, batch_loss: 0.2909, loss: 0.3167 ||: 100%|##########| 154/154 [00:01<00:00, 91.42it/s]
2023-04-04 01:08:08,070 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 01:08:08,071 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.905  |     0.886
2023-04-04 01:08:08,071 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   569.716  |       N/A
2023-04-04 01:08:08,072 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.262  |     0.317
2023-04-04 01:08:08,073 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.719  |       N/A
2023-04-04 01:08:08,785 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:05:23.021688
2023-04-04 01:08:08,786 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 5:02:12
2023-04-04 01:08:08,787 - INFO - allennlp.training.gradient_descent_trainer - Epoch 18/74
2023-04-04 01:08:08,788 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 01:08:08,789 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 555M
2023-04-04 01:08:08,790 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 01:08:08,791 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 01:08:18,860 - INFO - tqdm - accuracy: 0.9029, batch_loss: 0.4434, loss: 0.2676 ||:   2%|1         | 141/8583 [00:10<05:17, 26.59it/s]
2023-04-04 01:08:28,868 - INFO - tqdm - accuracy: 0.9063, batch_loss: 0.1985, loss: 0.2619 ||:   6%|5         | 478/8583 [00:20<04:03, 33.27it/s]
2023-04-04 01:08:38,880 - INFO - tqdm - accuracy: 0.9058, batch_loss: 0.2557, loss: 0.2621 ||:   9%|9         | 785/8583 [00:30<04:37, 28.06it/s]
2023-04-04 01:08:48,965 - INFO - tqdm - accuracy: 0.9062, batch_loss: 0.1672, loss: 0.2605 ||:  13%|#2        | 1112/8583 [00:40<03:33, 34.95it/s]
2023-04-04 01:08:58,977 - INFO - tqdm - accuracy: 0.9060, batch_loss: 0.2911, loss: 0.2613 ||:  17%|#6        | 1430/8583 [00:50<04:00, 29.74it/s]
2023-04-04 01:09:09,104 - INFO - tqdm - accuracy: 0.9060, batch_loss: 0.2173, loss: 0.2614 ||:  20%|#9        | 1711/8583 [01:00<04:49, 23.76it/s]
2023-04-04 01:09:19,175 - INFO - tqdm - accuracy: 0.9063, batch_loss: 0.1161, loss: 0.2607 ||:  24%|##3       | 2041/8583 [01:10<03:12, 33.96it/s]
2023-04-04 01:09:29,217 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1103, loss: 0.2593 ||:  27%|##7       | 2350/8583 [01:20<03:16, 31.65it/s]
2023-04-04 01:09:39,265 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.2339, loss: 0.2591 ||:  32%|###1      | 2718/8583 [01:30<03:02, 32.20it/s]
2023-04-04 01:09:49,308 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.4297, loss: 0.2590 ||:  35%|###5      | 3039/8583 [01:40<02:39, 34.74it/s]
2023-04-04 01:09:59,335 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.3319, loss: 0.2593 ||:  39%|###9      | 3379/8583 [01:50<02:27, 35.34it/s]
2023-04-04 01:10:09,399 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.4615, loss: 0.2596 ||:  43%|####3     | 3724/8583 [02:00<02:17, 35.23it/s]
2023-04-04 01:10:19,491 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.1383, loss: 0.2592 ||:  47%|####7     | 4037/8583 [02:10<02:15, 33.64it/s]
2023-04-04 01:10:29,514 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.3009, loss: 0.2592 ||:  50%|#####     | 4304/8583 [02:20<02:51, 25.00it/s]
2023-04-04 01:10:39,532 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.2069, loss: 0.2590 ||:  54%|#####3    | 4621/8583 [02:30<02:24, 27.49it/s]
2023-04-04 01:10:49,554 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.1128, loss: 0.2587 ||:  57%|#####7    | 4901/8583 [02:40<02:20, 26.15it/s]
2023-04-04 01:10:59,676 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.1579, loss: 0.2586 ||:  60%|######    | 5168/8583 [02:50<02:14, 25.37it/s]
2023-04-04 01:11:09,758 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.2175, loss: 0.2587 ||:  63%|######3   | 5430/8583 [03:00<01:59, 26.41it/s]
2023-04-04 01:11:19,800 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2302, loss: 0.2590 ||:  67%|######6   | 5720/8583 [03:11<01:16, 37.30it/s]
2023-04-04 01:11:29,879 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.2135, loss: 0.2586 ||:  70%|#######   | 6049/8583 [03:21<01:14, 34.11it/s]
2023-04-04 01:11:39,889 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2667, loss: 0.2589 ||:  75%|#######4  | 6409/8583 [03:31<01:11, 30.47it/s]
2023-04-04 01:11:49,995 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.1842, loss: 0.2585 ||:  78%|#######7  | 6677/8583 [03:41<01:12, 26.21it/s]
2023-04-04 01:12:00,088 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.3137, loss: 0.2585 ||:  81%|########  | 6946/8583 [03:51<01:08, 23.97it/s]
2023-04-04 01:12:10,098 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.2180, loss: 0.2587 ||:  85%|########4 | 7258/8583 [04:01<00:42, 31.25it/s]
2023-04-04 01:12:20,125 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.3626, loss: 0.2582 ||:  88%|########8 | 7574/8583 [04:11<00:29, 34.72it/s]
2023-04-04 01:12:30,191 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.2515, loss: 0.2584 ||:  92%|#########1| 7876/8583 [04:21<00:20, 34.03it/s]
2023-04-04 01:12:40,204 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.1860, loss: 0.2586 ||:  96%|#########5| 8225/8583 [04:31<00:11, 30.65it/s]
2023-04-04 01:12:50,204 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2491, loss: 0.2587 ||:  99%|#########9| 8530/8583 [04:41<00:01, 27.44it/s]
2023-04-04 01:12:50,803 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2908, loss: 0.2587 ||: 100%|#########9| 8543/8583 [04:42<00:01, 24.52it/s]
2023-04-04 01:12:50,907 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1664, loss: 0.2587 ||: 100%|#########9| 8546/8583 [04:42<00:01, 25.61it/s]
2023-04-04 01:12:51,263 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2152, loss: 0.2587 ||: 100%|#########9| 8549/8583 [04:42<00:02, 16.12it/s]
2023-04-04 01:12:51,391 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1013, loss: 0.2587 ||: 100%|#########9| 8552/8583 [04:42<00:01, 17.75it/s]
2023-04-04 01:12:51,502 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2147, loss: 0.2587 ||: 100%|#########9| 8555/8583 [04:42<00:01, 19.74it/s]
2023-04-04 01:12:51,605 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.3123, loss: 0.2587 ||: 100%|#########9| 8558/8583 [04:42<00:01, 21.82it/s]
2023-04-04 01:12:51,718 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.3792, loss: 0.2587 ||: 100%|#########9| 8561/8583 [04:42<00:00, 23.03it/s]
2023-04-04 01:12:51,827 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2285, loss: 0.2587 ||: 100%|#########9| 8564/8583 [04:43<00:00, 24.22it/s]
2023-04-04 01:12:51,932 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1940, loss: 0.2587 ||: 100%|#########9| 8567/8583 [04:43<00:00, 25.39it/s]
2023-04-04 01:12:52,040 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1611, loss: 0.2587 ||: 100%|#########9| 8570/8583 [04:43<00:00, 26.04it/s]
2023-04-04 01:12:52,160 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1154, loss: 0.2587 ||: 100%|#########9| 8574/8583 [04:43<00:00, 28.26it/s]
2023-04-04 01:12:52,275 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2719, loss: 0.2587 ||: 100%|#########9| 8578/8583 [04:43<00:00, 30.22it/s]
2023-04-04 01:12:52,402 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1387, loss: 0.2587 ||: 100%|#########9| 8582/8583 [04:43<00:00, 30.59it/s]
2023-04-04 01:12:52,809 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.1913, loss: 0.2587 ||: 100%|##########| 8583/8583 [04:44<00:00, 30.22it/s]
2023-04-04 01:12:52,812 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 01:12:52,813 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 01:12:54,493 - INFO - tqdm - accuracy: 0.8866, batch_loss: 0.2873, loss: 0.3191 ||: 100%|##########| 154/154 [00:01<00:00, 91.80it/s]
2023-04-04 01:12:54,507 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 01:12:54,508 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.906  |     0.887
2023-04-04 01:12:54,509 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   554.675  |       N/A
2023-04-04 01:12:54,509 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.259  |     0.319
2023-04-04 01:12:54,510 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.719  |       N/A
2023-04-04 01:12:55,164 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:04:46.376865
2023-04-04 01:12:55,165 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 4:55:21
2023-04-04 01:12:55,166 - INFO - allennlp.training.gradient_descent_trainer - Epoch 19/74
2023-04-04 01:12:55,166 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 01:12:55,168 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 01:12:55,169 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 01:12:55,170 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 01:13:14,413 - INFO - tqdm - accuracy: 0.8594, batch_loss: 0.2940, loss: 0.2940 ||:   0%|          | 1/8583 [00:19<45:52:16, 19.24s/it]
2023-04-04 01:13:24,499 - INFO - tqdm - accuracy: 0.9056, batch_loss: 0.3554, loss: 0.2595 ||:   4%|3         | 328/8583 [00:29<04:20, 31.74it/s]
2023-04-04 01:13:34,605 - INFO - tqdm - accuracy: 0.9047, batch_loss: 0.1309, loss: 0.2596 ||:   7%|7         | 603/8583 [00:39<04:48, 27.67it/s]
2023-04-04 01:13:44,701 - INFO - tqdm - accuracy: 0.9031, batch_loss: 0.4571, loss: 0.2646 ||:  10%|#         | 871/8583 [00:49<04:00, 32.04it/s]
2023-04-04 01:13:54,711 - INFO - tqdm - accuracy: 0.9047, batch_loss: 0.2359, loss: 0.2627 ||:  14%|#4        | 1225/8583 [00:59<03:53, 31.52it/s]
2023-04-04 01:14:04,743 - INFO - tqdm - accuracy: 0.9055, batch_loss: 0.2311, loss: 0.2613 ||:  18%|#7        | 1509/8583 [01:09<04:09, 28.30it/s]
2023-04-04 01:14:14,765 - INFO - tqdm - accuracy: 0.9060, batch_loss: 0.2235, loss: 0.2605 ||:  21%|##1       | 1812/8583 [01:19<04:12, 26.79it/s]
2023-04-04 01:14:24,790 - INFO - tqdm - accuracy: 0.9063, batch_loss: 0.4207, loss: 0.2594 ||:  25%|##4       | 2115/8583 [01:29<03:09, 34.11it/s]
2023-04-04 01:14:34,798 - INFO - tqdm - accuracy: 0.9064, batch_loss: 0.2737, loss: 0.2592 ||:  28%|##8       | 2437/8583 [01:39<03:00, 34.11it/s]
2023-04-04 01:14:44,859 - INFO - tqdm - accuracy: 0.9064, batch_loss: 0.2620, loss: 0.2590 ||:  31%|###1      | 2698/8583 [01:49<03:39, 26.75it/s]
2023-04-04 01:14:54,938 - INFO - tqdm - accuracy: 0.9062, batch_loss: 0.1615, loss: 0.2590 ||:  35%|###4      | 2973/8583 [01:59<03:28, 26.89it/s]
2023-04-04 01:15:05,054 - INFO - tqdm - accuracy: 0.9064, batch_loss: 0.3390, loss: 0.2586 ||:  38%|###8      | 3289/8583 [02:09<02:54, 30.39it/s]
2023-04-04 01:15:15,168 - INFO - tqdm - accuracy: 0.9063, batch_loss: 0.2017, loss: 0.2588 ||:  41%|####1     | 3560/8583 [02:19<02:46, 30.13it/s]
2023-04-04 01:15:25,258 - INFO - tqdm - accuracy: 0.9063, batch_loss: 0.1566, loss: 0.2586 ||:  46%|####5     | 3922/8583 [02:30<02:00, 38.52it/s]
2023-04-04 01:15:35,336 - INFO - tqdm - accuracy: 0.9063, batch_loss: 0.3127, loss: 0.2586 ||:  50%|#####     | 4292/8583 [02:40<02:01, 35.18it/s]
2023-04-04 01:15:45,341 - INFO - tqdm - accuracy: 0.9063, batch_loss: 0.3672, loss: 0.2583 ||:  54%|#####3    | 4595/8583 [02:50<02:05, 31.75it/s]
2023-04-04 01:15:55,368 - INFO - tqdm - accuracy: 0.9064, batch_loss: 0.3165, loss: 0.2581 ||:  57%|#####7    | 4915/8583 [03:00<02:28, 24.78it/s]
2023-04-04 01:16:05,415 - INFO - tqdm - accuracy: 0.9064, batch_loss: 0.1222, loss: 0.2580 ||:  61%|######    | 5198/8583 [03:10<02:08, 26.42it/s]
2023-04-04 01:16:15,475 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2921, loss: 0.2578 ||:  65%|######4   | 5538/8583 [03:20<01:29, 33.83it/s]
2023-04-04 01:16:25,520 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2493, loss: 0.2577 ||:  68%|######7   | 5823/8583 [03:30<01:42, 26.85it/s]
2023-04-04 01:16:35,544 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.3625, loss: 0.2577 ||:  71%|#######1  | 6098/8583 [03:40<01:35, 26.09it/s]
2023-04-04 01:16:45,617 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.2018, loss: 0.2575 ||:  75%|#######4  | 6410/8583 [03:50<00:58, 37.16it/s]
2023-04-04 01:16:55,680 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.3966, loss: 0.2575 ||:  79%|#######9  | 6781/8583 [04:00<00:47, 38.11it/s]
2023-04-04 01:17:05,713 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.1729, loss: 0.2573 ||:  83%|########3 | 7155/8583 [04:10<00:38, 36.62it/s]
2023-04-04 01:17:15,773 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.2084, loss: 0.2570 ||:  87%|########7 | 7506/8583 [04:20<00:27, 38.69it/s]
2023-04-04 01:17:25,853 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2758, loss: 0.2566 ||:  92%|#########1| 7893/8583 [04:30<00:18, 37.48it/s]
2023-04-04 01:17:35,941 - INFO - tqdm - accuracy: 0.9069, batch_loss: 0.1375, loss: 0.2567 ||:  96%|#########6| 8269/8583 [04:40<00:08, 37.92it/s]
2023-04-04 01:17:44,096 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2491, loss: 0.2567 ||: 100%|#########9| 8541/8583 [04:48<00:01, 34.27it/s]
2023-04-04 01:17:44,215 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2105, loss: 0.2567 ||: 100%|#########9| 8545/8583 [04:49<00:01, 34.05it/s]
2023-04-04 01:17:44,328 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2182, loss: 0.2567 ||: 100%|#########9| 8549/8583 [04:49<00:00, 34.45it/s]
2023-04-04 01:17:44,444 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2631, loss: 0.2567 ||: 100%|#########9| 8553/8583 [04:49<00:00, 34.53it/s]
2023-04-04 01:17:44,554 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2523, loss: 0.2567 ||: 100%|#########9| 8557/8583 [04:49<00:00, 35.06it/s]
2023-04-04 01:17:44,665 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.3863, loss: 0.2567 ||: 100%|#########9| 8561/8583 [04:49<00:00, 35.29it/s]
2023-04-04 01:17:44,777 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.1740, loss: 0.2567 ||: 100%|#########9| 8565/8583 [04:49<00:00, 35.45it/s]
2023-04-04 01:17:44,895 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.3391, loss: 0.2567 ||: 100%|#########9| 8569/8583 [04:49<00:00, 34.97it/s]
2023-04-04 01:17:45,008 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.1008, loss: 0.2567 ||: 100%|#########9| 8573/8583 [04:49<00:00, 35.09it/s]
2023-04-04 01:17:45,127 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2864, loss: 0.2567 ||: 100%|#########9| 8577/8583 [04:49<00:00, 34.59it/s]
2023-04-04 01:17:45,241 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2858, loss: 0.2567 ||: 100%|#########9| 8581/8583 [04:50<00:00, 34.75it/s]
2023-04-04 01:17:45,677 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.1375, loss: 0.2567 ||: 100%|##########| 8583/8583 [04:50<00:00, 29.54it/s]
2023-04-04 01:17:45,678 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 01:17:45,679 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 01:17:47,346 - INFO - tqdm - accuracy: 0.8865, batch_loss: 0.6377, loss: 0.3193 ||: 100%|##########| 154/154 [00:01<00:00, 92.47it/s]
2023-04-04 01:17:47,369 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 01:17:47,369 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.907  |     0.887
2023-04-04 01:17:47,370 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.099  |       N/A
2023-04-04 01:17:47,371 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.257  |     0.319
2023-04-04 01:17:47,371 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.719  |       N/A
2023-04-04 01:17:48,141 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:04:52.975688
2023-04-04 01:17:48,142 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 4:48:59
2023-04-04 01:17:48,143 - INFO - allennlp.training.gradient_descent_trainer - Epoch 20/74
2023-04-04 01:17:48,144 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 01:17:48,144 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 567M
2023-04-04 01:17:48,146 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 01:17:48,146 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 01:17:58,250 - INFO - tqdm - accuracy: 0.9083, batch_loss: 0.2685, loss: 0.2543 ||:   2%|2         | 187/8583 [00:10<03:53, 35.95it/s]
2023-04-04 01:18:08,278 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.2897, loss: 0.2558 ||:   6%|5         | 509/8583 [00:20<04:58, 27.02it/s]
2023-04-04 01:18:18,364 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2749, loss: 0.2552 ||:  10%|#         | 871/8583 [00:30<03:27, 37.17it/s]
2023-04-04 01:18:28,423 - INFO - tqdm - accuracy: 0.9067, batch_loss: 0.2229, loss: 0.2565 ||:  14%|#4        | 1238/8583 [00:40<03:22, 36.30it/s]
2023-04-04 01:18:38,474 - INFO - tqdm - accuracy: 0.9068, batch_loss: 0.2598, loss: 0.2571 ||:  19%|#8        | 1623/8583 [00:50<03:17, 35.29it/s]
2023-04-04 01:18:48,571 - INFO - tqdm - accuracy: 0.9069, batch_loss: 0.2288, loss: 0.2572 ||:  22%|##2       | 1895/8583 [01:00<04:24, 25.27it/s]
2023-04-04 01:18:58,662 - INFO - tqdm - accuracy: 0.9071, batch_loss: 0.2634, loss: 0.2568 ||:  26%|##5       | 2200/8583 [01:10<03:55, 27.05it/s]
2023-04-04 01:19:08,721 - INFO - tqdm - accuracy: 0.9066, batch_loss: 0.4524, loss: 0.2578 ||:  30%|##9       | 2561/8583 [01:20<02:37, 38.28it/s]
2023-04-04 01:19:18,778 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.3390, loss: 0.2580 ||:  34%|###4      | 2941/8583 [01:30<02:24, 38.96it/s]
2023-04-04 01:19:28,837 - INFO - tqdm - accuracy: 0.9065, batch_loss: 0.3514, loss: 0.2578 ||:  38%|###8      | 3301/8583 [01:40<02:28, 35.66it/s]
2023-04-04 01:19:38,872 - INFO - tqdm - accuracy: 0.9070, batch_loss: 0.2753, loss: 0.2566 ||:  43%|####2     | 3672/8583 [01:50<02:20, 35.01it/s]
2023-04-04 01:19:48,887 - INFO - tqdm - accuracy: 0.9072, batch_loss: 0.3354, loss: 0.2565 ||:  47%|####7     | 4053/8583 [02:00<01:58, 38.39it/s]
2023-04-04 01:19:58,949 - INFO - tqdm - accuracy: 0.9072, batch_loss: 0.2910, loss: 0.2567 ||:  52%|#####1    | 4433/8583 [02:10<01:54, 36.36it/s]
2023-04-04 01:20:09,015 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2421, loss: 0.2561 ||:  55%|#####5    | 4759/8583 [02:20<01:42, 37.37it/s]
2023-04-04 01:20:19,027 - INFO - tqdm - accuracy: 0.9073, batch_loss: 0.3068, loss: 0.2564 ||:  60%|#####9    | 5129/8583 [02:30<01:36, 35.97it/s]
2023-04-04 01:20:29,116 - INFO - tqdm - accuracy: 0.9072, batch_loss: 0.3053, loss: 0.2564 ||:  64%|######3   | 5476/8583 [02:40<01:23, 37.40it/s]
2023-04-04 01:20:39,160 - INFO - tqdm - accuracy: 0.9072, batch_loss: 0.2833, loss: 0.2567 ||:  67%|######7   | 5779/8583 [02:51<01:23, 33.48it/s]
2023-04-04 01:20:49,196 - INFO - tqdm - accuracy: 0.9071, batch_loss: 0.2720, loss: 0.2569 ||:  71%|#######   | 6062/8583 [03:01<01:31, 27.62it/s]
2023-04-04 01:20:59,207 - INFO - tqdm - accuracy: 0.9072, batch_loss: 0.2762, loss: 0.2568 ||:  74%|#######3  | 6330/8583 [03:11<01:21, 27.57it/s]
2023-04-04 01:21:09,296 - INFO - tqdm - accuracy: 0.9072, batch_loss: 0.1520, loss: 0.2567 ||:  77%|#######7  | 6610/8583 [03:21<01:03, 30.86it/s]
2023-04-04 01:21:19,307 - INFO - tqdm - accuracy: 0.9073, batch_loss: 0.1843, loss: 0.2564 ||:  81%|########  | 6911/8583 [03:31<01:03, 26.23it/s]
2023-04-04 01:21:29,336 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2409, loss: 0.2562 ||:  84%|########3 | 7191/8583 [03:41<00:52, 26.63it/s]
2023-04-04 01:21:39,395 - INFO - tqdm - accuracy: 0.9073, batch_loss: 0.2691, loss: 0.2561 ||:  88%|########7 | 7551/8583 [03:51<00:25, 40.14it/s]
2023-04-04 01:21:49,415 - INFO - tqdm - accuracy: 0.9073, batch_loss: 0.2581, loss: 0.2561 ||:  92%|#########1| 7873/8583 [04:01<00:20, 34.53it/s]
2023-04-04 01:21:59,446 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2794, loss: 0.2560 ||:  95%|#########5| 8189/8583 [04:11<00:15, 26.23it/s]
2023-04-04 01:22:09,390 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2068, loss: 0.2561 ||: 100%|#########9| 8542/8583 [04:21<00:01, 38.63it/s]
2023-04-04 01:22:09,505 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.3248, loss: 0.2561 ||: 100%|#########9| 8546/8583 [04:21<00:00, 37.42it/s]
2023-04-04 01:22:09,629 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2119, loss: 0.2561 ||: 100%|#########9| 8550/8583 [04:21<00:00, 35.70it/s]
2023-04-04 01:22:09,756 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2635, loss: 0.2561 ||: 100%|#########9| 8554/8583 [04:21<00:00, 34.34it/s]
2023-04-04 01:22:09,863 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2563, loss: 0.2561 ||: 100%|#########9| 8558/8583 [04:21<00:00, 35.18it/s]
2023-04-04 01:22:09,973 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.1949, loss: 0.2561 ||: 100%|#########9| 8562/8583 [04:21<00:00, 35.54it/s]
2023-04-04 01:22:10,092 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.1371, loss: 0.2561 ||: 100%|#########9| 8566/8583 [04:21<00:00, 34.95it/s]
2023-04-04 01:22:10,197 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.3471, loss: 0.2561 ||: 100%|#########9| 8570/8583 [04:22<00:00, 35.83it/s]
2023-04-04 01:22:10,329 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2759, loss: 0.2561 ||: 100%|#########9| 8574/8583 [04:22<00:00, 33.99it/s]
2023-04-04 01:22:10,436 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.4124, loss: 0.2561 ||: 100%|#########9| 8578/8583 [04:22<00:00, 34.92it/s]
2023-04-04 01:22:10,537 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2329, loss: 0.2561 ||: 100%|#########9| 8582/8583 [04:22<00:00, 36.21it/s]
2023-04-04 01:22:10,938 - INFO - tqdm - accuracy: 0.9074, batch_loss: 0.2613, loss: 0.2561 ||: 100%|##########| 8583/8583 [04:22<00:00, 32.66it/s]
2023-04-04 01:22:10,940 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 01:22:10,941 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 01:22:12,650 - INFO - tqdm - accuracy: 0.8866, batch_loss: 0.3129, loss: 0.3193 ||: 100%|##########| 154/154 [00:01<00:00, 90.13it/s]
2023-04-04 01:22:12,660 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 01:22:12,661 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.907  |     0.887
2023-04-04 01:22:12,662 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   566.934  |       N/A
2023-04-04 01:22:12,662 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.256  |     0.319
2023-04-04 01:22:12,663 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.719  |       N/A
2023-04-04 01:22:13,438 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:04:25.294981
2023-04-04 01:22:13,439 - INFO - allennlp.training.gradient_descent_trainer - Estimated training time remaining: 4:41:36
2023-04-04 01:22:13,439 - INFO - allennlp.training.gradient_descent_trainer - Epoch 21/74
2023-04-04 01:22:13,440 - INFO - allennlp.training.gradient_descent_trainer - Worker 0 memory usage: 7.6G
2023-04-04 01:22:13,442 - INFO - allennlp.training.gradient_descent_trainer - GPU 0 memory usage: 570M
2023-04-04 01:22:13,443 - INFO - allennlp.training.gradient_descent_trainer - Training
2023-04-04 01:22:13,444 - INFO - tqdm - 0%|          | 0/8583 [00:00<?, ?it/s]
2023-04-04 01:22:23,469 - INFO - tqdm - accuracy: 0.9028, batch_loss: 0.2596, loss: 0.2746 ||:   2%|1         | 170/8583 [00:10<04:18, 32.58it/s]
2023-04-04 01:22:33,476 - INFO - tqdm - accuracy: 0.9073, batch_loss: 0.2521, loss: 0.2580 ||:   6%|6         | 532/8583 [00:20<03:36, 37.14it/s]
2023-04-04 01:22:43,574 - INFO - tqdm - accuracy: 0.9081, batch_loss: 0.1700, loss: 0.2565 ||:  11%|#         | 908/8583 [00:30<03:18, 38.62it/s]
2023-04-04 01:22:53,677 - INFO - tqdm - accuracy: 0.9075, batch_loss: 0.4193, loss: 0.2573 ||:  15%|#4        | 1283/8583 [00:40<03:28, 34.99it/s]
2023-04-04 01:23:03,730 - INFO - tqdm - accuracy: 0.9078, batch_loss: 0.1542, loss: 0.2564 ||:  19%|#8        | 1606/8583 [00:50<03:58, 29.23it/s]
2023-04-04 01:23:13,784 - INFO - tqdm - accuracy: 0.9075, batch_loss: 0.1943, loss: 0.2570 ||:  22%|##2       | 1903/8583 [01:00<03:09, 35.24it/s]
2023-04-04 01:23:23,790 - INFO - tqdm - accuracy: 0.9076, batch_loss: 0.1237, loss: 0.2565 ||:  27%|##6       | 2281/8583 [01:10<02:58, 35.32it/s]
2023-04-04 01:23:33,838 - INFO - tqdm - accuracy: 0.9077, batch_loss: 0.3567, loss: 0.2557 ||:  31%|###       | 2651/8583 [01:20<03:16, 30.20it/s]
2023-04-04 01:23:43,906 - INFO - tqdm - accuracy: 0.9076, batch_loss: 0.2896, loss: 0.2558 ||:  34%|###4      | 2925/8583 [01:30<03:29, 27.04it/s]
2023-04-04 01:23:53,976 - INFO - tqdm - accuracy: 0.9077, batch_loss: 0.3594, loss: 0.2554 ||:  37%|###7      | 3215/8583 [01:40<02:30, 35.57it/s]
2023-04-04 01:24:04,022 - INFO - tqdm - accuracy: 0.9076, batch_loss: 0.3784, loss: 0.2558 ||:  42%|####1     | 3579/8583 [01:50<02:12, 37.63it/s]
2023-04-04 01:24:14,065 - INFO - tqdm - accuracy: 0.9076, batch_loss: 0.1448, loss: 0.2554 ||:  46%|####5     | 3907/8583 [02:00<02:40, 29.15it/s]
2023-04-04 01:24:24,166 - INFO - tqdm - accuracy: 0.9078, batch_loss: 0.1669, loss: 0.2548 ||:  49%|####9     | 4220/8583 [02:10<02:37, 27.77it/s]
2023-04-04 01:24:34,209 - INFO - tqdm - accuracy: 0.9080, batch_loss: 0.2907, loss: 0.2546 ||:  53%|#####2    | 4526/8583 [02:20<01:49, 36.96it/s]
2023-04-04 01:24:44,262 - INFO - tqdm - accuracy: 0.9079, batch_loss: 0.3491, loss: 0.2546 ||:  57%|#####7    | 4902/8583 [02:30<01:35, 38.56it/s]
2023-04-04 01:24:54,369 - INFO - tqdm - accuracy: 0.9078, batch_loss: 0.1529, loss: 0.2549 ||:  62%|######1   | 5292/8583 [02:40<01:20, 40.71it/s]
2023-04-04 01:25:04,392 - INFO - tqdm - accuracy: 0.9079, batch_loss: 0.3138, loss: 0.2545 ||:  65%|######4   | 5562/8583 [02:50<01:50, 27.34it/s]
2023-04-04 01:25:14,411 - INFO - tqdm - accuracy: 0.9081, batch_loss: 0.3548, loss: 0.2543 ||:  68%|######7   | 5830/8583 [03:00<01:29, 30.89it/s]
2023-04-04 01:25:24,419 - INFO - tqdm - accuracy: 0.9081, batch_loss: 0.2583, loss: 0.2543 ||:  71%|#######1  | 6106/8583 [03:10<01:20, 30.92it/s]
2023-04-04 01:25:34,529 - INFO - tqdm - accuracy: 0.9081, batch_loss: 0.2962, loss: 0.2544 ||:  75%|#######4  | 6398/8583 [03:21<01:24, 26.01it/s]
2023-04-04 01:25:44,593 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3140, loss: 0.2540 ||:  79%|#######8  | 6748/8583 [03:31<00:48, 37.88it/s]
2023-04-04 01:25:54,690 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.2834, loss: 0.2543 ||:  82%|########2 | 7042/8583 [03:41<00:49, 30.91it/s]
2023-04-04 01:26:04,796 - INFO - tqdm - accuracy: 0.9081, batch_loss: 0.1606, loss: 0.2547 ||:  86%|########5 | 7342/8583 [03:51<00:44, 27.60it/s]
2023-04-04 01:26:14,870 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3012, loss: 0.2543 ||:  89%|########9 | 7642/8583 [04:01<00:25, 37.09it/s]
2023-04-04 01:26:24,934 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.2480, loss: 0.2545 ||:  93%|#########2| 7970/8583 [04:11<00:18, 32.89it/s]
2023-04-04 01:26:35,029 - INFO - tqdm - accuracy: 0.9081, batch_loss: 0.2506, loss: 0.2548 ||:  97%|#########7| 8350/8583 [04:21<00:06, 38.69it/s]
2023-04-04 01:26:40,121 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.2467, loss: 0.2547 ||: 100%|#########9| 8542/8583 [04:26<00:01, 37.79it/s]
2023-04-04 01:26:40,229 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.4796, loss: 0.2548 ||: 100%|#########9| 8546/8583 [04:26<00:00, 37.62it/s]
2023-04-04 01:26:40,338 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3239, loss: 0.2548 ||: 100%|#########9| 8550/8583 [04:26<00:00, 37.26it/s]
2023-04-04 01:26:40,445 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.1869, loss: 0.2548 ||: 100%|#########9| 8554/8583 [04:27<00:00, 37.37it/s]
2023-04-04 01:26:40,570 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.0705, loss: 0.2547 ||: 100%|#########9| 8558/8583 [04:27<00:00, 35.58it/s]
2023-04-04 01:26:40,704 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3554, loss: 0.2548 ||: 100%|#########9| 8562/8583 [04:27<00:00, 33.59it/s]
2023-04-04 01:26:40,832 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3187, loss: 0.2548 ||: 100%|#########9| 8566/8583 [04:27<00:00, 32.90it/s]
2023-04-04 01:26:40,940 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3231, loss: 0.2548 ||: 100%|#########9| 8570/8583 [04:27<00:00, 34.00it/s]
2023-04-04 01:26:41,064 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.2431, loss: 0.2548 ||: 100%|#########9| 8575/8583 [04:27<00:00, 35.96it/s]
2023-04-04 01:26:41,174 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.2901, loss: 0.2548 ||: 100%|#########9| 8579/8583 [04:27<00:00, 36.12it/s]
2023-04-04 01:26:41,279 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3180, loss: 0.2548 ||: 100%|##########| 8583/8583 [04:27<00:00, 36.60it/s]
2023-04-04 01:26:41,658 - INFO - tqdm - accuracy: 0.9082, batch_loss: 0.3180, loss: 0.2548 ||: 100%|##########| 8583/8583 [04:28<00:00, 32.00it/s]
2023-04-04 01:26:41,659 - INFO - allennlp.training.gradient_descent_trainer - Validating
2023-04-04 01:26:41,660 - INFO - tqdm - 0%|          | 0/154 [00:00<?, ?it/s]
2023-04-04 01:26:43,309 - INFO - tqdm - accuracy: 0.8865, batch_loss: 0.1705, loss: 0.3194 ||: 100%|##########| 154/154 [00:01<00:00, 93.47it/s]
2023-04-04 01:26:43,327 - INFO - allennlp.training.callbacks.console_logger -                        Training |  Validation
2023-04-04 01:26:43,327 - INFO - allennlp.training.callbacks.console_logger - accuracy           |     0.908  |     0.887
2023-04-04 01:26:43,328 - INFO - allennlp.training.callbacks.console_logger - gpu_0_memory_MB    |   570.054  |       N/A
2023-04-04 01:26:43,329 - INFO - allennlp.training.callbacks.console_logger - loss               |     0.255  |     0.319
2023-04-04 01:26:43,329 - INFO - allennlp.training.callbacks.console_logger - worker_0_memory_MB |  7796.727  |       N/A
2023-04-04 01:26:44,053 - INFO - allennlp.training.gradient_descent_trainer - Epoch duration: 0:04:30.613794
2023-04-04 01:26:44,054 - INFO - allennlp.training.gradient_descent_trainer - Ran out of patience. Stopping training.
2023-04-04 01:26:44,152 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.
2023-04-04 01:26:44,159 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 16,
  "peak_worker_0_memory_MB": 7796.7265625,
  "peak_gpu_0_memory_MB": 591.6171875,
  "training_duration": "1:54:01.370480",
  "epoch": 21,
  "training_accuracy": 0.9082157090138491,
  "training_loss": 0.254754509378824,
  "training_worker_0_memory_MB": 7796.7265625,
  "training_gpu_0_memory_MB": 570.0537109375,
  "validation_accuracy": 0.8865068075594391,
  "validation_loss": 0.3194480088430566,
  "best_validation_accuracy": 0.8871164397480187,
  "best_validation_loss": 0.3200975119970836
}
2023-04-04 01:26:44,276 - INFO - allennlp.models.archival - archiving weights and vocabulary to /kuacc/users/mugekural/workfolder/dev/git/cogeval/model/language-inference/model_output_esim/model.tar.gz
