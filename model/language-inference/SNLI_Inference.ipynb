{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization"
      ],
      "metadata": {
        "id": "ashqguTWYFz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the GPU model\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "r7a0TexjX8zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuN5oUr3M1ti"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "WORKING_DIR = \"/content/drive/MyDrive/Research/CogEval-1/SNLI\"\n",
        "os.environ['WORKING_DIR'] = WORKING_DIR"
      ],
      "metadata": {
        "id": "VqTqg3c1X818"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $WORKING_DIR"
      ],
      "metadata": {
        "id": "zt4NEC3-X84S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install allennlp allennlp-models"
      ],
      "metadata": {
        "id": "Cdgddh-R4Oun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check models"
      ],
      "metadata": {
        "id": "LUvZdUH5aBPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir $WORKING_DIR/output"
      ],
      "metadata": {
        "id": "jx_YWqbjZzsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir $WORKING_DIR/output/RoBERTa"
      ],
      "metadata": {
        "id": "S6ZRaQYpZ3c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!allennlp predict ./checkpoints/RoBERTa/model.tar.gz ./data/snli_1.0_train_lalor.jsonl  --use-dataset-reader --output-file ./output/RoBERTa/snli_roberta.txt"
      ],
      "metadata": {
        "id": "mFiNzAwtZpvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir $WORKING_DIR/output/ESIM"
      ],
      "metadata": {
        "id": "kqV-2OOuaKCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccAMqNOm5P0K"
      },
      "outputs": [],
      "source": [
        "!allennlp predict ./checkpoints/ESIM/model.tar.gz ./data/snli_1.0_train_lalor.jsonl  --use-dataset-reader --output-file ./output/ESIM/snli_esim.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run inference"
      ],
      "metadata": {
        "id": "97r7Qw83btKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RoBERTa"
      ],
      "metadata": {
        "id": "jkesyfKMdWtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./checkpoints/RoBERTa/model.tar.gz\"\n",
        "output_path_noncalibrated = \"./output/RoBERTa/lalor_snli_no_calibration.csv\"\n",
        "output_path_calibrated = \"./output/RoBERTa/lalor_snli_calibrated_mc_dropout_50.csv\"\n",
        "logits_key_name = \"logits\"\n",
        "prob_key_name = \"probs\""
      ],
      "metadata": {
        "id": "VBghbgC1bzcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ESIM"
      ],
      "metadata": {
        "id": "EqQI9P9NdaPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./checkpoints/ESIM/model.tar.gz\"\n",
        "output_path_noncalibrated = \"./output/ESIM/lalor_snli_no_calibration.csv\"\n",
        "output_path_calibrated = \"./output/ESIM/lalor_snli_calibrated_mc_dropout_50.csv\"\n",
        "logits_key_name = \"label_logits\"\n",
        "prob_key_name = \"label_probs\""
      ],
      "metadata": {
        "id": "6yaHhOjXdSyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the model"
      ],
      "metadata": {
        "id": "DMyrN9AbeEO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6Fa0Rtl5P0K"
      },
      "outputs": [],
      "source": [
        "# try running this cell several times in case of errors\n",
        "from allennlp_models.pair_classification.predictors.textual_entailment import TextualEntailmentPredictor\n",
        "from allennlp.models import archival\n",
        "\n",
        "archive = archival.load_archive(model_path)\n",
        "predictor = TextualEntailmentPredictor.from_archive(archive=archive, predictor_name='textual_entailment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLOAZ1Ce0BuW"
      },
      "outputs": [],
      "source": [
        "# from allennlp_models.pretrained import load_predictor\n",
        "# predictor = load_predictor(\"pair-classification-roberta-snli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSFdnGGJ0ZQB"
      },
      "outputs": [],
      "source": [
        "# A test model run\n",
        "\n",
        "premise = \"It's a cat.\"\n",
        "hypothesis = \"It's Monday.\"\n",
        "preds = predictor.predict(premise, hypothesis)\n",
        "\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exBKK1x4Stjs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./human_data/snli_human_4gs.csv', sep=',', header=0)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQoWRoQWdL73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running without calibration"
      ],
      "metadata": {
        "id": "o5ZvMtpReJtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSALsaPB3GdG"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import entropy\n",
        "\n",
        "label_1 = []\n",
        "label_2 = []\n",
        "label_3 = []\n",
        "\n",
        "sample_entropy = dict()\n",
        "predictions = dict()\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for ind, row in df.iterrows():\n",
        "\n",
        "    premise = row['sentence_1']\n",
        "    hypothesis = row['sentence_2']\n",
        "    preds = predictor.predict(premise, hypothesis)\n",
        "\n",
        "    label_1.append(preds[prob_key_name][0])\n",
        "    label_2.append(preds[prob_key_name][1])\n",
        "    label_3.append(preds[prob_key_name][2])\n",
        "\n",
        "    guid = row['snli_id'] \n",
        "\n",
        "    sample_entropy[guid] = entropy(preds[prob_key_name], base=2)\n",
        "    predictions[guid] = preds['label']\n",
        "\n",
        "    if row['label'] == preds['label']:\n",
        "      correct += 1\n",
        "\n",
        "print(correct / len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKuKP-OL4GBY"
      },
      "outputs": [],
      "source": [
        "df['label_1'] = label_1\n",
        "df['label_2'] = label_2\n",
        "df['label_3'] = label_3\n",
        "df['pred'] = list(predictions.values())\n",
        "df['softmax_entropy'] = list(sample_entropy.values())\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lqOtCvJ478p"
      },
      "outputs": [],
      "source": [
        "df.to_csv(output_path_noncalibrated, index=False, header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMgeea8I9hrX"
      },
      "source": [
        "##MC Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke4O6v2QtB9O"
      },
      "outputs": [],
      "source": [
        "# switch to train mode to enable drop out layers\n",
        "predictor._model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1vUQqFLnT_X"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# number of MC dropout iterations\n",
        "iterations = 50\n",
        "\n",
        "sm_sum = dict()\n",
        "\n",
        "for counter in range(iterations):\n",
        "\n",
        "    print('Iteration: ', counter)\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    for ind, row in df.iterrows():\n",
        "\n",
        "        premise = row['sentence_1']\n",
        "        hypothesis = row['sentence_2']\n",
        "        preds = predictor.predict(premise, hypothesis)\n",
        "\n",
        "        scores = softmax(preds[logits_key_name])\n",
        "\n",
        "        guid = row['snli_id'] \n",
        "\n",
        "        if guid in sm_sum:\n",
        "            for i in range(3):\n",
        "              sm_sum[guid][i] += scores[i]\n",
        "        else:\n",
        "          sm_sum[guid] = scores.copy()\n",
        "\n",
        "        if row['label'] == preds['label']:\n",
        "          correct += 1\n",
        "\n",
        "    print(correct / len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA6_79CRwFR8"
      },
      "outputs": [],
      "source": [
        "# calculate means\n",
        "for guid in sm_sum.keys():\n",
        "  sm_sum[guid] = sm_sum[guid] / iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-268NdIwjYe"
      },
      "outputs": [],
      "source": [
        "# calculcate entropies\n",
        "from scipy.stats import entropy\n",
        "\n",
        "sample_entropy = dict()\n",
        "\n",
        "for guid in sorted(sm_sum.keys()):\n",
        "  sample_entropy[guid] = entropy(sm_sum[guid], base=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x2vvD28njjg"
      },
      "outputs": [],
      "source": [
        "# get the predictions\n",
        "import numpy as np\n",
        "\n",
        "predictions = dict()\n",
        "\n",
        "for guid in sorted(sm_sum.keys()):\n",
        "  predictions[guid] = np.argmax(sm_sum[guid])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKII-h6AJzw9"
      },
      "outputs": [],
      "source": [
        "label_map = {\n",
        "    0: \"entailment\",\n",
        "    1: \"contradiction\",\n",
        "    2: \"neutral\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUhefqLS7FKe"
      },
      "outputs": [],
      "source": [
        "prob_0 = []\n",
        "prob_1 = []\n",
        "prob_2 = []\n",
        "entropy = []\n",
        "preds = []\n",
        "\n",
        "for ind, row in df.iterrows():\n",
        "  \n",
        "  sample_id = row['snli_id']\n",
        "\n",
        "  prob_0.append(sm_sum[sample_id][0])\n",
        "  prob_1.append(sm_sum[sample_id][1])\n",
        "  prob_2.append(sm_sum[sample_id][2])\n",
        "  entropy.append(sample_entropy[sample_id])\n",
        "  preds.append(label_map[predictions[sample_id]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhtMzEGIwulk"
      },
      "outputs": [],
      "source": [
        "df['prob_0'] = prob_0\n",
        "df['prob_1'] = prob_1\n",
        "df['prob_2'] = prob_2\n",
        "df[\"pred\"] = preds\n",
        "df[\"softmax_entropy\"] = entropy\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAvOlXhnKEfD"
      },
      "outputs": [],
      "source": [
        "# wrong predictions\n",
        "df[df.label != df.pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2lnMKWR5P0a"
      },
      "outputs": [],
      "source": [
        "# calibrated accuracy\n",
        "1-df[df.label != df.pred].shape[0]/df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some formatting\n",
        "df = df.rename(columns={\"label_1\": \"prob_0_no_cal\", \"label_2\": \"prob_1_no_cal\", \"label_3\": \"prob_2_no_cal\" })\n",
        "df = df.rename(columns={\"prob_0\": \"prob_0_with_cal\", \"prob_1\": \"prob_1_with_cal\", \"prob_2\": \"prob_2_with_cal\" })\n",
        "df['entropy_with_cal'] = df['softmax_entropy']\n",
        "df = df.drop(columns = ['softmax_entropy'])"
      ],
      "metadata": {
        "id": "Nz0MzZu6gKRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A6aQFAEZNos"
      },
      "outputs": [],
      "source": [
        "df.to_csv(output_path_calibrated, index=False, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNzLsFAxl7Bg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}